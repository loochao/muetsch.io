{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/cactus-dark/source/images/apple-touch-icon.png","path":"images/apple-touch-icon.png","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/images/favicon-192x192.png","path":"images/favicon-192x192.png","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/images/favicon.ico","path":"images/favicon.ico","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/images/logo.png","path":"images/logo.png","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/justified-gallery/jquery.justifiedGallery.min.js","path":"lib/justified-gallery/jquery.justifiedGallery.min.js","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/justified-gallery/justifiedGallery.min.css","path":"lib/justified-gallery/justifiedGallery.min.css","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/styles.css","path":"lib/meslo-LG/styles.css","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/jquery/jquery.min.js","path":"lib/jquery/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGL-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGM-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","path":"lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","path":"lib/meslo-LG/fonts/MesloLGS-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus-dark/source/images/theme overview.psd","path":"images/theme overview.psd","modified":0,"renderable":1},{"_id":"source/images/raid01.png","path":"images/raid01.png","modified":0,"renderable":0},{"_id":"source/images/raid10.png","path":"images/raid10.png","modified":0,"renderable":0},{"_id":"source/images/scorecard.jpg","path":"images/scorecard.jpg","modified":0,"renderable":0},{"_id":"source/images/anchr_2.jpg","path":"images/anchr_2.jpg","modified":0,"renderable":0},{"_id":"source/images/anchr_1.jpg","path":"images/anchr_1.jpg","modified":0,"renderable":0},{"_id":"source/images/angular2_logo.png","path":"images/angular2_logo.png","modified":0,"renderable":0},{"_id":"source/images/webdev_techstack.png","path":"images/webdev_techstack.png","modified":0,"renderable":0},{"_id":"source/images/webdev_techstack_large.png","path":"images/webdev_techstack_large.png","modified":0,"renderable":0},{"_id":"source/images/do.png","path":"images/do.png","modified":0,"renderable":0},{"_id":"source/images/whatsapp_logo.png","path":"images/whatsapp_logo.png","modified":0,"renderable":0},{"_id":"source/images/unhosted.jpg","path":"images/unhosted.jpg","modified":0,"renderable":0},{"_id":"source/images/expensebot_icon.png","path":"images/expensebot_icon.png","modified":0,"renderable":0},{"_id":"source/images/doodlerbot_icon.png","path":"images/doodlerbot_icon.png","modified":0,"renderable":0},{"_id":"source/images/statista.png","path":"images/statista.png","modified":0,"renderable":0},{"_id":"source/images/webdevlist.jpg","path":"images/webdevlist.jpg","modified":0,"renderable":0},{"_id":"source/images/thesis_mockup.png","path":"images/thesis_mockup.png","modified":0,"renderable":0},{"_id":"source/images/thesis_stack.png","path":"images/thesis_stack.png","modified":0,"renderable":0},{"_id":"source/images/push_screenshot1.png","path":"images/push_screenshot1.png","modified":0,"renderable":0},{"_id":"source/images/push_screenshot2.png","path":"images/push_screenshot2.png","modified":0,"renderable":0},{"_id":"source/images/benchmarks.svg","path":"images/benchmarks.svg","modified":0,"renderable":0},{"_id":"source/images/benchmarks2.svg","path":"images/benchmarks2.svg","modified":0,"renderable":0},{"_id":"source/images/webservers.png","path":"images/webservers.png","modified":0,"renderable":0},{"_id":"source/images/Webserver_memory_graph.jpg","path":"images/Webserver_memory_graph.jpg","modified":0,"renderable":0},{"_id":"source/images/webserver_performance.png","path":"images/webserver_performance.png","modified":0,"renderable":0},{"_id":"source/images/trivia.jpg","path":"images/trivia.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"themes/landscape/.npmignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1493842432552},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1493842432552},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1493842432552},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1493842432553},{"_id":"themes/landscape/_config.yml","hash":"fb8c98a0f6ff9f962637f329c22699721854cd73","modified":1493842432554},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1493842432554},{"_id":"source/_posts/hello-world.md","hash":"8a02477044e2b77f1b262da2c48c01429e4a32e4","modified":1493842432552},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1493842432572},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1493842432573},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1493842432572},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1493842432579},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1493842432576},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1493842432574},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1493842432573},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1493842432580},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1493842432574},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1493842432581},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1493842432577},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1493842432581},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1493842432576},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1493842432577},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1493842432572},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1493842432598},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1493842432597},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1493842432600},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1493842432600},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1493842432598},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1493842432598},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"4fe8853e864d192701c03e5cd3a5390287b90612","modified":1493842432599},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"c21ca56f419d01a9f49c27b6be9f4a98402b2aa3","modified":1493842432599},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1493842432601},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1493842432604},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1493842432605},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1493842432597},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1493842432606},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1493842432606},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1493842432606},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1493842432597},{"_id":"themes/landscape/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1493842432604},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1493842432607},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1493842432609},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1493842432607},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1493842432607},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1493842432608},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1493842432608},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1493842432608},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1493842432612},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1493842432641},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1493842432631},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1493842432607},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1493842432630},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1493842432631},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1493842432634},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1493842432632},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1493842432633},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1493842432632},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1493842432636},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1493842432644},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1493842432642},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1493842432642},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1493842432643},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1493842432645},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1493842432642},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1493842432643},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1493842432644},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1493842432644},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1493842432637},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1493842432650},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1493842432643},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1493842432661},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1493842432649},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1493842432638},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1493842432651},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1493842432650},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1493842432650},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1493842432651},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1493842432651},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1493842432656},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1493842432660},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1493842432656},{"_id":"source/about/index.md","hash":"24719b93325f0a85c25522fad49e180fd984eb71","modified":1493843373836},{"_id":"public/about/index.html","hash":"4215c955ec373cfeeb57e97d6cf1d275f099134f","modified":1493847087772},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1493842902787},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1493842902787},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1493842902787},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1493842902788},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1493842902788},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1493842902788},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1493842902788},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1493842902789},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1493842902789},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1493842902789},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1493842903569},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1493842903580},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1493842903580},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1493842903580},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1493842903580},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1493842903580},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1493842903580},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1493842903580},{"_id":"public/css/style.css","hash":"fffb3966bf36057a325498aba9ce3a2ea7bd79e1","modified":1493842903581},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1493842903582},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1493842903582},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1493842903585},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1493842903588},{"_id":"themes/cactus-dark/LICENSE","hash":"4d5f5f360a18c68f0fd1897bdb1eb1210c2893e3","modified":1493843026515},{"_id":"themes/cactus-dark/README.md","hash":"f38b2f4771eeccc0ae0959ac3e3c485a9d159d4a","modified":1493843026521},{"_id":"themes/cactus-dark/_config.yml","hash":"6578a910d914f97f3a526ccf7c83c9d1d46aa36a","modified":1493846139690},{"_id":"themes/cactus-dark/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1493843026467},{"_id":"themes/cactus-dark/.git/config","hash":"5c73cefa9505b02666ce690c7524e38f7e11e557","modified":1493847074291},{"_id":"themes/cactus-dark/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1493843022473},{"_id":"themes/cactus-dark/.git/index","hash":"8f893ca5178a2c7443d74616e9a5332f5101e970","modified":1493847074787},{"_id":"themes/cactus-dark/.git/packed-refs","hash":"ce099299e21033c73eb8141b418983b506825473","modified":1493847074256},{"_id":"themes/cactus-dark/layout/archive.ejs","hash":"ab9798bf534485a4fed4d3089011421858afdd26","modified":1493843026703},{"_id":"themes/cactus-dark/layout/index.ejs","hash":"53196279a25035da55902f4b8f0ebdf7871d39d1","modified":1493843026737},{"_id":"themes/cactus-dark/layout/layout.ejs","hash":"8484532ad7c4da22f46fc1394bb2fd9ded34be1f","modified":1493843026747},{"_id":"themes/cactus-dark/layout/page.ejs","hash":"b6b7b1e6dc856a0e62f35da0151f67ba41143e04","modified":1493843026751},{"_id":"themes/cactus-dark/layout/post.ejs","hash":"2731e597b5d1714a6f5a775c432e99785f02a3e3","modified":1493843026762},{"_id":"themes/cactus-dark/scripts/meta.js","hash":"fa6055a39851c9953d033e70c1614547b94dce60","modified":1493843026772},{"_id":"themes/cactus-dark/scripts/thumbnail.js","hash":"df8829fd8c3119650037eba5ec11bdce06acff9d","modified":1493843026778},{"_id":"themes/cactus-dark/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1493843022478},{"_id":"themes/cactus-dark/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1493843022484},{"_id":"themes/cactus-dark/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1493843022489},{"_id":"themes/cactus-dark/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1493843022494},{"_id":"themes/cactus-dark/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1493843022501},{"_id":"themes/cactus-dark/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1493843022508},{"_id":"themes/cactus-dark/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1493843022517},{"_id":"themes/cactus-dark/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1493843022524},{"_id":"themes/cactus-dark/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1493843022532},{"_id":"themes/cactus-dark/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1493843022537},{"_id":"themes/cactus-dark/.git/logs/HEAD","hash":"e21898b690ce88fcfcd286f449dbf4968f2ada72","modified":1493847074277},{"_id":"themes/cactus-dark/layout/_partial/comments.ejs","hash":"853a4500da515ef3facc51a055886eaf8efd080d","modified":1493843026534},{"_id":"themes/cactus-dark/layout/_partial/footer.ejs","hash":"7f6b3f126a58e6734b658ab57bc6b41822bc9342","modified":1493843026538},{"_id":"themes/cactus-dark/layout/_partial/head.ejs","hash":"7782e6b1ce72fcf121f0017d383e2fb87e72c539","modified":1493843026579},{"_id":"themes/cactus-dark/layout/_partial/header.ejs","hash":"889fe54bbfd1fb3357e8c0614d57a437a72f782a","modified":1493843026593},{"_id":"themes/cactus-dark/layout/_partial/pagination.ejs","hash":"ca660c59aec56daa4a7b41715b97434d4a24c37e","modified":1493843026600},{"_id":"themes/cactus-dark/layout/_partial/scripts.ejs","hash":"6cffa3adb2f5b93a47f29549ac589c8bce8c223e","modified":1493843026671},{"_id":"themes/cactus-dark/layout/_partial/styles.ejs","hash":"e62b799d8ac369d1f1b36bd2649ecc34aec3384c","modified":1493843026682},{"_id":"themes/cactus-dark/source/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1493843027063},{"_id":"themes/cactus-dark/source/images/favicon-192x192.png","hash":"96e6fcbbb13a5914a6131391e210eb7dfd13d692","modified":1493843027064},{"_id":"themes/cactus-dark/source/images/favicon.ico","hash":"189f9842bcb79a6f8f9e8445bc8bbd773443826b","modified":1493843027076},{"_id":"themes/cactus-dark/source/images/logo.png","hash":"199750f3a39251ca97d36ed8317d88dfdc2dfe66","modified":1493843027078},{"_id":"themes/cactus-dark/source/css/_extend.styl","hash":"faca25132d55e8989d1c1d638e55d1e97de3c561","modified":1493843026783},{"_id":"themes/cactus-dark/source/css/_mixins.styl","hash":"c921ceb620deedddd38c9cec28190995e8764bab","modified":1493843026967},{"_id":"themes/cactus-dark/source/css/_util.styl","hash":"f8e286a21c7ec3e771d5ddeb2909ac92390af9bd","modified":1493843027040},{"_id":"themes/cactus-dark/source/css/_variables.styl","hash":"80345f77f0e601669047cbb3c44491720c3b5c13","modified":1493843027048},{"_id":"themes/cactus-dark/source/css/style.styl","hash":"0c24759c2556f5f8f2ade62f925694c2150b1a69","modified":1493843027061},{"_id":"themes/cactus-dark/source/js/main.js","hash":"2703a7cb4fc7056d13215b9fde675da426b9cdc4","modified":1493843027124},{"_id":"themes/cactus-dark/.git/objects/pack/pack-96addcda4feab6ea6f65a2c5e3489444915245ca.idx","hash":"2df99f3e17037731d09f0f9a6f40181467cf1080","modified":1493843026363},{"_id":"themes/cactus-dark/.git/refs/heads/master","hash":"e2bc22839d14f788f87b0d22f02f6dce760f4976","modified":1493847074273},{"_id":"themes/cactus-dark/layout/_partial/post/actions_desktop.ejs","hash":"2319dea76f205c27dd59c994921f66350df8027a","modified":1493843026608},{"_id":"themes/cactus-dark/layout/_partial/post/actions_mobile.ejs","hash":"e7638a83e5aaa4bf5b24440ca76fec8eb563bed7","modified":1493843026615},{"_id":"themes/cactus-dark/layout/_partial/post/date.ejs","hash":"12a4a7ba6334e3e5c03d9a9601d7779a27c2e082","modified":1493843026621},{"_id":"themes/cactus-dark/layout/_partial/post/gallery.ejs","hash":"9aecd8908e8a684f33dc20c02497c0f1774137c7","modified":1493843026631},{"_id":"themes/cactus-dark/layout/_partial/post/share.ejs","hash":"25a3406f97e976ec13239f0d3f32f9e512511f50","modified":1493843026636},{"_id":"themes/cactus-dark/layout/_partial/post/title.ejs","hash":"a060f1c6e3718494a6b1d0e1981ea0bf4e549828","modified":1493843026649},{"_id":"themes/cactus-dark/layout/_partial/post/tag.ejs","hash":"bfab03ef986d35ccad583f2d2b575db4a8d2789e","modified":1493843026644},{"_id":"themes/cactus-dark/source/css/_highlight/agate.styl","hash":"601eb70448a16b918df132f6fc41e891ae053653","modified":1493843026787},{"_id":"themes/cactus-dark/source/css/_highlight/androidstudio.styl","hash":"65d09f1b0e81c6a182f549fd3de51e59823c97ae","modified":1493843026792},{"_id":"themes/cactus-dark/source/css/_highlight/arta.styl","hash":"1a5accc115f41d1b669ed708ac6a29abac876599","modified":1493843026797},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-dune-dark.styl","hash":"df50a85a4b14c7ca6e825d665594b91229d0e460","modified":1493843026806},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-cave-dark.styl","hash":"bc647b2c1d971d7cc947aa1ed66e9fd115261921","modified":1493843026802},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-estuary-dark.styl","hash":"d84382bc8298f96730757391d3e761b7e640f406","modified":1493843026810},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-forest-dark.styl","hash":"57c154c6045a038dc7df0a25927853e10bf48c4a","modified":1493843026814},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-heath-dark.styl","hash":"b0cf13b2233e7bc38342032d2d7296591a4c2bcf","modified":1493843026818},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-lakeside-dark.styl","hash":"bb0a8c4ad0dd8e3e7de7122ddf268fc42aa94acb","modified":1493843026822},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-plateau-dark.styl","hash":"09c64f1a7052aec9070c36c0431df25216afaea1","modified":1493843026826},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-savanna-dark.styl","hash":"a16c919a1ccf2f845488078fb341381bec46b1f3","modified":1493843026830},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-seaside-dark.styl","hash":"ce233a101daea7124cbfcd34add43ccfe2e1e1c7","modified":1493843026834},{"_id":"themes/cactus-dark/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"414b0cfc142f70afe359c16450b651e28bf7325a","modified":1493843026838},{"_id":"themes/cactus-dark/source/css/_highlight/codepen-embed.styl","hash":"f4dcc84d8e39f9831a5efe80e51923fc3054feb0","modified":1493843026843},{"_id":"themes/cactus-dark/source/css/_highlight/dark.styl","hash":"71ce56d311cc2f3a605f6e2c495ccd7236878404","modified":1493843026846},{"_id":"themes/cactus-dark/source/css/_highlight/darkula.styl","hash":"ad0d5728d21645039c9f199e7a56814170ed3bab","modified":1493843026850},{"_id":"themes/cactus-dark/source/css/_highlight/far.styl","hash":"d9928010ffe71e80b97a5afcba1a4975efdd7372","modified":1493843026854},{"_id":"themes/cactus-dark/source/css/_highlight/hopscotch.styl","hash":"b374c6550b89b4751aedc8fbc3cf98d95bd70ead","modified":1493843026859},{"_id":"themes/cactus-dark/source/css/_highlight/hybrid.styl","hash":"ea8d7ddc258b073308746385f5cb85aabb8bfb83","modified":1493843026863},{"_id":"themes/cactus-dark/source/css/_highlight/ir-black.styl","hash":"693078bbd72a2091ed30f506cc55949600b717af","modified":1493843026867},{"_id":"themes/cactus-dark/source/css/_highlight/kimbie.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1493843026871},{"_id":"themes/cactus-dark/source/css/_highlight/monokai-sublime.styl","hash":"25aa2fc1dbe38593e7c7ebe525438a39574d9935","modified":1493843026876},{"_id":"themes/cactus-dark/source/css/_highlight/monokai.styl","hash":"5a4fe9f957fd7a368c21b62a818403db4270452f","modified":1493843026880},{"_id":"themes/cactus-dark/source/css/_highlight/obsidian.styl","hash":"55572bbcfee1de6c31ac54681bb00336f5ae826d","modified":1493843026884},{"_id":"themes/cactus-dark/source/css/_highlight/paraiso.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1493843026888},{"_id":"themes/cactus-dark/source/css/_highlight/pojoaque.styl","hash":"77dae9dc41945359d17fe84dbd317f1b40b2ee33","modified":1493843026892},{"_id":"themes/cactus-dark/source/css/_highlight/railscasts.styl","hash":"acd620f8bb7ff0e3fe5f9a22b4433ceef93a05e6","modified":1493843026896},{"_id":"themes/cactus-dark/source/css/_highlight/rainbow.styl","hash":"ce73b858fc0aba0e57ef9fb136c083082746bc1d","modified":1493843026904},{"_id":"themes/cactus-dark/source/css/_highlight/solarized-dark.styl","hash":"702b9299a48c90124e3ac1d45f1591042f2beccc","modified":1493843026924},{"_id":"themes/cactus-dark/source/css/_highlight/sunburst.styl","hash":"a0b5b5129547a23865d400cfa562ea0ac1ee3958","modified":1493843026932},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-blue.styl","hash":"8b3087d4422be6eb800935a22eb11e035341c4ba","modified":1493843026942},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-bright.styl","hash":"0ac6af6ecb446b5b60d6226748e4a6532db34f57","modified":1493843026948},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night-eighties.styl","hash":"fa57b3bb7857a160fc856dbe319b31e30cc5d771","modified":1493843026954},{"_id":"themes/cactus-dark/source/css/_highlight/tomorrow-night.styl","hash":"19b3080d4b066b40d50d7e7f297472482b5801fd","modified":1493843026958},{"_id":"themes/cactus-dark/source/css/_highlight/zenburn.styl","hash":"fc5ec840435dad80964d04519d3f882ddc03746a","modified":1493843026963},{"_id":"themes/cactus-dark/source/css/_partial/archive.styl","hash":"18fa7f84a9783c5fb56c9f450ea93bd88408e682","modified":1493843026975},{"_id":"themes/cactus-dark/source/css/_partial/article.styl","hash":"202b775a966d7bc35bf5adc693b62463dec106bb","modified":1493843026982},{"_id":"themes/cactus-dark/source/css/_partial/comments.styl","hash":"11fb41241a13971d23fc3f7e6d60315c7f248396","modified":1493843026987},{"_id":"themes/cactus-dark/source/css/_partial/footer.styl","hash":"b7570de60eaf9aa6b0192bf9c71b9172ff11bfbc","modified":1493843026993},{"_id":"themes/cactus-dark/source/css/_partial/header.styl","hash":"63707d9103a283147ca222fd6f8ff9bffbffe427","modified":1493843026998},{"_id":"themes/cactus-dark/source/css/_partial/index.styl","hash":"cf43702450ea1e5617541501886982a394cff8ec","modified":1493843027007},{"_id":"themes/cactus-dark/source/css/_partial/pagination.styl","hash":"03a1b81d60dae3dd55963b7e74a6fee83470e6bb","modified":1493843027013},{"_id":"themes/cactus-dark/source/lib/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1493843027346},{"_id":"themes/cactus-dark/source/lib/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1493843027351},{"_id":"themes/cactus-dark/source/lib/meslo-LG/styles.css","hash":"eb88d0b9f1bbef99070e9627e2c96d892036bf7e","modified":1493843027468},{"_id":"themes/cactus-dark/source/lib/jquery/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1493843027306},{"_id":"themes/cactus-dark/.git/logs/refs/heads/master","hash":"e21898b690ce88fcfcd286f449dbf4968f2ada72","modified":1493847074275},{"_id":"themes/cactus-dark/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1493843026465},{"_id":"themes/cactus-dark/source/css/_partial/post/actions_desktop.styl","hash":"a9f9b6382d313f9ef9ff9f53bd0db11e5b36edf4","modified":1493843027025},{"_id":"themes/cactus-dark/source/css/_partial/post/actions_mobile.styl","hash":"e6a802d7ee1023c5fc5fac18bb0ba3dc03ef2ac8","modified":1493843027031},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1493846438319},{"_id":"themes/cactus-dark/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1493846438357},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1493846431223},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1493846431294},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1493846431469},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1493846431526},{"_id":"themes/cactus-dark/.git/logs/refs/remotes/origin/HEAD","hash":"e21898b690ce88fcfcd286f449dbf4968f2ada72","modified":1493847074264},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1493846431412},{"_id":"themes/cactus-dark/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1493846431374},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","hash":"96c97a0a098ca40802f948ae56fa37aa6683d034","modified":1493843027384},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","hash":"68700db02debd4b922304134da83b829cbfddfc9","modified":1493843027423},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","hash":"7f7cdbdcc26279c04046632e22d872f111bc9399","modified":1493843027456},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","hash":"bfa1ed9a263ed78462f06d322de13bd5bd0906b2","modified":1493843027365},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","hash":"a9a431fc7a6c3a67c98021d4035c12a07a4f1070","modified":1493843027376},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","hash":"2b912dd13f052f645ee19951604610bb350d50af","modified":1493843027393},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","hash":"a8a8df3393bccc365335fc5eb0a62a6b7ccd32b9","modified":1493843027401},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","hash":"65ddb11e75ee93909e845ab912a36717c48f1c94","modified":1493843027412},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","hash":"5e220152adefe905b2197f873d7cee99eca50e91","modified":1493843027431},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","hash":"df202ce09cbdc70bc16b81983a13ef0f94e46f10","modified":1493843027440},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","hash":"d895a1bd25e36c58b7f463ebe14de09f186d5ab4","modified":1493843027448},{"_id":"themes/cactus-dark/source/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","hash":"56fa0e33a390b704afc56af93a31576ccdbbdd9e","modified":1493843027464},{"_id":"themes/cactus-dark/source/images/theme overview.psd","hash":"8dc11d9d289c247423911e962c4eb3a556dc67d1","modified":1493843027110},{"_id":"themes/cactus-dark/.git/objects/pack/pack-96addcda4feab6ea6f65a2c5e3489444915245ca.pack","hash":"09ba6814b94344bf1c09476028128534a1ca1da3","modified":1493843026393},{"_id":"source/imprint/index.md","hash":"01f3329f4193a72e2ccbd1922dd258bcd2ae91a2","modified":1493843443049},{"_id":"source/_posts/cache-information-script.md","hash":"b6b8f282c48dc37e39b68d8a56e2e040253d3936","modified":1493843559020},{"_id":"public/imprint/index.html","hash":"bb2a8a880c6612f11c839656130c051ae9ab3e0a","modified":1493847087773},{"_id":"public/hello-world","hash":"b4a74ab7413550d6b388df19f6728d813a6fc151","modified":1493843647507},{"_id":"public/cache-information-script","hash":"5ced3ec967e749e8473da6157a5c37a339ed851b","modified":1493843647507},{"_id":"public/archives/index.html","hash":"033dea41819d74153bb2274aa685bd74de641d28","modified":1493847087774},{"_id":"public/archives/2015/index.html","hash":"e56e8751560d12c3e80aa8405041fc127370f2e6","modified":1493847087774},{"_id":"public/archives/2015/02/index.html","hash":"0ae685ebad63bb8e095a50fd7962c8246d77e509","modified":1493847087774},{"_id":"public/archives/2017/index.html","hash":"3329e3ae6080f0ef2552fd0fed0907754e8451ed","modified":1493847087775},{"_id":"public/archives/2017/05/index.html","hash":"416350c310ce017290e44a577c802554b892eb3f","modified":1493843805796},{"_id":"public/index.html","hash":"ce3ba2093055a7c7f7fd482da491ef8f4ceb9101","modified":1493847087775},{"_id":"public/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1493843647528},{"_id":"public/images/favicon.ico","hash":"189f9842bcb79a6f8f9e8445bc8bbd773443826b","modified":1493843647528},{"_id":"public/images/favicon-192x192.png","hash":"96e6fcbbb13a5914a6131391e210eb7dfd13d692","modified":1493843647528},{"_id":"public/images/logo.png","hash":"199750f3a39251ca97d36ed8317d88dfdc2dfe66","modified":1493843647528},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1493843647538},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1493843647541},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1493843647541},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1493843647541},{"_id":"public/lib/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1493843647548},{"_id":"public/js/main.js","hash":"2703a7cb4fc7056d13215b9fde675da426b9cdc4","modified":1493843647548},{"_id":"public/lib/meslo-LG/styles.css","hash":"eb88d0b9f1bbef99070e9627e2c96d892036bf7e","modified":1493843647548},{"_id":"public/lib/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1493843647548},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1493843647548},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1493843647548},{"_id":"public/lib/jquery/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1493843647548},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1493843647548},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1493843647572},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Italic.ttf","hash":"96c97a0a098ca40802f948ae56fa37aa6683d034","modified":1493843647605},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Italic.ttf","hash":"68700db02debd4b922304134da83b829cbfddfc9","modified":1493843647605},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Italic.ttf","hash":"7f7cdbdcc26279c04046632e22d872f111bc9399","modified":1493843647606},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Bold.ttf","hash":"bfa1ed9a263ed78462f06d322de13bd5bd0906b2","modified":1493843647612},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-BoldItalic.ttf","hash":"a9a431fc7a6c3a67c98021d4035c12a07a4f1070","modified":1493843647612},{"_id":"public/lib/meslo-LG/fonts/MesloLGL-Regular.ttf","hash":"2b912dd13f052f645ee19951604610bb350d50af","modified":1493843647613},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Bold.ttf","hash":"a8a8df3393bccc365335fc5eb0a62a6b7ccd32b9","modified":1493843647613},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-BoldItalic.ttf","hash":"65ddb11e75ee93909e845ab912a36717c48f1c94","modified":1493843647614},{"_id":"public/lib/meslo-LG/fonts/MesloLGM-Regular.ttf","hash":"5e220152adefe905b2197f873d7cee99eca50e91","modified":1493843647621},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Regular.ttf","hash":"56fa0e33a390b704afc56af93a31576ccdbbdd9e","modified":1493843647622},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-Bold.ttf","hash":"df202ce09cbdc70bc16b81983a13ef0f94e46f10","modified":1493843647623},{"_id":"public/lib/meslo-LG/fonts/MesloLGS-BoldItalic.ttf","hash":"d895a1bd25e36c58b7f463ebe14de09f186d5ab4","modified":1493843647623},{"_id":"public/images/theme overview.psd","hash":"8dc11d9d289c247423911e962c4eb3a556dc67d1","modified":1493843647731},{"_id":"public/hello-world.html","hash":"f355debc3342ccdcc380ad419153f94d9a88fa3a","modified":1493843805794},{"_id":"public/cache-information-script.html","hash":"2c7b663c1021bdbe6760b2822b9c82231aa3ae39","modified":1493843805794},{"_id":"source/_posts/anchr-io-image-uploads-bookmarks-and-shortlink-service.md","hash":"789d49d89b31f482f80e792ffdc627d7c245fe3c","modified":1493844685776},{"_id":"source/_posts/caddy-a-modern-web-server-vs-nginx.md","hash":"9a9c355ed3ddcbef9ff79deef95f88751212450f","modified":1493845726343},{"_id":"source/_posts/design-of-a-linked-data-enabled-microservice-platform-for-the-industrial-internet-of-things.md","hash":"c1c3aab0d95a2987e58fe9189598f9c36a18ccc9","modified":1493845426096},{"_id":"source/_posts/digitalocean-my-preferred-cloud-hosting-provider.md","hash":"7d6b7e6bed189f180fb58f52f0ea971dae96ab45","modified":1493844945992},{"_id":"source/_posts/how-do-whatsapps-end-to-end-encrypted-group-chats-work.md","hash":"1209b6df611783a249ba29a1dbaedc94e3079ff0","modified":1493845124447},{"_id":"source/_posts/how-to-load-yago-into-apache-jena-fuseki.md","hash":"47a6356bc8cfce54d352a58373a76ac38f3009ea","modified":1493845471934},{"_id":"source/_posts/how-to-make-telegram-bots.md","hash":"ad41a23a8ef8683745fa102e406708f2b8fa2a5b","modified":1493844055791},{"_id":"source/_posts/http-performance-java-jersey-vs-go-vs-nodejs.md","hash":"cbb3c4ef84caaf4456120b02e7efe53062607303","modified":1493845868986},{"_id":"source/_posts/http20-server-push-proxy.md","hash":"ec535d2a2ef2f10ab1f207fa664c7a2763b27f3a","modified":1493846094439},{"_id":"source/_posts/innovation-in-germany-not.md","hash":"31d27dc67d2c57fac4a28ac15ca1ebdbaca57fef","modified":1493845276762},{"_id":"source/_posts/learning-angular2-what-is-new.md","hash":"942d033405f0192315d26efedbe8b8bbce20631a","modified":1493844774223},{"_id":"source/_posts/linkeddata-trivia-game.md","hash":"5f8d798558af3716b59c271c4c07050d66b3293d","modified":1493845778898},{"_id":"source/_posts/instant-messenger-security-encryption-overview.md","hash":"eefec3bcbd6bd4f6e9241ac168ccea422b01a4c3","modified":1493844786032},{"_id":"source/_posts/linux-cache-information-bash-script.md","hash":"9b5526414d08dc4102119d7c31996c9961288fbb","modified":1493843970000},{"_id":"source/_posts/migrate-maildir-to-new-server-using-imapsync.md","hash":"15ae57c2734c5e3514532806234212184f340166","modified":1493845318241},{"_id":"source/_posts/ml-telegram-chat-message-classification.md","hash":"58ddc07e88e9917646c60d0ded5ddca7e310cbe6","modified":1493845826656},{"_id":"source/_posts/my-teck-stack-if-i-had-to-build-an-app-today.md","hash":"173cd62d9eccceda4387127935c58d132aff6774","modified":1493845515804},{"_id":"source/_posts/telegram-bot-example-code-in-nodejs.md","hash":"10a1212093688aa9589c882fafe0297fd999e2b6","modified":1493844184038},{"_id":"source/_posts/telegram-expensebot-doodlerbot.md","hash":"30f5598d3774028f543c17dc63a4e32ae9d3cbdc","modified":1493845210276},{"_id":"source/_posts/unhostedorg-applications-with-remotestorageio-and-webfingernet.md","hash":"213eca3c8df289c14d237fbcec4038bfe6994c04","modified":1493845114646},{"_id":"source/_posts/web-development-technology-stack.md","hash":"3196d6ac39cf01f233d0919f4d4405e768dfa565","modified":1493844873615},{"_id":"source/_posts/webdevlistnet-the-developers-resource-collection.md","hash":"b0f879ca1c4c00993c5e088bb1439356d9cdccc2","modified":1493845372850},{"_id":"source/_posts/why-raid-10-is-better-than-raid-01.md","hash":"a6eafba6baa3e10da17b3d93281bd3860cd0893d","modified":1493844400668},{"_id":"source/images/Webserver_memory_graph.jpg","hash":"aeaf52174560a2d3a7ff32fda21a26b96c907cc9","modified":1493845685790},{"_id":"source/images/anchr_1.jpg","hash":"0d50b24329bdcddea234f0c3ade3f2846daae148","modified":1493844641575},{"_id":"source/images/anchr_2.jpg","hash":"d07dfedb2fc549983f63bf7251f3d011b96188aa","modified":1493844638480},{"_id":"source/images/angular2_logo.png","hash":"189713e0c0de88477c6726fc59b4cd1cfb16b05e","modified":1493844757655},{"_id":"source/images/benchmarks.svg","hash":"e9fbfdf69d7ac1c9890d541fb07d69f844fbb99a","modified":1493845588136},{"_id":"source/images/benchmarks2.svg","hash":"c4bd56f99f3a8810fd50a3caf7a99213b407a0d5","modified":1493845594103},{"_id":"source/images/doodlerbot_icon.png","hash":"7e548feeabd180f1e5af390365ce88fe70fe619e","modified":1493845162012},{"_id":"source/images/expensebot_icon.png","hash":"479cb80aa0620db49e0a353ac7f550f7cc9f205d","modified":1493845159227},{"_id":"source/images/push_screenshot1.png","hash":"91d5fa3e4c5a3a3d0f369a8d90055d029e8ef28e","modified":1493845525389},{"_id":"source/images/push_screenshot2.png","hash":"144ca3caed3e5b9285f7f8edeba41917266ed529","modified":1493845527733},{"_id":"source/images/raid01.png","hash":"15da9f10e5a4d3f452287daf4420da8582d3ad31","modified":1493844386000},{"_id":"source/images/raid10.png","hash":"ae8cb17a2ae2eba7d238a8d56136f60823172242","modified":1493844388000},{"_id":"source/images/statista.png","hash":"4385242cac93067b8ca8dd02c01a1778bf1c6102","modified":1493845233499},{"_id":"source/images/trivia.jpg","hash":"8e7715fa940d79f43fd1e2a9ff8c2149cf0b11a8","modified":1493845737633},{"_id":"source/images/unhosted.jpg","hash":"6e0bde1ad7bfb3ba8d9b634f6518299e2d9d1f1b","modified":1493845074373},{"_id":"source/images/webdev_techstack.png","hash":"e3f4b8cdac4233ebcb5d7e20ee42703c9ffad6ba","modified":1493844829453},{"_id":"source/images/webdevlist.jpg","hash":"cfa9e038e301cdcd577c7833fc8b220f6c0d6a98","modified":1493845331047},{"_id":"source/images/webserver_performance.png","hash":"737f74276f3832a342464110566fdab49593de94","modified":1493845689854},{"_id":"source/images/whatsapp_logo.png","hash":"197552fa1ec1aefb1c912e52272d6d2d032e76f6","modified":1493845013721},{"_id":"source/images/do.png","hash":"dd43ce0ffde6885ad251e6e4edff64b36ddecd02","modified":1493844892762},{"_id":"source/images/thesis_mockup.png","hash":"a5ec4a8949edd6a168c866c675ab6c4e2bc00d33","modified":1493845390890},{"_id":"source/images/thesis_stack.png","hash":"5a410fcb932c552dbc0096f59fda594be334e9cd","modified":1493845394097},{"_id":"source/images/webdev_techstack_large.png","hash":"76169ecb9523c245c6588156fcff24c851b5c43b","modified":1493844833369},{"_id":"source/images/webservers.png","hash":"c1550f9bcb7350c9ebef5090484960877d8dda55","modified":1493845683186},{"_id":"source/images/scorecard.jpg","hash":"e4b56c4f825d42890e6c735c17d6a29a80a7f075","modified":1493844615462},{"_id":"themes/cactus-dark/.git/objects/pack/pack-c31da307765c27cc6a9efc99988ef537bcfd713b.idx","hash":"e9b92eabc5e0d5f93ea6cb6e9e1cb53ecb3b11e4","modified":1493847074159},{"_id":"themes/cactus-dark/.git/objects/pack/pack-c31da307765c27cc6a9efc99988ef537bcfd713b.pack","hash":"04baae160c4963d5aad3c1a15ef3b398904a3b7e","modified":1493847074198},{"_id":"public/linkeddata-trivia-game.html","hash":"9441720fd19f0f97108d2f834c06332656f647c5","modified":1493847087773},{"_id":"public/http20-server-push-proxy.html","hash":"bfc155e07edc2adc35078a97365d119dc26ba742","modified":1493847087773},{"_id":"public/web-development-technology-stack.html","hash":"35dbc2d3e7f4005923487418905c041cbf4e2c7d","modified":1493847087773},{"_id":"public/instant-messenger-security-encryption-overview.html","hash":"b2b6fb33a175a6df004961e033346c9aff6ac258","modified":1493847087773},{"_id":"public/telegram-bot-example-code-in-nodejs.html","hash":"18bf8c127875d4a802ead5a1e96fe46a2079de5d","modified":1493847087773},{"_id":"public/linux-cache-information-bash-script.html","hash":"9ed1b2a1a4aeb3b3cac80597c024dffe23b4e0c5","modified":1493847087773},{"_id":"public/archives/page/2/index.html","hash":"6dc7f296f29f219a2eb3cd297ce3709d7b7ca758","modified":1493847087774},{"_id":"public/archives/2015/06/index.html","hash":"9244950dc7b33f69ea13c74cf45e857d0a7ee9d6","modified":1493847087774},{"_id":"public/archives/2015/11/index.html","hash":"3d4a36c65c3ab73cdf215bb623f37e7bafb3daa2","modified":1493847087774},{"_id":"public/archives/2015/12/index.html","hash":"546e99b50a221b603d94d63deeffc5ab2e1078cb","modified":1493847087774},{"_id":"public/archives/2016/02/index.html","hash":"c9abb27edade36f62cad11176d850f0d0eacb604","modified":1493847087774},{"_id":"public/archives/2016/index.html","hash":"5e33a1227e896e6e70cd52317984049e9d78c0c8","modified":1493847087774},{"_id":"public/archives/2016/03/index.html","hash":"ce3295465459aa131ff2ea755816102bb4d6a95e","modified":1493847087774},{"_id":"public/archives/2016/04/index.html","hash":"dcfdf428a7f4deb802118127a0bf41586a5b97a1","modified":1493847087774},{"_id":"public/archives/2016/05/index.html","hash":"c14b4fced9f683b26c94170a5a5b2270d738120d","modified":1493847087774},{"_id":"public/archives/2016/07/index.html","hash":"0d1400c869cf9bc532b82ce866452e412c2115b1","modified":1493847087774},{"_id":"public/archives/2016/09/index.html","hash":"fea2349e09f593802811ae1b1f62858061272770","modified":1493847087774},{"_id":"public/archives/2016/10/index.html","hash":"cc03e13f725187350f55898f56382b3717ba4b35","modified":1493847087774},{"_id":"public/archives/2016/11/index.html","hash":"1b8dee4ac925f8ea8a4ad021edde981b01285d89","modified":1493847087774},{"_id":"public/archives/2017/01/index.html","hash":"7d654b1bb6e5767c808f7205bd285fe24aea131b","modified":1493847087775},{"_id":"public/archives/2017/02/index.html","hash":"5b2bcf5e480f3f94c81986ced021bdc980ccb73a","modified":1493847087775},{"_id":"public/page/2/index.html","hash":"9fee2417c364210018c348baf493d91cf384c0bc","modified":1493847087775},{"_id":"public/ml-telegram-chat-message-classification.html","hash":"c12c122c71a288f1bbde6ebbde11ea5bbd15f6a0","modified":1493847087775},{"_id":"public/caddy-a-modern-web-server-vs-nginx.html","hash":"c609e3033ec6f2c7a4ac557589d4caa1bd343dee","modified":1493847087775},{"_id":"public/http-performance-java-jersey-vs-go-vs-nodejs.html","hash":"f12476821a900f630dbe0430eb2d666beb8d1eb7","modified":1493847087775},{"_id":"public/my-teck-stack-if-i-had-to-build-an-app-today.html","hash":"d58d8e8640ad5a033eb5bedf854152071ad6a6ed","modified":1493847087775},{"_id":"public/how-to-load-yago-into-apache-jena-fuseki.html","hash":"8a5784b581dd497a651c8a8e54baa70f721965a0","modified":1493847087775},{"_id":"public/design-of-a-linked-data-enabled-microservice-platform-for-the-industrial-internet-of-things.html","hash":"048449e45a37c63dcb26e13405b8061e3e41cbd3","modified":1493847087775},{"_id":"public/webdevlistnet-the-developers-resource-collection.html","hash":"ff3a8a66042216a47f9d13ce72845d258521a3aa","modified":1493847087775},{"_id":"public/migrate-maildir-to-new-server-using-imapsync.html","hash":"c703698567db64ae023ea640fac3e764250d7240","modified":1493847087775},{"_id":"public/innovation-in-germany-not.html","hash":"8952d3273cb95463ab988f7f767f9d2ff52c67be","modified":1493847087775},{"_id":"public/telegram-expensebot-doodlerbot.html","hash":"05069dd6fcae2eb464fefda9f5a295b18e9d56cc","modified":1493847087775},{"_id":"public/unhostedorg-applications-with-remotestorageio-and-webfingernet.html","hash":"5571973f2d51b4643ad40535fd9202323fe4ae68","modified":1493847087775},{"_id":"public/how-do-whatsapps-end-to-end-encrypted-group-chats-work.html","hash":"70fb852afe0665592c2dab651c09e46eec0aebc0","modified":1493847087776},{"_id":"public/digitalocean-my-preferred-cloud-hosting-provider.html","hash":"d7b95ab6e6966883f5fa4f83e2f58b53b5e00562","modified":1493847087776},{"_id":"public/learning-angular2-what-is-new.html","hash":"e9651524ef24c31bcd89bd034529799086c9c4fb","modified":1493847087776},{"_id":"public/anchr-io-image-uploads-bookmarks-and-shortlink-service.html","hash":"697a8547384df9b43de4d73593ce60da69908a9f","modified":1493847087776},{"_id":"public/why-raid-10-is-better-than-raid-01.html","hash":"0fe0913c2b02ad89b6e158dbcd84d8e4b7c88746","modified":1493847087780},{"_id":"public/how-to-make-telegram-bots.html","hash":"f7cc5b834293b723815b22c0860523a306555e92","modified":1493847087780}],"Category":[],"Data":[],"Page":[{"title":"about","date":"2017-05-03T20:21:16.000Z","_content":"\nHey, welcome and thank you for visiting my webpage! My name is Ferdinand Mütsch, I’m 22 years young and currently living in Karlsruhe, Germany. I’m studying [information economics](http://informationswirtschaft.org) which basically is a mixture of 40 % computer science, 40 % economics and 20 % law – at the [Karlsruhe Institute of Technology](http://kit.edu). I just finished my bachelor's thesis at [TECO](http://teco.edu) and now I'm in the first master semester. I’m about to graduate as a Master Of Science by the end of 2018.\n\nMy interests are – among others – software development, especially in a web- and mobile context. Additionally I'm also interested in operations, because of which I'm running my own little virtual server to host my applications, webpages and e-mails. I consider myself pretty open-minded and I’m continuously interested in new technology. Currently I’m teaching myself the Golang.\n\nCurrently I'm working as a student employee at [Inovex](http://inovex.de) in Karlsruhe, which is a great place to improve my skills and learn about new things literally every day.\n\nTo drop some buzzword here are a few technologies I'm experienced at.\n\nJavaScript, ECMAScript 2015, [TypeScript](https://www.typescriptlang.org/), [Node.js](http://nodejs.org), [ExpressJS](http://expressjs.com/), [Pug](https://pugjs.org/api/getting-started.html), [LoopbackJS](http://loopback.io), [AngularJS](https://angularjs.org/\n), [Angular2](http://angular.io), [Ionic](http://ionicframework.com/\n), [Cordova](https://cordova.apache.org/\n), [Selenium](http://www.seleniumhq.org/), [Protractor](http://www.protractortest.org/\n), Java, JUnit, [Spring Boot](http://projects.spring.io/spring-boot/), Android, PHP, PHPUnit, [Slim MVC Framework](http://www.slimframework.com/), [Go](http://golang.org), [Docker](http://docker.com/), MongoDB, SQL, SPARQL, [Linked Data](linked_data.html), Semantic Web\n\nIf you’re interested in some of my private software projects, check out the [Projects section](/projects.html) or take a look at [my profile on GitHub](https://github.com/n1try). Please also take a look at my [Xing profile](https://www.xing.com/profile/Ferdinand_Muetsch).","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-05-03 22:21:16\n---\n\nHey, welcome and thank you for visiting my webpage! My name is Ferdinand Mütsch, I’m 22 years young and currently living in Karlsruhe, Germany. I’m studying [information economics](http://informationswirtschaft.org) which basically is a mixture of 40 % computer science, 40 % economics and 20 % law – at the [Karlsruhe Institute of Technology](http://kit.edu). I just finished my bachelor's thesis at [TECO](http://teco.edu) and now I'm in the first master semester. I’m about to graduate as a Master Of Science by the end of 2018.\n\nMy interests are – among others – software development, especially in a web- and mobile context. Additionally I'm also interested in operations, because of which I'm running my own little virtual server to host my applications, webpages and e-mails. I consider myself pretty open-minded and I’m continuously interested in new technology. Currently I’m teaching myself the Golang.\n\nCurrently I'm working as a student employee at [Inovex](http://inovex.de) in Karlsruhe, which is a great place to improve my skills and learn about new things literally every day.\n\nTo drop some buzzword here are a few technologies I'm experienced at.\n\nJavaScript, ECMAScript 2015, [TypeScript](https://www.typescriptlang.org/), [Node.js](http://nodejs.org), [ExpressJS](http://expressjs.com/), [Pug](https://pugjs.org/api/getting-started.html), [LoopbackJS](http://loopback.io), [AngularJS](https://angularjs.org/\n), [Angular2](http://angular.io), [Ionic](http://ionicframework.com/\n), [Cordova](https://cordova.apache.org/\n), [Selenium](http://www.seleniumhq.org/), [Protractor](http://www.protractortest.org/\n), Java, JUnit, [Spring Boot](http://projects.spring.io/spring-boot/), Android, PHP, PHPUnit, [Slim MVC Framework](http://www.slimframework.com/), [Go](http://golang.org), [Docker](http://docker.com/), MongoDB, SQL, SPARQL, [Linked Data](linked_data.html), Semantic Web\n\nIf you’re interested in some of my private software projects, check out the [Projects section](/projects.html) or take a look at [my profile on GitHub](https://github.com/n1try). Please also take a look at my [Xing profile](https://www.xing.com/profile/Ferdinand_Muetsch).","updated":"2017-05-03T20:29:33.836Z","path":"about/index.html","_id":"cj29fh8ad0001owqgre2cjibn","comments":1,"layout":"page","content":"<p>Hey, welcome and thank you for visiting my webpage! My name is Ferdinand Mütsch, I’m 22 years young and currently living in Karlsruhe, Germany. I’m studying <a href=\"http://informationswirtschaft.org\" target=\"_blank\" rel=\"external\">information economics</a> which basically is a mixture of 40 % computer science, 40 % economics and 20 % law – at the <a href=\"http://kit.edu\" target=\"_blank\" rel=\"external\">Karlsruhe Institute of Technology</a>. I just finished my bachelor’s thesis at <a href=\"http://teco.edu\" target=\"_blank\" rel=\"external\">TECO</a> and now I’m in the first master semester. I’m about to graduate as a Master Of Science by the end of 2018.</p>\n<p>My interests are – among others – software development, especially in a web- and mobile context. Additionally I’m also interested in operations, because of which I’m running my own little virtual server to host my applications, webpages and e-mails. I consider myself pretty open-minded and I’m continuously interested in new technology. Currently I’m teaching myself the Golang.</p>\n<p>Currently I’m working as a student employee at <a href=\"http://inovex.de\" target=\"_blank\" rel=\"external\">Inovex</a> in Karlsruhe, which is a great place to improve my skills and learn about new things literally every day.</p>\n<p>To drop some buzzword here are a few technologies I’m experienced at.</p>\n<p>JavaScript, ECMAScript 2015, <a href=\"https://www.typescriptlang.org/\" target=\"_blank\" rel=\"external\">TypeScript</a>, <a href=\"http://nodejs.org\" target=\"_blank\" rel=\"external\">Node.js</a>, <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"external\">ExpressJS</a>, <a href=\"https://pugjs.org/api/getting-started.html\" target=\"_blank\" rel=\"external\">Pug</a>, <a href=\"http://loopback.io\" target=\"_blank\" rel=\"external\">LoopbackJS</a>, <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"external\">AngularJS</a>, <a href=\"http://angular.io\" target=\"_blank\" rel=\"external\">Angular2</a>, <a href=\"http://ionicframework.com/\" target=\"_blank\" rel=\"external\">Ionic</a>, <a href=\"https://cordova.apache.org/\" target=\"_blank\" rel=\"external\">Cordova</a>, <a href=\"http://www.seleniumhq.org/\" target=\"_blank\" rel=\"external\">Selenium</a>, <a href=\"http://www.protractortest.org/\" target=\"_blank\" rel=\"external\">Protractor</a>, Java, JUnit, <a href=\"http://projects.spring.io/spring-boot/\" target=\"_blank\" rel=\"external\">Spring Boot</a>, Android, PHP, PHPUnit, <a href=\"http://www.slimframework.com/\" target=\"_blank\" rel=\"external\">Slim MVC Framework</a>, <a href=\"http://golang.org\" target=\"_blank\" rel=\"external\">Go</a>, <a href=\"http://docker.com/\" target=\"_blank\" rel=\"external\">Docker</a>, MongoDB, SQL, SPARQL, <a href=\"linked_data.html\">Linked Data</a>, Semantic Web</p>\n<p>If you’re interested in some of my private software projects, check out the <a href=\"/projects.html\">Projects section</a> or take a look at <a href=\"https://github.com/n1try\" target=\"_blank\" rel=\"external\">my profile on GitHub</a>. Please also take a look at my <a href=\"https://www.xing.com/profile/Ferdinand_Muetsch\" target=\"_blank\" rel=\"external\">Xing profile</a>.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Hey, welcome and thank you for visiting my webpage! My name is Ferdinand Mütsch, I’m 22 years young and currently living in Karlsruhe, Germany. I’m studying <a href=\"http://informationswirtschaft.org\" target=\"_blank\" rel=\"external\">information economics</a> which basically is a mixture of 40 % computer science, 40 % economics and 20 % law – at the <a href=\"http://kit.edu\" target=\"_blank\" rel=\"external\">Karlsruhe Institute of Technology</a>. I just finished my bachelor’s thesis at <a href=\"http://teco.edu\" target=\"_blank\" rel=\"external\">TECO</a> and now I’m in the first master semester. I’m about to graduate as a Master Of Science by the end of 2018.</p>\n<p>My interests are – among others – software development, especially in a web- and mobile context. Additionally I’m also interested in operations, because of which I’m running my own little virtual server to host my applications, webpages and e-mails. I consider myself pretty open-minded and I’m continuously interested in new technology. Currently I’m teaching myself the Golang.</p>\n<p>Currently I’m working as a student employee at <a href=\"http://inovex.de\" target=\"_blank\" rel=\"external\">Inovex</a> in Karlsruhe, which is a great place to improve my skills and learn about new things literally every day.</p>\n<p>To drop some buzzword here are a few technologies I’m experienced at.</p>\n<p>JavaScript, ECMAScript 2015, <a href=\"https://www.typescriptlang.org/\" target=\"_blank\" rel=\"external\">TypeScript</a>, <a href=\"http://nodejs.org\" target=\"_blank\" rel=\"external\">Node.js</a>, <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"external\">ExpressJS</a>, <a href=\"https://pugjs.org/api/getting-started.html\" target=\"_blank\" rel=\"external\">Pug</a>, <a href=\"http://loopback.io\" target=\"_blank\" rel=\"external\">LoopbackJS</a>, <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"external\">AngularJS</a>, <a href=\"http://angular.io\" target=\"_blank\" rel=\"external\">Angular2</a>, <a href=\"http://ionicframework.com/\" target=\"_blank\" rel=\"external\">Ionic</a>, <a href=\"https://cordova.apache.org/\" target=\"_blank\" rel=\"external\">Cordova</a>, <a href=\"http://www.seleniumhq.org/\" target=\"_blank\" rel=\"external\">Selenium</a>, <a href=\"http://www.protractortest.org/\" target=\"_blank\" rel=\"external\">Protractor</a>, Java, JUnit, <a href=\"http://projects.spring.io/spring-boot/\" target=\"_blank\" rel=\"external\">Spring Boot</a>, Android, PHP, PHPUnit, <a href=\"http://www.slimframework.com/\" target=\"_blank\" rel=\"external\">Slim MVC Framework</a>, <a href=\"http://golang.org\" target=\"_blank\" rel=\"external\">Go</a>, <a href=\"http://docker.com/\" target=\"_blank\" rel=\"external\">Docker</a>, MongoDB, SQL, SPARQL, <a href=\"linked_data.html\">Linked Data</a>, Semantic Web</p>\n<p>If you’re interested in some of my private software projects, check out the <a href=\"/projects.html\">Projects section</a> or take a look at <a href=\"https://github.com/n1try\" target=\"_blank\" rel=\"external\">my profile on GitHub</a>. Please also take a look at my <a href=\"https://www.xing.com/profile/Ferdinand_Muetsch\" target=\"_blank\" rel=\"external\">Xing profile</a>.</p>\n"},{"title":"imprint","date":"2017-05-03T20:30:32.000Z","_content":"\n### Legal Disclosure & Privacy Statement\nInformation in accordance with section 5 German TMG\n\n```\nFerdinand Mütsch\nVorholzstraße 11 \n76137 Karlsruhe\nGermany\n```\n\n### Contact\n```\nTelephone: +49629361314\nE-Mail: mail@ferdinand-muetsch.de\nWeb: www.ferdinand-muetsch.de\n```\n\n### Disclaimer\n#### Accountability for content\nThe contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).\n\n#### Accountability for links\nResponsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. \n\n#### Copyright\nOur web pages and their contents are subject to German copyright law. Unless expressly permitted by law (§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (§ 106 of the copyright law).\n\n#### General\nYour personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.\n\n#### Inventory data\n(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods. \n(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.\n\n#### Information about cookies\n(1) To optimize our web presence, we use cookies. These are small text files stored in your computer's main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.\n(2) You can prevent storage of cookies by choosing a \"disable cookies\" option in your browser settings. But this can limit the functionality of our Internet offers as a result.\n\n#### Disclosure\nAccording to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( [mail@ferdinand-muetsch.de](mailto:mail@ferdinand-muetsch.de) )\n\nSource: [twiggs translations](http://www.twigg.de/)\n","source":"imprint/index.md","raw":"---\ntitle: imprint\ndate: 2017-05-03 22:30:32\n---\n\n### Legal Disclosure & Privacy Statement\nInformation in accordance with section 5 German TMG\n\n```\nFerdinand Mütsch\nVorholzstraße 11 \n76137 Karlsruhe\nGermany\n```\n\n### Contact\n```\nTelephone: +49629361314\nE-Mail: mail@ferdinand-muetsch.de\nWeb: www.ferdinand-muetsch.de\n```\n\n### Disclaimer\n#### Accountability for content\nThe contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).\n\n#### Accountability for links\nResponsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. \n\n#### Copyright\nOur web pages and their contents are subject to German copyright law. Unless expressly permitted by law (§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (§ 106 of the copyright law).\n\n#### General\nYour personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.\n\n#### Inventory data\n(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods. \n(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.\n\n#### Information about cookies\n(1) To optimize our web presence, we use cookies. These are small text files stored in your computer's main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.\n(2) You can prevent storage of cookies by choosing a \"disable cookies\" option in your browser settings. But this can limit the functionality of our Internet offers as a result.\n\n#### Disclosure\nAccording to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( [mail@ferdinand-muetsch.de](mailto:mail@ferdinand-muetsch.de) )\n\nSource: [twiggs translations](http://www.twigg.de/)\n","updated":"2017-05-03T20:30:43.049Z","path":"imprint/index.html","_id":"cj29ft5mn0000zsqgzm9cz5u7","comments":1,"layout":"page","content":"<h3 id=\"Legal-Disclosure-amp-Privacy-Statement\"><a href=\"#Legal-Disclosure-amp-Privacy-Statement\" class=\"headerlink\" title=\"Legal Disclosure &amp; Privacy Statement\"></a>Legal Disclosure &amp; Privacy Statement</h3><p>Information in accordance with section 5 German TMG</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">Ferdinand Mütsch</div><div class=\"line\">Vorholzstraße 11 </div><div class=\"line\">76137 Karlsruhe</div><div class=\"line\">Germany</div></pre></td></tr></table></figure>\n<h3 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Telephone: +49629361314</div><div class=\"line\">E-Mail: mail@ferdinand-muetsch.de</div><div class=\"line\">Web: www.ferdinand-muetsch.de</div></pre></td></tr></table></figure>\n<h3 id=\"Disclaimer\"><a href=\"#Disclaimer\" class=\"headerlink\" title=\"Disclaimer\"></a>Disclaimer</h3><h4 id=\"Accountability-for-content\"><a href=\"#Accountability-for-content\" class=\"headerlink\" title=\"Accountability for content\"></a>Accountability for content</h4><p>The contents of our pages have been created with the utmost care. However, we cannot guarantee the contents’ accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).</p>\n<h4 id=\"Accountability-for-links\"><a href=\"#Accountability-for-links\" class=\"headerlink\" title=\"Accountability for links\"></a>Accountability for links</h4><p>Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. </p>\n<h4 id=\"Copyright\"><a href=\"#Copyright\" class=\"headerlink\" title=\"Copyright\"></a>Copyright</h4><p>Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law (§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (§ 106 of the copyright law).</p>\n<h4 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h4><p>Your personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.</p>\n<h4 id=\"Inventory-data\"><a href=\"#Inventory-data\" class=\"headerlink\" title=\"Inventory data\"></a>Inventory data</h4><p>(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods.<br>(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.</p>\n<h4 id=\"Information-about-cookies\"><a href=\"#Information-about-cookies\" class=\"headerlink\" title=\"Information about cookies\"></a>Information about cookies</h4><p>(1) To optimize our web presence, we use cookies. These are small text files stored in your computer’s main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.<br>(2) You can prevent storage of cookies by choosing a “disable cookies” option in your browser settings. But this can limit the functionality of our Internet offers as a result.</p>\n<h4 id=\"Disclosure\"><a href=\"#Disclosure\" class=\"headerlink\" title=\"Disclosure\"></a>Disclosure</h4><p>According to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( <a href=\"mailto:mail@ferdinand-muetsch.de\">mail@ferdinand-muetsch.de</a> )</p>\n<p>Source: <a href=\"http://www.twigg.de/\" target=\"_blank\" rel=\"external\">twiggs translations</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Legal-Disclosure-amp-Privacy-Statement\"><a href=\"#Legal-Disclosure-amp-Privacy-Statement\" class=\"headerlink\" title=\"Legal Disclosure &amp; Privacy Statement\"></a>Legal Disclosure &amp; Privacy Statement</h3><p>Information in accordance with section 5 German TMG</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">Ferdinand Mütsch</div><div class=\"line\">Vorholzstraße 11 </div><div class=\"line\">76137 Karlsruhe</div><div class=\"line\">Germany</div></pre></td></tr></table></figure>\n<h3 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Telephone: +49629361314</div><div class=\"line\">E-Mail: mail@ferdinand-muetsch.de</div><div class=\"line\">Web: www.ferdinand-muetsch.de</div></pre></td></tr></table></figure>\n<h3 id=\"Disclaimer\"><a href=\"#Disclaimer\" class=\"headerlink\" title=\"Disclaimer\"></a>Disclaimer</h3><h4 id=\"Accountability-for-content\"><a href=\"#Accountability-for-content\" class=\"headerlink\" title=\"Accountability for content\"></a>Accountability for content</h4><p>The contents of our pages have been created with the utmost care. However, we cannot guarantee the contents’ accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this context, please note that we are accordingly not obliged to monitor merely the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).</p>\n<h4 id=\"Accountability-for-links\"><a href=\"#Accountability-for-links\" class=\"headerlink\" title=\"Accountability for links\"></a>Accountability for links</h4><p>Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately. </p>\n<h4 id=\"Copyright\"><a href=\"#Copyright\" class=\"headerlink\" title=\"Copyright\"></a>Copyright</h4><p>Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law (§ 44a et seq. of the copyright law), every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are allowed only for private use, so must not serve either directly or indirectly for earnings. Unauthorized utilization of copyrighted works is punishable (§ 106 of the copyright law).</p>\n<h4 id=\"General\"><a href=\"#General\" class=\"headerlink\" title=\"General\"></a>General</h4><p>Your personal data (e.g. title, name, house address, e-mail address, phone number, bank details, credit card number) are processed by us only in accordance with the provisions of German data privacy laws. The following provisions describe the type, scope and purpose of collecting, processing and utilizing personal data. This data privacy policy applies only to our web pages. If links on our pages route you to other pages, please inquire there about how your data are handled in such cases.</p>\n<h4 id=\"Inventory-data\"><a href=\"#Inventory-data\" class=\"headerlink\" title=\"Inventory data\"></a>Inventory data</h4><p>(1) Your personal data, insofar as these are necessary for this contractual relationship (inventory data) in terms of its establishment, organization of content and modifications, are used exclusively for fulfilling the contract. For goods to be delivered, for instance, your name and address must be relayed to the supplier of the goods.<br>(2) Without your explicit consent or a legal basis, your personal data are not passed on to third parties outside the scope of fulfilling this contract. After completion of the contract, your data are blocked against further use. After expiry of deadlines as per tax-related and commercial regulations, these data are deleted unless you have expressly consented to their further use.</p>\n<h4 id=\"Information-about-cookies\"><a href=\"#Information-about-cookies\" class=\"headerlink\" title=\"Information about cookies\"></a>Information about cookies</h4><p>(1) To optimize our web presence, we use cookies. These are small text files stored in your computer’s main memory. These cookies are deleted after you close the browser. Other cookies remain on your computer (long-term cookies) and permit its recognition on your next visit. This allows us to improve your access to our site.<br>(2) You can prevent storage of cookies by choosing a “disable cookies” option in your browser settings. But this can limit the functionality of our Internet offers as a result.</p>\n<h4 id=\"Disclosure\"><a href=\"#Disclosure\" class=\"headerlink\" title=\"Disclosure\"></a>Disclosure</h4><p>According to the Federal Data Protection Act, you have a right to free-of-charge information about your stored data, and possibly entitlement to correction, blocking or deletion of such data. Inquiries can be directed to the following e-mail addresses: ( <a href=\"mailto:mail@ferdinand-muetsch.de\">mail@ferdinand-muetsch.de</a> )</p>\n<p>Source: <a href=\"http://www.twigg.de/\" target=\"_blank\" rel=\"external\">twiggs translations</a></p>\n"}],"Post":[{"title":"Linux - Cache information bash script","date":"2015-02-27T21:31:53.000Z","_content":"\nThis is a little bash script to get the CPU cache ratios on Ubuntu.\n\n```\nCache Level: (1, 2 or 3)\nCache Type: (data-, instruction or general cache)\nCapacity: of the respective cache\nAssociativity: (set size)\nBlock capacity: / capacity of a cache line\nNumber of sets: ((total capacity / block capacity) / associativity)\n```\n\nConcerning the associativity, see [https://en.wikipedia.org/wiki/CPU_cache#Associativity](https://en.wikipedia.org/wiki/CPU_cache#Associativity).\n\n```bash\nfor DIR0 in /sys/devices/system/cpu/cpu0/cache/*\n    do\n        LEVEL0=$(sudo cat $DIR0\\/level)\n        TYPE0=$(sudo cat $DIR0\\/type)\n        SIZE0=$(sudo cat $DIR0\\/size)\n        ASSOC0=$(sudo cat $DIR0\\/ways_of_associativity)\n        BLOCK0=$(sudo cat $DIR0\\/coherency_line_size)\n        SETS0=$(sudo cat $DIR0\\/number_of_sets)\n\n        printf &quot;Cache level: %s\\nCache type: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&quot; &quot;$LEVEL0&quot; &quot;$TYPE0&quot; &quot;$SIZE0&quot; &quot;$ASSOC0&quot; &quot;$SETS0&quot; &quot;$BLOCK0&quot;\ndone\n```\n\n**Usage:**\n\n1.  Save code to file, e.g. _~/cacheinfo.sh_\n2.  Make it executable: _chmod +x cacheinfo.sh_\n3.  Execute: _sudo sh cacheinfo.sh_","source":"_posts/linux-cache-information-bash-script.md","raw":"---\ntitle: Linux - Cache information bash script\ndate: 2015-02-27 22:31:53\ntags:\n---\n\nThis is a little bash script to get the CPU cache ratios on Ubuntu.\n\n```\nCache Level: (1, 2 or 3)\nCache Type: (data-, instruction or general cache)\nCapacity: of the respective cache\nAssociativity: (set size)\nBlock capacity: / capacity of a cache line\nNumber of sets: ((total capacity / block capacity) / associativity)\n```\n\nConcerning the associativity, see [https://en.wikipedia.org/wiki/CPU_cache#Associativity](https://en.wikipedia.org/wiki/CPU_cache#Associativity).\n\n```bash\nfor DIR0 in /sys/devices/system/cpu/cpu0/cache/*\n    do\n        LEVEL0=$(sudo cat $DIR0\\/level)\n        TYPE0=$(sudo cat $DIR0\\/type)\n        SIZE0=$(sudo cat $DIR0\\/size)\n        ASSOC0=$(sudo cat $DIR0\\/ways_of_associativity)\n        BLOCK0=$(sudo cat $DIR0\\/coherency_line_size)\n        SETS0=$(sudo cat $DIR0\\/number_of_sets)\n\n        printf &quot;Cache level: %s\\nCache type: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&quot; &quot;$LEVEL0&quot; &quot;$TYPE0&quot; &quot;$SIZE0&quot; &quot;$ASSOC0&quot; &quot;$SETS0&quot; &quot;$BLOCK0&quot;\ndone\n```\n\n**Usage:**\n\n1.  Save code to file, e.g. _~/cacheinfo.sh_\n2.  Make it executable: _chmod +x cacheinfo.sh_\n3.  Execute: _sudo sh cacheinfo.sh_","slug":"linux-cache-information-bash-script","published":1,"updated":"2017-05-03T20:39:30.000Z","_id":"cj29g4oj70002qkqggi8nl9rj","comments":1,"layout":"post","photos":[],"link":"","content":"<p>This is a little bash script to get the CPU cache ratios on Ubuntu.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Cache Level: (1, 2 or 3)</div><div class=\"line\">Cache Type: (data-, instruction or general cache)</div><div class=\"line\">Capacity: of the respective cache</div><div class=\"line\">Associativity: (set size)</div><div class=\"line\">Block capacity: / capacity of a cache line</div><div class=\"line\">Number of sets: ((total capacity / block capacity) / associativity)</div></pre></td></tr></table></figure>\n<p>Concerning the associativity, see <a href=\"https://en.wikipedia.org/wiki/CPU_cache#Associativity\" target=\"_blank\" rel=\"external\">https://en.wikipedia.org/wiki/CPU_cache#Associativity</a>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> DIR0 <span class=\"keyword\">in</span> /sys/devices/system/cpu/cpu0/cache/*</div><div class=\"line\">    <span class=\"keyword\">do</span></div><div class=\"line\">        LEVEL0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/level)</div><div class=\"line\">        TYPE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/<span class=\"built_in\">type</span>)</div><div class=\"line\">        SIZE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/size)</div><div class=\"line\">        ASSOC0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/ways_of_associativity)</div><div class=\"line\">        BLOCK0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/coherency_line_size)</div><div class=\"line\">        SETS0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/number_of_sets)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"built_in\">printf</span> &amp;quot;Cache level: %s\\nCache <span class=\"built_in\">type</span>: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&amp;quot; &amp;quot;<span class=\"variable\">$LEVEL0</span>&amp;quot; &amp;quot;<span class=\"variable\">$TYPE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SIZE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$ASSOC0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SETS0</span>&amp;quot; &amp;quot;<span class=\"variable\">$BLOCK0</span>&amp;quot;</div><div class=\"line\"><span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<p><strong>Usage:</strong></p>\n<ol>\n<li>Save code to file, e.g. <em>~/cacheinfo.sh</em></li>\n<li>Make it executable: <em>chmod +x cacheinfo.sh</em></li>\n<li>Execute: <em>sudo sh cacheinfo.sh</em></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>This is a little bash script to get the CPU cache ratios on Ubuntu.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Cache Level: (1, 2 or 3)</div><div class=\"line\">Cache Type: (data-, instruction or general cache)</div><div class=\"line\">Capacity: of the respective cache</div><div class=\"line\">Associativity: (set size)</div><div class=\"line\">Block capacity: / capacity of a cache line</div><div class=\"line\">Number of sets: ((total capacity / block capacity) / associativity)</div></pre></td></tr></table></figure>\n<p>Concerning the associativity, see <a href=\"https://en.wikipedia.org/wiki/CPU_cache#Associativity\" target=\"_blank\" rel=\"external\">https://en.wikipedia.org/wiki/CPU_cache#Associativity</a>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> DIR0 <span class=\"keyword\">in</span> /sys/devices/system/cpu/cpu0/cache/*</div><div class=\"line\">    <span class=\"keyword\">do</span></div><div class=\"line\">        LEVEL0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/level)</div><div class=\"line\">        TYPE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/<span class=\"built_in\">type</span>)</div><div class=\"line\">        SIZE0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/size)</div><div class=\"line\">        ASSOC0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/ways_of_associativity)</div><div class=\"line\">        BLOCK0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/coherency_line_size)</div><div class=\"line\">        SETS0=$(sudo cat <span class=\"variable\">$DIR0</span>\\/number_of_sets)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"built_in\">printf</span> &amp;quot;Cache level: %s\\nCache <span class=\"built_in\">type</span>: %s\\nCapacity: %s Bytes\\nAssociativity: %s\\nSets: %s\\nBlock size: %s Bytes\\n\\n&amp;quot; &amp;quot;<span class=\"variable\">$LEVEL0</span>&amp;quot; &amp;quot;<span class=\"variable\">$TYPE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SIZE0</span>&amp;quot; &amp;quot;<span class=\"variable\">$ASSOC0</span>&amp;quot; &amp;quot;<span class=\"variable\">$SETS0</span>&amp;quot; &amp;quot;<span class=\"variable\">$BLOCK0</span>&amp;quot;</div><div class=\"line\"><span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<p><strong>Usage:</strong></p>\n<ol>\n<li>Save code to file, e.g. <em>~/cacheinfo.sh</em></li>\n<li>Make it executable: <em>chmod +x cacheinfo.sh</em></li>\n<li>Execute: <em>sudo sh cacheinfo.sh</em></li>\n</ol>\n"},{"title":"How to make Telegram Bots","date":"2015-06-28T20:39:44.000Z","_content":"\nRecently [Telegram](http://telegram.org \"Telegram\") has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todo’s or even a little text based game – everything within the Telegram chat. The nice thing about them is that they’re really simple to create. You can read more about the bots in general here: [https://telegram.org/blog/bot-revolution](https://telegram.org/blog/bot-revolution)\n\nThis article shouldn’t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality – its backend. On how to initially set up one, please refer to this little guide: [https://core.telegram.org/bots](https://core.telegram.org/bots). It’s very easy, trust me. Everything you need for that is your Telegram app.\n\nWhat you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, [this](https://core.telegram.org/bots/api \"this\") page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.\n\nFirst some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram won’t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesn’t provide more than kind of an interface between your users’ Telegram client (app) and your bot application. The flow would be like:\n\n1.  You create a new bot with @BotFather and set its description and commands (the commands you set there are – strictly speaking – completely independent of which commands your program will actually accept – they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.\n\n2.  You write the backend and run it to be listening.\n\n3.  A user sends a message to your bot.\n\n4.  The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.\n\n5.  Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.\n\n6.  Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).\n\n7.  Telegram shows the message to your user’s chat window.\n\nAlright, now let’s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who don’t understand JavaScript too well, I’ll try to explain everything as clear as you need to re-do this in your programming language.\n\nFirst, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js we’ll use the [Unirest](http://unirest.io/nodejs.html \"Unirest\") library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.\n\nSo first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and you’re familiar with npm).\n\n```javascript\n/* app.js */\n\nvar unirest = require('unirest');\n```\n\nNext is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that you’re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram won’t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend won’t do request after request after request (because this would be so inefficient!) but use [long polling](http://www.pubnub.com/blog/http-long-polling/ \"long polling\"). To put it simple long polling means that a request won’t be answered instantly, but kept open until there is some data available.\n\nWe need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the [getUpdates](https://core.telegram.org/bots/api#getupdates \"getUpdates\") method endpoint and the URL for the [sendMessage](https://core.telegram.org/bots/api#sendmessage \"sendMessage\") method endpoint. The *:offset:* within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.\n\n```javascript\n/* app.js */\n\n/* ... */\n\nvar BASE_URL = \"https://api.telegram.org/botYOUR_TOKEN_HERE/\";\nvar POLLING_URL = BASE_URL + \"getUpdates?offset=:offset:&timeout=60\";\nvar SEND_MESSAGE_URL = BASE_URL + \"sendMessage\";\n```\n\nNow we’ll introduce a function called *poll* (you can choose any other name), which basically is kind of the main loop of our program. Here’s the code for this method, explanation follows.\n\n```javascript\n/* ... */\nfunction poll(offset) {\n    var url = POLLING_URL.replace(\":offset:\", offset);\n\n    unirest.get(url)\n        .end(function(response) {\n            var body = response.raw_body;\n            if (response.status == 200) {\n                var jsonData = JSON.parse(body);\n                var result = jsonData.result;\n\n                if (result.length > 0) {\n                    for (i in result) {\n                        if (runCommand(result[i].message)) continue;\n                    }\n\n                    max_offset = parseInt(result[result.length - 1].update_id) + 1; // update max offset\n                }\n                poll(max_offset);\n            }\n        });\n};\n```\n\nAlright. The function is recursive, meaning it will call itself – namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the *:offset:* placeholder in the url string. To read more about this parameter, go to [https://core.telegram.org/bots/api#getupdates](https://core.telegram.org/bots/api#getupdates). Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an *ok* field and a *result* array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (i’ll give you the runCommand() function is a second…) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.\n\n```javascript\n/* ... */\n\nvar dosth = function(message) {\n    // to be implemented....\n}\n\nvar COMMANDS = {\n    \"dosth\" : dosth\n};\n```\n\nNow we specify a map, which maps strings (representing the users’ command input – in this case */dosth* to actual functions.\n\n```javascript\n    var msgtext = message.text;\n\n    if (msgtext.indexOf(\"/\") != 0) return false; // no slash at beginning?\n    var command = msgtext.substring(1, msgtext.indexOf(\" \"));\n    if (COMMANDS[command] == null) return false; // not a valid command?\n    COMMANDS[command](message);\n    return true;\n}\n```\n\nAnd this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didn’t get a valid command. We simply return here, but we also could send a message to the user telling him “Hey, please enter a valid command.”. But let’s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustn’t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.\n\nWhat have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.\n\nAll we still need is to implement the method belonging to the */dosth* command.\n\n```javascript\n    var caps = message.text.toUpperCase();\n    var answer = {\n        chat_id : message.chat.id,\n        text : \"You told be to do something, so I took your input and made it all caps. Look: \" + caps\n    };\n\n    unirest.post(SEND_MESSAGE_URL)\n        .send(answer)\n        .end(function (response) {\n            if (response.status == 200) console.log(\"Successfully sent message to \" + message.chat.id);\n        });\n}\n```\n\nMost times you’ll want to send a message as response to your user. You could also send an image, an audio, a location, … (see [https://core.telegram.org/bots/api#available-methods](https://core.telegram.org/bots/api#available-methods)). Every message object needs a *chat_id* field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message object’s chat object we received from the user. The second mandatory field in a message object is the *text*. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user – see [https://core.telegram.org/bots/api#message](https://core.telegram.org/bots/api#message) for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.\n\nThis example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine – with a Telegram chat as the text i/o interface. Please tell be your ideas – what would be a great bot?\n\nIf you like to try by bot, simply write a message to **@FavoriteBot** and share it to your friends, if you like it.\n\nIf you have any questions, contact me via mail to *mail(at)ferdinand-muetsch.de.*","source":"_posts/how-to-make-telegram-bots.md","raw":"---\ntitle: How to make Telegram Bots\ndate: 2015-06-28 22:39:44\ntags:\n---\n\nRecently [Telegram](http://telegram.org \"Telegram\") has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todo’s or even a little text based game – everything within the Telegram chat. The nice thing about them is that they’re really simple to create. You can read more about the bots in general here: [https://telegram.org/blog/bot-revolution](https://telegram.org/blog/bot-revolution)\n\nThis article shouldn’t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality – its backend. On how to initially set up one, please refer to this little guide: [https://core.telegram.org/bots](https://core.telegram.org/bots). It’s very easy, trust me. Everything you need for that is your Telegram app.\n\nWhat you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, [this](https://core.telegram.org/bots/api \"this\") page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.\n\nFirst some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram won’t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesn’t provide more than kind of an interface between your users’ Telegram client (app) and your bot application. The flow would be like:\n\n1.  You create a new bot with @BotFather and set its description and commands (the commands you set there are – strictly speaking – completely independent of which commands your program will actually accept – they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.\n\n2.  You write the backend and run it to be listening.\n\n3.  A user sends a message to your bot.\n\n4.  The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.\n\n5.  Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.\n\n6.  Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).\n\n7.  Telegram shows the message to your user’s chat window.\n\nAlright, now let’s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who don’t understand JavaScript too well, I’ll try to explain everything as clear as you need to re-do this in your programming language.\n\nFirst, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js we’ll use the [Unirest](http://unirest.io/nodejs.html \"Unirest\") library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.\n\nSo first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and you’re familiar with npm).\n\n```javascript\n/* app.js */\n\nvar unirest = require('unirest');\n```\n\nNext is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that you’re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram won’t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend won’t do request after request after request (because this would be so inefficient!) but use [long polling](http://www.pubnub.com/blog/http-long-polling/ \"long polling\"). To put it simple long polling means that a request won’t be answered instantly, but kept open until there is some data available.\n\nWe need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the [getUpdates](https://core.telegram.org/bots/api#getupdates \"getUpdates\") method endpoint and the URL for the [sendMessage](https://core.telegram.org/bots/api#sendmessage \"sendMessage\") method endpoint. The *:offset:* within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.\n\n```javascript\n/* app.js */\n\n/* ... */\n\nvar BASE_URL = \"https://api.telegram.org/botYOUR_TOKEN_HERE/\";\nvar POLLING_URL = BASE_URL + \"getUpdates?offset=:offset:&timeout=60\";\nvar SEND_MESSAGE_URL = BASE_URL + \"sendMessage\";\n```\n\nNow we’ll introduce a function called *poll* (you can choose any other name), which basically is kind of the main loop of our program. Here’s the code for this method, explanation follows.\n\n```javascript\n/* ... */\nfunction poll(offset) {\n    var url = POLLING_URL.replace(\":offset:\", offset);\n\n    unirest.get(url)\n        .end(function(response) {\n            var body = response.raw_body;\n            if (response.status == 200) {\n                var jsonData = JSON.parse(body);\n                var result = jsonData.result;\n\n                if (result.length > 0) {\n                    for (i in result) {\n                        if (runCommand(result[i].message)) continue;\n                    }\n\n                    max_offset = parseInt(result[result.length - 1].update_id) + 1; // update max offset\n                }\n                poll(max_offset);\n            }\n        });\n};\n```\n\nAlright. The function is recursive, meaning it will call itself – namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the *:offset:* placeholder in the url string. To read more about this parameter, go to [https://core.telegram.org/bots/api#getupdates](https://core.telegram.org/bots/api#getupdates). Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an *ok* field and a *result* array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (i’ll give you the runCommand() function is a second…) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.\n\n```javascript\n/* ... */\n\nvar dosth = function(message) {\n    // to be implemented....\n}\n\nvar COMMANDS = {\n    \"dosth\" : dosth\n};\n```\n\nNow we specify a map, which maps strings (representing the users’ command input – in this case */dosth* to actual functions.\n\n```javascript\n    var msgtext = message.text;\n\n    if (msgtext.indexOf(\"/\") != 0) return false; // no slash at beginning?\n    var command = msgtext.substring(1, msgtext.indexOf(\" \"));\n    if (COMMANDS[command] == null) return false; // not a valid command?\n    COMMANDS[command](message);\n    return true;\n}\n```\n\nAnd this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didn’t get a valid command. We simply return here, but we also could send a message to the user telling him “Hey, please enter a valid command.”. But let’s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustn’t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.\n\nWhat have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.\n\nAll we still need is to implement the method belonging to the */dosth* command.\n\n```javascript\n    var caps = message.text.toUpperCase();\n    var answer = {\n        chat_id : message.chat.id,\n        text : \"You told be to do something, so I took your input and made it all caps. Look: \" + caps\n    };\n\n    unirest.post(SEND_MESSAGE_URL)\n        .send(answer)\n        .end(function (response) {\n            if (response.status == 200) console.log(\"Successfully sent message to \" + message.chat.id);\n        });\n}\n```\n\nMost times you’ll want to send a message as response to your user. You could also send an image, an audio, a location, … (see [https://core.telegram.org/bots/api#available-methods](https://core.telegram.org/bots/api#available-methods)). Every message object needs a *chat_id* field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message object’s chat object we received from the user. The second mandatory field in a message object is the *text*. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user – see [https://core.telegram.org/bots/api#message](https://core.telegram.org/bots/api#message) for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.\n\nThis example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine – with a Telegram chat as the text i/o interface. Please tell be your ideas – what would be a great bot?\n\nIf you like to try by bot, simply write a message to **@FavoriteBot** and share it to your friends, if you like it.\n\nIf you have any questions, contact me via mail to *mail(at)ferdinand-muetsch.de.*","slug":"how-to-make-telegram-bots","published":1,"updated":"2017-05-03T20:40:55.791Z","_id":"cj29g4zem0003qkqg2d60k1v2","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Recently <a href=\"http://telegram.org\" title=\"Telegram\" target=\"_blank\" rel=\"external\">Telegram</a> has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todo’s or even a little text based game – everything within the Telegram chat. The nice thing about them is that they’re really simple to create. You can read more about the bots in general here: <a href=\"https://telegram.org/blog/bot-revolution\" target=\"_blank\" rel=\"external\">https://telegram.org/blog/bot-revolution</a></p>\n<p>This article shouldn’t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality – its backend. On how to initially set up one, please refer to this little guide: <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots</a>. It’s very easy, trust me. Everything you need for that is your Telegram app.</p>\n<p>What you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, <a href=\"https://core.telegram.org/bots/api\" title=\"this\" target=\"_blank\" rel=\"external\">this</a> page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.</p>\n<p>First some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram won’t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesn’t provide more than kind of an interface between your users’ Telegram client (app) and your bot application. The flow would be like:</p>\n<ol>\n<li><p>You create a new bot with @BotFather and set its description and commands (the commands you set there are – strictly speaking – completely independent of which commands your program will actually accept – they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.</p>\n</li>\n<li><p>You write the backend and run it to be listening.</p>\n</li>\n<li><p>A user sends a message to your bot.</p>\n</li>\n<li><p>The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.</p>\n</li>\n<li><p>Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.</p>\n</li>\n<li><p>Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).</p>\n</li>\n<li><p>Telegram shows the message to your user’s chat window.</p>\n</li>\n</ol>\n<p>Alright, now let’s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who don’t understand JavaScript too well, I’ll try to explain everything as clear as you need to re-do this in your programming language.</p>\n<p>First, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js we’ll use the <a href=\"http://unirest.io/nodejs.html\" title=\"Unirest\" target=\"_blank\" rel=\"external\">Unirest</a> library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.</p>\n<p>So first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and you’re familiar with npm).</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* app.js */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> unirest = <span class=\"built_in\">require</span>(<span class=\"string\">'unirest'</span>);</div></pre></td></tr></table></figure>\n<p>Next is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that you’re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram won’t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend won’t do request after request after request (because this would be so inefficient!) but use <a href=\"http://www.pubnub.com/blog/http-long-polling/\" title=\"long polling\" target=\"_blank\" rel=\"external\">long polling</a>. To put it simple long polling means that a request won’t be answered instantly, but kept open until there is some data available.</p>\n<p>We need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the <a href=\"https://core.telegram.org/bots/api#getupdates\" title=\"getUpdates\" target=\"_blank\" rel=\"external\">getUpdates</a> method endpoint and the URL for the <a href=\"https://core.telegram.org/bots/api#sendmessage\" title=\"sendMessage\" target=\"_blank\" rel=\"external\">sendMessage</a> method endpoint. The <em>:offset:</em> within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* app.js */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> BASE_URL = <span class=\"string\">\"https://api.telegram.org/botYOUR_TOKEN_HERE/\"</span>;</div><div class=\"line\"><span class=\"keyword\">var</span> POLLING_URL = BASE_URL + <span class=\"string\">\"getUpdates?offset=:offset:&amp;timeout=60\"</span>;</div><div class=\"line\"><span class=\"keyword\">var</span> SEND_MESSAGE_URL = BASE_URL + <span class=\"string\">\"sendMessage\"</span>;</div></pre></td></tr></table></figure>\n<p>Now we’ll introduce a function called <em>poll</em> (you can choose any other name), which basically is kind of the main loop of our program. Here’s the code for this method, explanation follows.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">poll</span>(<span class=\"params\">offset</span>) </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">var</span> url = POLLING_URL.replace(<span class=\"string\">\":offset:\"</span>, offset);</div><div class=\"line\"></div><div class=\"line\">    unirest.get(url)</div><div class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">response</span>) </span>&#123;</div><div class=\"line\">            <span class=\"keyword\">var</span> body = response.raw_body;</div><div class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) &#123;</div><div class=\"line\">                <span class=\"keyword\">var</span> jsonData = <span class=\"built_in\">JSON</span>.parse(body);</div><div class=\"line\">                <span class=\"keyword\">var</span> result = jsonData.result;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">if</span> (result.length &gt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">for</span> (i <span class=\"keyword\">in</span> result) &#123;</div><div class=\"line\">                        <span class=\"keyword\">if</span> (runCommand(result[i].message)) <span class=\"keyword\">continue</span>;</div><div class=\"line\">                    &#125;</div><div class=\"line\"></div><div class=\"line\">                    max_offset = <span class=\"built_in\">parseInt</span>(result[result.length - <span class=\"number\">1</span>].update_id) + <span class=\"number\">1</span>; <span class=\"comment\">// update max offset</span></div><div class=\"line\">                &#125;</div><div class=\"line\">                poll(max_offset);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Alright. The function is recursive, meaning it will call itself – namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the <em>:offset:</em> placeholder in the url string. To read more about this parameter, go to <a href=\"https://core.telegram.org/bots/api#getupdates\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#getupdates</a>. Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an <em>ok</em> field and a <em>result</em> array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (i’ll give you the runCommand() function is a second…) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> dosth = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">message</span>) </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// to be implemented....</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> COMMANDS = &#123;</div><div class=\"line\">    <span class=\"string\">\"dosth\"</span> : dosth</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Now we specify a map, which maps strings (representing the users’ command input – in this case <em>/dosth</em> to actual functions.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">    <span class=\"keyword\">var</span> msgtext = message.text;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> (msgtext.indexOf(<span class=\"string\">\"/\"</span>) != <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// no slash at beginning?</span></div><div class=\"line\">    <span class=\"keyword\">var</span> command = msgtext.substring(<span class=\"number\">1</span>, msgtext.indexOf(<span class=\"string\">\" \"</span>));</div><div class=\"line\">    <span class=\"keyword\">if</span> (COMMANDS[command] == <span class=\"literal\">null</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// not a valid command?</span></div><div class=\"line\">    COMMANDS[command](message);</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>And this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didn’t get a valid command. We simply return here, but we also could send a message to the user telling him “Hey, please enter a valid command.”. But let’s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustn’t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.</p>\n<p>What have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.</p>\n<p>All we still need is to implement the method belonging to the <em>/dosth</em> command.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">    <span class=\"keyword\">var</span> caps = message.text.toUpperCase();</div><div class=\"line\">    <span class=\"keyword\">var</span> answer = &#123;</div><div class=\"line\">        <span class=\"attr\">chat_id</span> : message.chat.id,</div><div class=\"line\">        <span class=\"attr\">text</span> : <span class=\"string\">\"You told be to do something, so I took your input and made it all caps. Look: \"</span> + caps</div><div class=\"line\">    &#125;;</div><div class=\"line\"></div><div class=\"line\">    unirest.post(SEND_MESSAGE_URL)</div><div class=\"line\">        .send(answer)</div><div class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">response</span>) </span>&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) <span class=\"built_in\">console</span>.log(<span class=\"string\">\"Successfully sent message to \"</span> + message.chat.id);</div><div class=\"line\">        &#125;);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Most times you’ll want to send a message as response to your user. You could also send an image, an audio, a location, … (see <a href=\"https://core.telegram.org/bots/api#available-methods\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#available-methods</a>). Every message object needs a <em>chat_id</em> field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message object’s chat object we received from the user. The second mandatory field in a message object is the <em>text</em>. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user – see <a href=\"https://core.telegram.org/bots/api#message\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#message</a> for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.</p>\n<p>This example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine – with a Telegram chat as the text i/o interface. Please tell be your ideas – what would be a great bot?</p>\n<p>If you like to try by bot, simply write a message to <strong>@FavoriteBot</strong> and share it to your friends, if you like it.</p>\n<p>If you have any questions, contact me via mail to <em>mail(at)ferdinand-muetsch.de.</em></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Recently <a href=\"http://telegram.org\" title=\"Telegram\" target=\"_blank\" rel=\"external\">Telegram</a> has introduced a new feature, the bots. Basically the bots enable human Telegram users to talk to machines, i.e. customly written little programs. A bot could be a daily helper, be it a bot that you can ask for the current temperature, one that googles something for you, one to manage your todo’s or even a little text based game – everything within the Telegram chat. The nice thing about them is that they’re really simple to create. You can read more about the bots in general here: <a href=\"https://telegram.org/blog/bot-revolution\" target=\"_blank\" rel=\"external\">https://telegram.org/blog/bot-revolution</a></p>\n<p>This article shouldn’t cover how to create and publish a bot (which actually is the same step), but how to write its actual functionality – its backend. On how to initially set up one, please refer to this little guide: <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots</a>. It’s very easy, trust me. Everything you need for that is your Telegram app.</p>\n<p>What you need further to program your bot basically is a favorite programming language, an IDE or at least a text editor, <a href=\"https://core.telegram.org/bots/api\" title=\"this\" target=\"_blank\" rel=\"external\">this</a> page to be open and again your app. In this tutorial we will use Node.js as programming language (or more precisely as programming platform), but you really could use any other language, as well. Probably Python or PHP would do the job well, but you could even write a Java application.</p>\n<p>First some basic things to understand. For the most parts your bot is your own application which we will try to create here, running on your own local PC or server. Telegram won’t host any code. All functionality and data storage is kept in your program on your machine. Basically Telegram doesn’t provide more than kind of an interface between your users’ Telegram client (app) and your bot application. The flow would be like:</p>\n<ol>\n<li><p>You create a new bot with @BotFather and set its description and commands (the commands you set there are – strictly speaking – completely independent of which commands your program will actually accept – they are just strings which the user gets suggested in a chat with your bot) so that the bot gets publicly accessible as any other (human) Telegram user is via her @ nickname.</p>\n</li>\n<li><p>You write the backend and run it to be listening.</p>\n</li>\n<li><p>A user sends a message to your bot.</p>\n</li>\n<li><p>The (JSON formatted) Telegram message object gets passed to your backend via HTTPS by Telegram.</p>\n</li>\n<li><p>Your backend parses the message text, extract the commands and arguments, processes some logic, possibly does some database actions and so on.</p>\n</li>\n<li><p>Your backend passes a response message object to the Telegram API via HTTPS (the other way round now).</p>\n</li>\n<li><p>Telegram shows the message to your user’s chat window.</p>\n</li>\n</ol>\n<p>Alright, now let’s get into the code. I require you to already have set up a bot and got its authentication token (all using @BotFather). As I said, we will make a little Node.js program here, but for those who don’t understand JavaScript too well, I’ll try to explain everything as clear as you need to re-do this in your programming language.</p>\n<p>First, you need any library that can do HTTP requests, because basically your backend will be busy doing POSTs and GETs for the most time. For Node.js we’ll use the <a href=\"http://unirest.io/nodejs.html\" title=\"Unirest\" target=\"_blank\" rel=\"external\">Unirest</a> library, which probably is a little bit overkill, but very simple for our purpose. The library is available for Python, PHP, Ruby, Java and many others as well.</p>\n<p>So first step is setting up a Node application and requiring Unirest (i assume you know how to set up a Node application and you’re familiar with npm).</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* app.js */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> unirest = <span class=\"built_in\">require</span>(<span class=\"string\">'unirest'</span>);</div></pre></td></tr></table></figure>\n<p>Next is to receive messages from your users. Telegram offers two ways to do this. The first way would be to use Webhooks, which basically means that you’re backend runs on a webserver (or for Node it actually is one itself), Telegram knows your HTTPS endpoint and does a request to your backend every time a message is sent by a user. I would consider this the more elegant way. But the minus about this is that you would need to have a valid SSL certificate (which costs monthly charge) to provide a secure HTTPS connection. Telegram won’t send any data to an unsecure or unverified endpoint. This is why we will take the other approach, which works kind of the other way round. Your backend will continuously request the Telegram API if there are new messages available. In detail your backend won’t do request after request after request (because this would be so inefficient!) but use <a href=\"http://www.pubnub.com/blog/http-long-polling/\" title=\"long polling\" target=\"_blank\" rel=\"external\">long polling</a>. To put it simple long polling means that a request won’t be answered instantly, but kept open until there is some data available.</p>\n<p>We need to specify some constants. As i said, everything between your backend and Telegram happens via their HTTPS interface. We set up constants for the base API url, containing your bot token, the URL for the <a href=\"https://core.telegram.org/bots/api#getupdates\" title=\"getUpdates\" target=\"_blank\" rel=\"external\">getUpdates</a> method endpoint and the URL for the <a href=\"https://core.telegram.org/bots/api#sendmessage\" title=\"sendMessage\" target=\"_blank\" rel=\"external\">sendMessage</a> method endpoint. The <em>:offset:</em> within the URL string will get replaced by a number, specifying, which new messages to fetch from Telegram later.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* app.js */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> BASE_URL = <span class=\"string\">\"https://api.telegram.org/botYOUR_TOKEN_HERE/\"</span>;</div><div class=\"line\"><span class=\"keyword\">var</span> POLLING_URL = BASE_URL + <span class=\"string\">\"getUpdates?offset=:offset:&amp;timeout=60\"</span>;</div><div class=\"line\"><span class=\"keyword\">var</span> SEND_MESSAGE_URL = BASE_URL + <span class=\"string\">\"sendMessage\"</span>;</div></pre></td></tr></table></figure>\n<p>Now we’ll introduce a function called <em>poll</em> (you can choose any other name), which basically is kind of the main loop of our program. Here’s the code for this method, explanation follows.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">poll</span>(<span class=\"params\">offset</span>) </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">var</span> url = POLLING_URL.replace(<span class=\"string\">\":offset:\"</span>, offset);</div><div class=\"line\"></div><div class=\"line\">    unirest.get(url)</div><div class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">response</span>) </span>&#123;</div><div class=\"line\">            <span class=\"keyword\">var</span> body = response.raw_body;</div><div class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) &#123;</div><div class=\"line\">                <span class=\"keyword\">var</span> jsonData = <span class=\"built_in\">JSON</span>.parse(body);</div><div class=\"line\">                <span class=\"keyword\">var</span> result = jsonData.result;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">if</span> (result.length &gt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">for</span> (i <span class=\"keyword\">in</span> result) &#123;</div><div class=\"line\">                        <span class=\"keyword\">if</span> (runCommand(result[i].message)) <span class=\"keyword\">continue</span>;</div><div class=\"line\">                    &#125;</div><div class=\"line\"></div><div class=\"line\">                    max_offset = <span class=\"built_in\">parseInt</span>(result[result.length - <span class=\"number\">1</span>].update_id) + <span class=\"number\">1</span>; <span class=\"comment\">// update max offset</span></div><div class=\"line\">                &#125;</div><div class=\"line\">                poll(max_offset);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Alright. The function is recursive, meaning it will call itself – namely each time, a request was answered (which is, when a new message was fetched). The http request to Telegram API to get updates will be pending until a message arrives. Then it gets answered, but has to be re-opened again instantly now to continue listening for message updates again. As a parameter it takes an offset number, which replaces the <em>:offset:</em> placeholder in the url string. To read more about this parameter, go to <a href=\"https://core.telegram.org/bots/api#getupdates\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#getupdates</a>. Unirest opens an http request to the specified url and executes the callback function given to end(), if the request was answered. First, we extract the response body. Afterwards, we check if our request was successful. If this is the case, we parse the body (which is a JSON object, consisting of an <em>ok</em> field and a <em>result</em> array. The result array contains one or more message objects. These are the ones that are relevant for us. For each message object, we try to parse it as a command (i’ll give you the runCommand() function is a second…) and depending on which command we got, execute the respective method. Afterwards the offset gets updates to the id of the latest message plus one (to not receive it again next time) and a new request gets opened.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* ... */</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> dosth = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">message</span>) </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// to be implemented....</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> COMMANDS = &#123;</div><div class=\"line\">    <span class=\"string\">\"dosth\"</span> : dosth</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Now we specify a map, which maps strings (representing the users’ command input – in this case <em>/dosth</em> to actual functions.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">    <span class=\"keyword\">var</span> msgtext = message.text;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> (msgtext.indexOf(<span class=\"string\">\"/\"</span>) != <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// no slash at beginning?</span></div><div class=\"line\">    <span class=\"keyword\">var</span> command = msgtext.substring(<span class=\"number\">1</span>, msgtext.indexOf(<span class=\"string\">\" \"</span>));</div><div class=\"line\">    <span class=\"keyword\">if</span> (COMMANDS[command] == <span class=\"literal\">null</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>; <span class=\"comment\">// not a valid command?</span></div><div class=\"line\">    COMMANDS[command](message);</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>And this is the runCommand method. It takes the entire Telegram message object, which we got as a response from the Telegram API above and tries to parse its text as a command. A command string always starts with a slash. So if there is not slash in the beginning, we can be sure that we didn’t get a valid command. We simply return here, but we also could send a message to the user telling him “Hey, please enter a valid command.”. But let’s keep it simple. In the following line we extract everything after the slash and before the first blank space (assuming a command mustn’t contain a blank space) as the command. Afterwards we look into our map if the command actually is a key for a method and if so, we just run this method, passing it the message object as a parameter as the function will need information out of it.</p>\n<p>What have we done so far? We wrote a program that requests the Telegram API for new messages, parses potentially contained commands and runs functions depending on these commands.</p>\n<p>All we still need is to implement the method belonging to the <em>/dosth</em> command.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">    <span class=\"keyword\">var</span> caps = message.text.toUpperCase();</div><div class=\"line\">    <span class=\"keyword\">var</span> answer = &#123;</div><div class=\"line\">        <span class=\"attr\">chat_id</span> : message.chat.id,</div><div class=\"line\">        <span class=\"attr\">text</span> : <span class=\"string\">\"You told be to do something, so I took your input and made it all caps. Look: \"</span> + caps</div><div class=\"line\">    &#125;;</div><div class=\"line\"></div><div class=\"line\">    unirest.post(SEND_MESSAGE_URL)</div><div class=\"line\">        .send(answer)</div><div class=\"line\">        .end(<span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">response</span>) </span>&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span> (response.status == <span class=\"number\">200</span>) <span class=\"built_in\">console</span>.log(<span class=\"string\">\"Successfully sent message to \"</span> + message.chat.id);</div><div class=\"line\">        &#125;);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Most times you’ll want to send a message as response to your user. You could also send an image, an audio, a location, … (see <a href=\"https://core.telegram.org/bots/api#available-methods\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#available-methods</a>). Every message object needs a <em>chat_id</em> field, containing a Telegram user id, so that Telegram knows which user to deliver your message to. We simply extract this id out of the message object’s chat object we received from the user. The second mandatory field in a message object is the <em>text</em>. This is up to you. After having set up the new message object (you could add other fields, e.g. to show bot-buttons to the user – see <a href=\"https://core.telegram.org/bots/api#message\" target=\"_blank\" rel=\"external\">https://core.telegram.org/bots/api#message</a> for this), we just need to HTTP POST it to Telegram using Unirest again. Finished.</p>\n<p>This example was kept veeeery simple. Of course you could implement your bot to do really fancy things. You could process media, do location-specific operations, include a database (MongoDB suits really well!) and many, many other things. You could write any complex application you can imagine – with a Telegram chat as the text i/o interface. Please tell be your ideas – what would be a great bot?</p>\n<p>If you like to try by bot, simply write a message to <strong>@FavoriteBot</strong> and share it to your friends, if you like it.</p>\n<p>If you have any questions, contact me via mail to <em>mail(at)ferdinand-muetsch.de.</em></p>\n"},{"title":"Telegram bot example code in Node.js","date":"2015-12-01T21:42:05.000Z","_content":"\nAs a response to my [latest article](how-to-make-telegram-bots.html) on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.\n\nAlright, here’s my sample bot: [http://github.com/n1try/telegram-bot-node-sample](http://github.com/n1try/telegram-bot-node-sample/)\n\nAlso check out my _@FavoriteBot_.  \nHave fun and good luck...","source":"_posts/telegram-bot-example-code-in-nodejs.md","raw":"---\ntitle: Telegram bot example code in Node.js\ndate: 2015-12-01 22:42:05\ntags:\n---\n\nAs a response to my [latest article](how-to-make-telegram-bots.html) on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.\n\nAlright, here’s my sample bot: [http://github.com/n1try/telegram-bot-node-sample](http://github.com/n1try/telegram-bot-node-sample/)\n\nAlso check out my _@FavoriteBot_.  \nHave fun and good luck...","slug":"telegram-bot-example-code-in-nodejs","published":1,"updated":"2017-05-03T20:43:04.038Z","_id":"cj29g8geu0005qkqgnrc6xk0f","comments":1,"layout":"post","photos":[],"link":"","content":"<p>As a response to my <a href=\"how-to-make-telegram-bots.html\">latest article</a> on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.</p>\n<p>Alright, here’s my sample bot: <a href=\"http://github.com/n1try/telegram-bot-node-sample/\" target=\"_blank\" rel=\"external\">http://github.com/n1try/telegram-bot-node-sample</a></p>\n<p>Also check out my <em>@FavoriteBot</em>.<br>Have fun and good luck…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>As a response to my <a href=\"how-to-make-telegram-bots.html\">latest article</a> on how to make Telegram bots, I got many requests from guys who had problems with actually getting such a bot set up with my tutorial and they asked for a complete, working code example. So I made one. It is limited to the very basics, but it works and may serve as inspiration for you. What most of you would probably like to have further in your bots, but what is not covered in my example, is a database connection. Because in most cases your bot will probably need to persist data. To realize this you should have a little rather advanced skills in Node as well as basic knowledge of the database system of your choice, which is MongoDB with Mongoose Node module for me.</p>\n<p>Alright, here’s my sample bot: <a href=\"http://github.com/n1try/telegram-bot-node-sample/\" target=\"_blank\" rel=\"external\">http://github.com/n1try/telegram-bot-node-sample</a></p>\n<p>Also check out my <em>@FavoriteBot</em>.<br>Have fun and good luck…</p>\n"},{"title":"Why RAID 10 is better than RAID 01","date":"2015-11-19T21:43:31.000Z","_content":"\nSince it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.  \nFirst you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments don’t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined – you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but it’s very unusual.  \nThe following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.\n\n![raid01](/images/raid01.png)  \n\n*Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.*\n\n![raid10](/images/raid10.png)  \n\n*Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.*\n\nWe assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.  \nFirst of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if they’re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date won’t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5\\. Now take a look at figure 2\\. The crash of one disk in a RAID 1 (sub)system won’t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldn’t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 – all but NOT 2\\. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01\\. Hope you got it…","source":"_posts/why-raid-10-is-better-than-raid-01.md","raw":"---\ntitle: Why RAID 10 is better than RAID 01\ndate: 2015-11-19 22:43:31\ntags:\n---\n\nSince it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.  \nFirst you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments don’t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined – you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but it’s very unusual.  \nThe following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.\n\n![raid01](/images/raid01.png)  \n\n*Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.*\n\n![raid10](/images/raid10.png)  \n\n*Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.*\n\nWe assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.  \nFirst of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if they’re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date won’t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5\\. Now take a look at figure 2\\. The crash of one disk in a RAID 1 (sub)system won’t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldn’t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 – all but NOT 2\\. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01\\. Hope you got it…","slug":"why-raid-10-is-better-than-raid-01","published":1,"updated":"2017-05-03T20:46:40.668Z","_id":"cj29g9v0y0006qkqgd6js2a62","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Since it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.<br>First you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments don’t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined – you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but it’s very unusual.<br>The following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.</p>\n<p><img src=\"/images/raid01.png\" alt=\"raid01\">  </p>\n<p><em>Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.</em></p>\n<p><img src=\"/images/raid10.png\" alt=\"raid10\">  </p>\n<p><em>Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.</em></p>\n<p>We assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.<br>First of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if they’re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date won’t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5. Now take a look at figure 2. The crash of one disk in a RAID 1 (sub)system won’t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldn’t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 – all but NOT 2. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01. Hope you got it…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Since it took me a while to completely understand why a RAID 1+0 configuration should be better than a RAID 0+1 one in terms of failure tolerance I want to put my insights down.<br>First you should have a basic understanding of what the first two RAID levels are and what it means to nest them. Very basically at level 0 data gets striped, meaning a datum gets split up into two or more blocks that get stored on a different hard drive each. Goal is to improve read and write performance linearly to the number of disks used, because the fragments don’t have to be read sequentially anymore but in parallel. Level 1 is about mirroring a datum on two disks with the goal to improve security. Of course, both levels can be combined – you could either mirror striped data or stripe mirrored data which finally gives both: security and performance. In each case at least four disks are needed, while the half of the disks usually is a mirror. So if you took six disks you would do 3-striping. With eight disks you would do 4-striping and so on. Technically you could have more than one mirror (like doing 2-striping and having a 3-mirror or even more) but it’s very unusual.<br>The following diagrams shall illustrate these two ways and are useful for further explanations. In both cases we have a RAID with six disks.</p>\n<p><img src=\"/images/raid01.png\" alt=\"raid01\">  </p>\n<p><em>Disks 4, 5 and 6 are the mirrors of 1, 2 and 3.</em></p>\n<p><img src=\"/images/raid10.png\" alt=\"raid10\">  </p>\n<p><em>Disk 2 mirrors 1, 4 mirrors 3 and 6 mirrors 5.</em></p>\n<p>We assert that RAID 10 is better in terms of fault tolerance because a total failure (= loss of data) is less likely. In other words if some drives crash in a RAID 01 configuration the chance that those are the right drives for suffering a data loss is higher.<br>First of all, both configurations can easily survive the crash of one drive. No matter which drive (see figures above) crashes, we have a second one with the exact same data on it in any case. Potentially both configurations can handle the simultaneous crash of two or even more drives (up to N/2), if they’re the right ones, but in the worst case, the second crash could end up in a total failure. What you need to make clear before understanding how RAID 01 is worse than RAID 10 is that a RAID 0 (sub)system immediately gets unusable if one of its disks goes down. This is apparent: In the upper figure (figure 1 from now on) data is divided up into three strips in both RAID 0 subsystem. So if one of their disks fails (assume a crash of Disc1), the subsystem is broken since the first two parts of a date won’t make sense without the third. You would still be in posession of all data, nothing is lost yet, but nevertheless the left RAID 0 subsystem is down. If a second drive fails this should only be 2 or 3 (since the left system in inacessible anyway) to keep the entire system up. Disc 4, 5 or 6 failing would cause a total crash. So the chance of the second failing disk resulting in a total crash is 3/5. Now take a look at figure 2. The crash of one disk in a RAID 1 (sub)system won’t make this subsystem go down because the RAID controller will seamlessly switch to the mirror drive which has exactly identical data. In figure 2 all RAID 0 disks (which actually are stanalone RAID 1 systems again) need to keep running for the entire system to stay up. So theoretically there wouldn’t be a problem with disks 1, 3 and 5 (or 2, 4 and 6) could crashing simultaneously. After one disk having failed (assume a crash of Disc1 again) the second one failing could be 3, 4, 5 or 6 – all but NOT 2. The probability of a total crash is 1/5 (namely Disc2 of the remaining five) now and therefore lower than 3/5 with RAID 01. Hope you got it…</p>\n"},{"title":"Anchr.io – Image uploads, bookmarks and shortlink service","date":"2015-12-01T21:47:35.000Z","_content":"\nI want to present my latest project called [Anchr.io](https://anchr.io). It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks – like those you have in Chrome or Firefox – accessible from everywhere without needing to synchronize your browser profile. Just like if you’re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchr’s **collections** feature does. It saves links – with an optional description for easier search and separated into seperate categories / collections.\n\n![Anchr collections](images/anchr_2.jpg)\n\nThe second feature is to **upload images**. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchr’s image hosting is that users are given the opportunity to client-sided **encrypt images** with a password. As a result no one without the password will ever see their photos’ content.\n\n![Anchr images](/images/anchr_1.jpg)\n\nThe last feature are **shortlinks** – actually not any different from those you know from [goo.gl](http://goo.gl) or [bit.ly](http://bit.ly). They’re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible – to be precise of a length of 22 bytes with Anchr.\n\nAnchr’s focus is on ease and quickness of use – short loading times, flat menu hierarchies, etc.\n\nAt the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.","source":"_posts/anchr-io-image-uploads-bookmarks-and-shortlink-service.md","raw":"---\ntitle: 'Anchr.io – Image uploads, bookmarks and shortlink service'\ndate: 2015-12-01 22:47:35\ntags:\n---\n\nI want to present my latest project called [Anchr.io](https://anchr.io). It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks – like those you have in Chrome or Firefox – accessible from everywhere without needing to synchronize your browser profile. Just like if you’re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchr’s **collections** feature does. It saves links – with an optional description for easier search and separated into seperate categories / collections.\n\n![Anchr collections](images/anchr_2.jpg)\n\nThe second feature is to **upload images**. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchr’s image hosting is that users are given the opportunity to client-sided **encrypt images** with a password. As a result no one without the password will ever see their photos’ content.\n\n![Anchr images](/images/anchr_1.jpg)\n\nThe last feature are **shortlinks** – actually not any different from those you know from [goo.gl](http://goo.gl) or [bit.ly](http://bit.ly). They’re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible – to be precise of a length of 22 bytes with Anchr.\n\nAnchr’s focus is on ease and quickness of use – short loading times, flat menu hierarchies, etc.\n\nAt the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.","slug":"anchr-io-image-uploads-bookmarks-and-shortlink-service","published":1,"updated":"2017-05-03T20:51:25.776Z","_id":"cj29gf9i90008qkqgaabcfdkw","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I want to present my latest project called <a href=\"https://anchr.io\" target=\"_blank\" rel=\"external\">Anchr.io</a>. It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks – like those you have in Chrome or Firefox – accessible from everywhere without needing to synchronize your browser profile. Just like if you’re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchr’s <strong>collections</strong> feature does. It saves links – with an optional description for easier search and separated into seperate categories / collections.</p>\n<p><img src=\"images/anchr_2.jpg\" alt=\"Anchr collections\"></p>\n<p>The second feature is to <strong>upload images</strong>. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchr’s image hosting is that users are given the opportunity to client-sided <strong>encrypt images</strong> with a password. As a result no one without the password will ever see their photos’ content.</p>\n<p><img src=\"/images/anchr_1.jpg\" alt=\"Anchr images\"></p>\n<p>The last feature are <strong>shortlinks</strong> – actually not any different from those you know from <a href=\"http://goo.gl\" target=\"_blank\" rel=\"external\">goo.gl</a> or <a href=\"http://bit.ly\" target=\"_blank\" rel=\"external\">bit.ly</a>. They’re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible – to be precise of a length of 22 bytes with Anchr.</p>\n<p>Anchr’s focus is on ease and quickness of use – short loading times, flat menu hierarchies, etc.</p>\n<p>At the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>I want to present my latest project called <a href=\"https://anchr.io\" target=\"_blank\" rel=\"external\">Anchr.io</a>. It claims to be a useful little helper or toolbox or the like for common tasks on the internet. The idea arised when someday I considered it useful to have a collection of web links or bookmarks – like those you have in Chrome or Firefox – accessible from everywhere without needing to synchronize your browser profile. Just like if you’re anywhere on an other PC, find a useful article on the internet and want to save it quickly for later at home. This is what Anchr’s <strong>collections</strong> feature does. It saves links – with an optional description for easier search and separated into seperate categories / collections.</p>\n<p><img src=\"images/anchr_2.jpg\" alt=\"Anchr collections\"></p>\n<p>The second feature is to <strong>upload images</strong>. You can easily upload one or more photos from your computer oder mobile device and send them to friends or include them into forum posts or the like. Special with Anchr’s image hosting is that users are given the opportunity to client-sided <strong>encrypt images</strong> with a password. As a result no one without the password will ever see their photos’ content.</p>\n<p><img src=\"/images/anchr_1.jpg\" alt=\"Anchr images\"></p>\n<p>The last feature are <strong>shortlinks</strong> – actually not any different from those you know from <a href=\"http://goo.gl\" target=\"_blank\" rel=\"external\">goo.gl</a> or <a href=\"http://bit.ly\" target=\"_blank\" rel=\"external\">bit.ly</a>. They’re useful if you have a very long web link including many query parameters, access tokens, session ids, special characters and the like and want to share them. Often special characters break the linking or your chat application has a maximum length for hyperlinks. Or you just want to keep clarity in your document or emails. In this case it can be very helpful to make the links as short as any possible – to be precise of a length of 22 bytes with Anchr.</p>\n<p>Anchr’s focus is on ease and quickness of use – short loading times, flat menu hierarchies, etc.</p>\n<p>At the end just a few words about the technical aspect in addition. Anchr.io is separated clearly into backend and frontend or server- and client-application. Both are kept as modular as possible, trying to follow the MVC pattern. Interface between front- and backend is a REST API. The server is based in Node.js with a bunch of very cool new frameworks while the client is an Angular application. Concluding the development was both fun and such a good practice to me and the result will definitely make some of my daily processes a small little easier. I hope you give the app a try and leave me some feedback to dev(at)anchr.io.</p>\n"},{"title":"Instant messenger security / encryption overview","date":"2016-02-01T21:48:46.000Z","_content":"\nI found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.\n\n![](/images/scorecard.jpg)\n\n[https://www.eff.org/secure-messaging-scorecard](https://www.eff.org/secure-messaging-scorecard \"https://www.eff.org/secure-messaging-scorecard\")\n\nThe aspects “Encrypted in transit?” and “Encrypted so the provider can’t read it?” are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it – neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.\n\nWhat I miss about this “Secure Messaging Scorecard” is a specification of whether images (and audio recordings, videos, …) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.\n\nWhat I find alarming is that some commonly used apps like Skype don’t even have end-to-end encryption – it is not that hard to integrate and for me this should be standard today. I don’t care that extremely much about online privacy because eventually I don’t have anything to hide but anyhow – why should Microsoft employees potentially be able to read my messages and view my pics?","source":"_posts/instant-messenger-security-encryption-overview.md","raw":"---\ntitle: Instant messenger security / encryption overview\ndate: 2016-02-01 22:48:46\ntags:\n---\n\nI found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.\n\n![](/images/scorecard.jpg)\n\n[https://www.eff.org/secure-messaging-scorecard](https://www.eff.org/secure-messaging-scorecard \"https://www.eff.org/secure-messaging-scorecard\")\n\nThe aspects “Encrypted in transit?” and “Encrypted so the provider can’t read it?” are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it – neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.\n\nWhat I miss about this “Secure Messaging Scorecard” is a specification of whether images (and audio recordings, videos, …) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.\n\nWhat I find alarming is that some commonly used apps like Skype don’t even have end-to-end encryption – it is not that hard to integrate and for me this should be standard today. I don’t care that extremely much about online privacy because eventually I don’t have anything to hide but anyhow – why should Microsoft employees potentially be able to read my messages and view my pics?","slug":"instant-messenger-security-encryption-overview","published":1,"updated":"2017-05-03T20:53:06.032Z","_id":"cj29gglna0009qkqgguz223z0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.</p>\n<p><img src=\"/images/scorecard.jpg\" alt=\"\"></p>\n<p><a href=\"https://www.eff.org/secure-messaging-scorecard\" title=\"https://www.eff.org/secure-messaging-scorecard\" target=\"_blank\" rel=\"external\">https://www.eff.org/secure-messaging-scorecard</a></p>\n<p>The aspects “Encrypted in transit?” and “Encrypted so the provider can’t read it?” are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it – neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.</p>\n<p>What I miss about this “Secure Messaging Scorecard” is a specification of whether images (and audio recordings, videos, …) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.</p>\n<p>What I find alarming is that some commonly used apps like Skype don’t even have end-to-end encryption – it is not that hard to integrate and for me this should be standard today. I don’t care that extremely much about online privacy because eventually I don’t have anything to hide but anyhow – why should Microsoft employees potentially be able to read my messages and view my pics?</p>\n","site":{"data":{}},"excerpt":"","more":"<p>I found a very nice page showing an overview of the security features of almost any instant messenger available. Nowadays where digital privacy observation is on everyones lips it is really interesting to see in how far the messengers we use every day are actually secure and who can potentially read or messages or not.</p>\n<p><img src=\"/images/scorecard.jpg\" alt=\"\"></p>\n<p><a href=\"https://www.eff.org/secure-messaging-scorecard\" title=\"https://www.eff.org/secure-messaging-scorecard\" target=\"_blank\" rel=\"external\">https://www.eff.org/secure-messaging-scorecard</a></p>\n<p>The aspects “Encrypted in transit?” and “Encrypted so the provider can’t read it?” are probably the most important ones and are a different way of saying if the application uses encrypted transmission (probably HTTPS for the most cases) and if it has end-to-end encryption. The last one means that keys are exchanged between sender and recipient which are used for asynchronous encryption so that nobody who potentially receives the message in the middle between them could read it – neither the provider nor the government. To prove that this is actually implemented properly it is required to have an open code which can be reviewed by anyone, because if nobody has ever seen the code it could potentially be the case that your messenger might use end-to-end encryption but the provider grabs your private key too or things the like.</p>\n<p>What I miss about this “Secure Messaging Scorecard” is a specification of whether images (and audio recordings, videos, …) get encrypted, too, by messengers that have a checkmark in the second column. Maybe I will do some research on this for some of the listed messengers.</p>\n<p>What I find alarming is that some commonly used apps like Skype don’t even have end-to-end encryption – it is not that hard to integrate and for me this should be standard today. I don’t care that extremely much about online privacy because eventually I don’t have anything to hide but anyhow – why should Microsoft employees potentially be able to read my messages and view my pics?</p>\n"},{"title":"Learning Angular2: What is new?","date":"2016-02-17T21:51:59.000Z","_content":"\n![](/images/angular2_logo.png)\n\nA few days ago i started teaching myself [Angular 2](http://angular.io), which is the successor of the popular frontend web-framework [AngularJS 1.x](https://angularjs.org/). It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But I’m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applications’ client side I have no doubts that Angular 2 will establish itself pretty quick too.\n\nFor those of you who are familiar with Angular 1 and have developed with it yet: according to what I’ve seen so far you will definitely need to take some time for learning Angular 2 – it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:\n\n*   **Different syntax for directives** in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.\n*   There are no controllers anymore. Instead everything is based on (Web-)**Components** (as you may know them from [Google Polymer](https://www.polymer-project.org/1.0/) – if you don’t check this out as well, it is pretty cool), which basically consist of the component’s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1’s controllers.\n*   It is based on **ES6 and [TypeScript](http://www.typescriptlang.org/)**. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely [new features](https://github.com/lukehoban/es6features) and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:\n```javascript\n    class Greeter {\n        greeting: string;\n        constructor(message: string) {\n            this.greeting = message;\n        }\n        greet() {\n            return \"Hello, \" + this.greeting;\n        }\n    }\n\n    var greeter = new Greeter(\"world\");</pre>\n```\n\nAlso there are interfaces, import statements, a shorthand way for anonymous functions called “arrow functions” and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which [these two videos](https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif) are really great.\n\n*   **Dependency injection** has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in components’ @Component decorator.\n*   Two-way data-binding is still available but the focus is now on **one-way data-binding** (if I got it right the main reason are performance considerations). One-way data-binding means that data isn’t continuously updated between template and component but only based on events triggered.\n\nThose where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:\n\n * [Angular’s offical Getting Started](https://angular.io/docs/ts/latest/quickstart.html)\n * [Angular 2 Fundamentals](https://www.udemy.com/angular-2-fundamentals/) (a free video course on [Udemy](http://udemy.com) for the very basic concepts)\n * This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  \n\n[![](http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg)](http://www.youtube.com/watch?v=KL4Yi3WtymA)\n\nBeing able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of today’s browsers won’t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector – which is probably the fastest growing and most hyped one at the moment.","source":"_posts/learning-angular2-what-is-new.md","raw":"---\ntitle: 'Learning Angular2: What is new?'\ndate: 2016-02-17 22:51:59\ntags:\n---\n\n![](/images/angular2_logo.png)\n\nA few days ago i started teaching myself [Angular 2](http://angular.io), which is the successor of the popular frontend web-framework [AngularJS 1.x](https://angularjs.org/). It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But I’m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applications’ client side I have no doubts that Angular 2 will establish itself pretty quick too.\n\nFor those of you who are familiar with Angular 1 and have developed with it yet: according to what I’ve seen so far you will definitely need to take some time for learning Angular 2 – it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:\n\n*   **Different syntax for directives** in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.\n*   There are no controllers anymore. Instead everything is based on (Web-)**Components** (as you may know them from [Google Polymer](https://www.polymer-project.org/1.0/) – if you don’t check this out as well, it is pretty cool), which basically consist of the component’s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1’s controllers.\n*   It is based on **ES6 and [TypeScript](http://www.typescriptlang.org/)**. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely [new features](https://github.com/lukehoban/es6features) and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:\n```javascript\n    class Greeter {\n        greeting: string;\n        constructor(message: string) {\n            this.greeting = message;\n        }\n        greet() {\n            return \"Hello, \" + this.greeting;\n        }\n    }\n\n    var greeter = new Greeter(\"world\");</pre>\n```\n\nAlso there are interfaces, import statements, a shorthand way for anonymous functions called “arrow functions” and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which [these two videos](https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif) are really great.\n\n*   **Dependency injection** has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in components’ @Component decorator.\n*   Two-way data-binding is still available but the focus is now on **one-way data-binding** (if I got it right the main reason are performance considerations). One-way data-binding means that data isn’t continuously updated between template and component but only based on events triggered.\n\nThose where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:\n\n * [Angular’s offical Getting Started](https://angular.io/docs/ts/latest/quickstart.html)\n * [Angular 2 Fundamentals](https://www.udemy.com/angular-2-fundamentals/) (a free video course on [Udemy](http://udemy.com) for the very basic concepts)\n * This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  \n\n[![](http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg)](http://www.youtube.com/watch?v=KL4Yi3WtymA)\n\nBeing able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of today’s browsers won’t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector – which is probably the fastest growing and most hyped one at the moment.","slug":"learning-angular2-what-is-new","published":1,"updated":"2017-05-03T20:52:54.223Z","_id":"cj29gkr0d000aqkqgfltce9x7","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/angular2_logo.png\" alt=\"\"></p>\n<p>A few days ago i started teaching myself <a href=\"http://angular.io\" target=\"_blank\" rel=\"external\">Angular 2</a>, which is the successor of the popular frontend web-framework <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"external\">AngularJS 1.x</a>. It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But I’m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applications’ client side I have no doubts that Angular 2 will establish itself pretty quick too.</p>\n<p>For those of you who are familiar with Angular 1 and have developed with it yet: according to what I’ve seen so far you will definitely need to take some time for learning Angular 2 – it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:</p>\n<ul>\n<li><strong>Different syntax for directives</strong> in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.</li>\n<li>There are no controllers anymore. Instead everything is based on (Web-)<strong>Components</strong> (as you may know them from <a href=\"https://www.polymer-project.org/1.0/\" target=\"_blank\" rel=\"external\">Google Polymer</a> – if you don’t check this out as well, it is pretty cool), which basically consist of the component’s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1’s controllers.</li>\n<li>It is based on <strong>ES6 and <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"external\">TypeScript</a></strong>. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely <a href=\"https://github.com/lukehoban/es6features\" target=\"_blank\" rel=\"external\">new features</a> and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Greeter</span> </span>&#123;</div><div class=\"line\">    greeting: string;</div><div class=\"line\">    <span class=\"keyword\">constructor</span>(message: string) &#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>.greeting = message;</div><div class=\"line\">    &#125;</div><div class=\"line\">    greet() &#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, \"</span> + <span class=\"keyword\">this</span>.greeting;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> greeter = <span class=\"keyword\">new</span> Greeter(<span class=\"string\">\"world\"</span>);&lt;/pre&gt;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>Also there are interfaces, import statements, a shorthand way for anonymous functions called “arrow functions” and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which <a href=\"https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif\" target=\"_blank\" rel=\"external\">these two videos</a> are really great.</p>\n<ul>\n<li><strong>Dependency injection</strong> has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in components’ @Component decorator.</li>\n<li>Two-way data-binding is still available but the focus is now on <strong>one-way data-binding</strong> (if I got it right the main reason are performance considerations). One-way data-binding means that data isn’t continuously updated between template and component but only based on events triggered.</li>\n</ul>\n<p>Those where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:</p>\n<ul>\n<li><a href=\"https://angular.io/docs/ts/latest/quickstart.html\" target=\"_blank\" rel=\"external\">Angular’s offical Getting Started</a></li>\n<li><a href=\"https://www.udemy.com/angular-2-fundamentals/\" target=\"_blank\" rel=\"external\">Angular 2 Fundamentals</a> (a free video course on <a href=\"http://udemy.com\" target=\"_blank\" rel=\"external\">Udemy</a> for the very basic concepts)</li>\n<li>This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  </li>\n</ul>\n<p><a href=\"http://www.youtube.com/watch?v=KL4Yi3WtymA\" target=\"_blank\" rel=\"external\"><img src=\"http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg\" alt=\"\"></a></p>\n<p>Being able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of today’s browsers won’t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector – which is probably the fastest growing and most hyped one at the moment.</p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"/images/angular2_logo.png\" alt=\"\"></p>\n<p>A few days ago i started teaching myself <a href=\"http://angular.io\" target=\"_blank\" rel=\"external\">Angular 2</a>, which is the successor of the popular frontend web-framework <a href=\"https://angularjs.org/\" target=\"_blank\" rel=\"external\">AngularJS 1.x</a>. It is still in development and only released as a beta and the developers at Google recommend to not use it in production yet. But I’m sure it will come some time in the near future so why not take a step ahead and already learn it now? As Angular 1 has become very successful and wide-spread for web-applications’ client side I have no doubts that Angular 2 will establish itself pretty quick too.</p>\n<p>For those of you who are familiar with Angular 1 and have developed with it yet: according to what I’ve seen so far you will definitely need to take some time for learning Angular 2 – it is considerably different from the first version and got few major changes, at least in my eyes. Those changes include:</p>\n<ul>\n<li><strong>Different syntax for directives</strong> in HTML: They have introduced parantheses (), brackets [], stars *, hashtags # and combinations of them to be used in your markup. E.g. parantheses () are used as attributes in HTML elements to bind to their events.</li>\n<li>There are no controllers anymore. Instead everything is based on (Web-)<strong>Components</strong> (as you may know them from <a href=\"https://www.polymer-project.org/1.0/\" target=\"_blank\" rel=\"external\">Google Polymer</a> – if you don’t check this out as well, it is pretty cool), which basically consist of the component’s logic and a view and define a new custom HTML element each. Almost everything in Angular 2 is a component, which enables the code to be even more structurable, more modular and more reusable. But it is a completely new way of thinking in comparison to Angular 1’s controllers.</li>\n<li>It is based on <strong>ES6 and <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"external\">TypeScript</a></strong>. ES6 is the latest JavaScript standard (or version so to say) and TypeScript is even a superset of that, which basically introduces types and modifiers for variables and functions (as you may know from strongly-typed languages like Java). This brings some completely <a href=\"https://github.com/lukehoban/es6features\" target=\"_blank\" rel=\"external\">new features</a> and syntax you need to get familiar with. For instance you can define classes with attributes and methods like this now:<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Greeter</span> </span>&#123;</div><div class=\"line\">    greeting: string;</div><div class=\"line\">    <span class=\"keyword\">constructor</span>(message: string) &#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>.greeting = message;</div><div class=\"line\">    &#125;</div><div class=\"line\">    greet() &#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello, \"</span> + <span class=\"keyword\">this</span>.greeting;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> greeter = <span class=\"keyword\">new</span> Greeter(<span class=\"string\">\"world\"</span>);&lt;/pre&gt;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>Also there are interfaces, import statements, a shorthand way for anonymous functions called “arrow functions” and many more. Before learning Angular 2 I really recommend to first learn JavaScript ES6 for which <a href=\"https://www.youtube.com/playlist?list=PLoYCgNOIyGACDQLaThEEKBAlgs4OIUGif\" target=\"_blank\" rel=\"external\">these two videos</a> are really great.</p>\n<ul>\n<li><strong>Dependency injection</strong> has also been reworked to be better understandable, easier to use and more modular now. You will no use @Inectable decorators for injectable services and other modules and provide in the modules by referencing to them in a providers property in components’ @Component decorator.</li>\n<li>Two-way data-binding is still available but the focus is now on <strong>one-way data-binding</strong> (if I got it right the main reason are performance considerations). One-way data-binding means that data isn’t continuously updated between template and component but only based on events triggered.</li>\n</ul>\n<p>Those where just some of the major changes I got so far. If you want to learn Angular 2 I recommend you the following resources:</p>\n<ul>\n<li><a href=\"https://angular.io/docs/ts/latest/quickstart.html\" target=\"_blank\" rel=\"external\">Angular’s offical Getting Started</a></li>\n<li><a href=\"https://www.udemy.com/angular-2-fundamentals/\" target=\"_blank\" rel=\"external\">Angular 2 Fundamentals</a> (a free video course on <a href=\"http://udemy.com\" target=\"_blank\" rel=\"external\">Udemy</a> for the very basic concepts)</li>\n<li>This video tutorial on YouTube which I found quite good (and I really had to laugh at 30:20 minutes). You can skip the first few minutes.  </li>\n</ul>\n<p><a href=\"http://www.youtube.com/watch?v=KL4Yi3WtymA\" target=\"_blank\" rel=\"external\"><img src=\"http://img.youtube.com/vi/KL4Yi3WtymA/0.jpg\" alt=\"\"></a></p>\n<p>Being able to develop the brand new, fancy Angular 2 with the brand new JavaScript ES6 (which is so new that most of today’s browsers won’t even understand it and as a result it needs to get transpiled to ES5 at present) will definitely give you benefits in web development and also in finding a job in that sector – which is probably the fastest growing and most hyped one at the moment.</p>\n"},{"title":"Web Development Technology Stack","date":"2016-03-15T21:54:04.000Z","_content":"\nI tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.\n\nFeel free to give your opinion on this collection and maybe add something you’re missing (in the comments after having logged in, via mail or via [telegram.me/n1try](http://telegram.me/n1try)).\n\n[![Web Tech Stack](/imgages/webdev_techstack.png)](/imgages/webdev_techstack_large.png)","source":"_posts/web-development-technology-stack.md","raw":"---\ntitle: Web Development Technology Stack\ndate: 2016-03-15 22:54:04\ntags:\n---\n\nI tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.\n\nFeel free to give your opinion on this collection and maybe add something you’re missing (in the comments after having logged in, via mail or via [telegram.me/n1try](http://telegram.me/n1try)).\n\n[![Web Tech Stack](/imgages/webdev_techstack.png)](/imgages/webdev_techstack_large.png)","slug":"web-development-technology-stack","published":1,"updated":"2017-05-03T20:54:33.615Z","_id":"cj29gnfav000bqkqgox27gn3o","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.</p>\n<p>Feel free to give your opinion on this collection and maybe add something you’re missing (in the comments after having logged in, via mail or via <a href=\"http://telegram.me/n1try\" target=\"_blank\" rel=\"external\">telegram.me/n1try</a>).</p>\n<p><a href=\"/imgages/webdev_techstack_large.png\"><img src=\"/imgages/webdev_techstack.png\" alt=\"Web Tech Stack\"></a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>I tried to give a comprehensive overview of all important and fashionable technologies concerning web- and cross-platform development, so I created kind of a mind map outlining relevant technologies in terms of languages, frameworks, libraries, webservices and tools. I consider them kind of must-haves for JavaScript fullstack web-developers. You might have already heard of most of them and probably you have even worked with the majority.</p>\n<p>Feel free to give your opinion on this collection and maybe add something you’re missing (in the comments after having logged in, via mail or via <a href=\"http://telegram.me/n1try\" target=\"_blank\" rel=\"external\">telegram.me/n1try</a>).</p>\n<p><a href=\"/imgages/webdev_techstack_large.png\"><img src=\"/imgages/webdev_techstack.png\" alt=\"Web Tech Stack\"></a></p>\n"},{"title":"Digitalocean – My preferred Cloud Hosting Provider","date":"2016-04-06T20:55:18.000Z","_content":"\n![](/images/do.png)\n[DigitalOcean.com](https://digitalocean.com) is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.\n\nIt is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.\n\nAs a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.\n\nFor scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.\n\nA feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I haven’t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.\n\nWhat I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.\n\nDigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are [Microsoft Azure](https://azure.microsoft.com/en-us/), [Google Compute Engine](https://cloud.google.com/compute/), [Amazon EC2](https://aws.amazon.com/de/ec2), [Linode](https://www.linode.com/) or in a wider sense also [JiffyBox.de](http://jiffybox.de).\n\nIf you want to give DigitalOcean a try (and support me), follow [this referral link](https://m.do.co/c/4abee7f659ad) where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.\n\n![](assets/img/simple-smile.png)","source":"_posts/digitalocean-my-preferred-cloud-hosting-provider.md","raw":"---\ntitle: Digitalocean – My preferred Cloud Hosting Provider\ndate: 2016-04-06 22:55:18\ntags:\n---\n\n![](/images/do.png)\n[DigitalOcean.com](https://digitalocean.com) is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.\n\nIt is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.\n\nAs a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.\n\nFor scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.\n\nA feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I haven’t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.\n\nWhat I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.\n\nDigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are [Microsoft Azure](https://azure.microsoft.com/en-us/), [Google Compute Engine](https://cloud.google.com/compute/), [Amazon EC2](https://aws.amazon.com/de/ec2), [Linode](https://www.linode.com/) or in a wider sense also [JiffyBox.de](http://jiffybox.de).\n\nIf you want to give DigitalOcean a try (and support me), follow [this referral link](https://m.do.co/c/4abee7f659ad) where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.\n\n![](assets/img/simple-smile.png)","slug":"digitalocean-my-preferred-cloud-hosting-provider","published":1,"updated":"2017-05-03T20:55:45.992Z","_id":"cj29gp5ky000dqkqgi6xyzaq6","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/do.png\" alt=\"\"><br><a href=\"https://digitalocean.com\" target=\"_blank\" rel=\"external\">DigitalOcean.com</a> is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.</p>\n<p>It is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.</p>\n<p>As a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.</p>\n<p>For scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.</p>\n<p>A feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I haven’t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.</p>\n<p>What I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.</p>\n<p>DigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are <a href=\"https://azure.microsoft.com/en-us/\" target=\"_blank\" rel=\"external\">Microsoft Azure</a>, <a href=\"https://cloud.google.com/compute/\" target=\"_blank\" rel=\"external\">Google Compute Engine</a>, <a href=\"https://aws.amazon.com/de/ec2\" target=\"_blank\" rel=\"external\">Amazon EC2</a>, <a href=\"https://www.linode.com/\" target=\"_blank\" rel=\"external\">Linode</a> or in a wider sense also <a href=\"http://jiffybox.de\" target=\"_blank\" rel=\"external\">JiffyBox.de</a>.</p>\n<p>If you want to give DigitalOcean a try (and support me), follow <a href=\"https://m.do.co/c/4abee7f659ad\" target=\"_blank\" rel=\"external\">this referral link</a> where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.</p>\n<p><img src=\"assets/img/simple-smile.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"/images/do.png\" alt=\"\"><br><a href=\"https://digitalocean.com\" target=\"_blank\" rel=\"external\">DigitalOcean.com</a> is a service that offers you on-demand virtual server instances that you can use to host any server application, be it a simple webpage, a Node.js written backend, any Docker container or anything else.</p>\n<p>It is especially useful if you have developed a web application and want to bring it to the internet without owning a root server. In this case you can go to DigitalOcean, choose any boilerplate (or Droplet, as they call it) for your new virtual, cloud-hosted machine, additionally choose a the datacenter region which is closest to you or your customers, add your SSH keys for quick access and hit the create button. Within less than a minute your machine is up and running with a dedicated IPv4 assigned where you can ssh in.</p>\n<p>As a template / boilerplate you can either choose from the common, plain Linux distributions (even CoreOS) in almost any version or take one of the various pre-configured environments like a machine already running Docker, Node.js, ownCloud, Joomla or plenty other runtimes and applications.</p>\n<p>For scalability you can choose between different sizes, which basically means different memory capacity, cpu cores, ssd capacity and amount of traffic.</p>\n<p>A feature which I only know from DigitalOcean by now is the ability to create a cluster of multiple machines (Droplets) with private networking, meaning they can communicate with every other node in the cluster but are kind of isolated from the internet. I haven’t tried this feature too much but it is similar to what you might know from linking multiple Docker containers together.</p>\n<p>What I also like about the service is the ultra simple-to-use, minimalistic and intuitive web-interface that abstracts away this entire technical complexity running in the background when users do a single click on a button until a pre-installed machine comes up.</p>\n<p>DigitalOcean is my personal favorite service of this type, but I also want to mention some alternatives which are <a href=\"https://azure.microsoft.com/en-us/\" target=\"_blank\" rel=\"external\">Microsoft Azure</a>, <a href=\"https://cloud.google.com/compute/\" target=\"_blank\" rel=\"external\">Google Compute Engine</a>, <a href=\"https://aws.amazon.com/de/ec2\" target=\"_blank\" rel=\"external\">Amazon EC2</a>, <a href=\"https://www.linode.com/\" target=\"_blank\" rel=\"external\">Linode</a> or in a wider sense also <a href=\"http://jiffybox.de\" target=\"_blank\" rel=\"external\">JiffyBox.de</a>.</p>\n<p>If you want to give DigitalOcean a try (and support me), follow <a href=\"https://m.do.co/c/4abee7f659ad\" target=\"_blank\" rel=\"external\">this referral link</a> where you get $10 in credits, which is enough for running the smallest container for two months. I will get $25 in credits in case you in turn spend $25 for credits. Of course I would be very pleased if you did so.</p>\n<p><img src=\"assets/img/simple-smile.png\" alt=\"\"></p>\n"},{"title":"How do WhatsApp’s end-to-end encrypted group chats work?","date":"2016-04-07T20:56:43.000Z","_content":"\n![WhatsApp_Logo](/images/whatsapp_logo.png)\n\nA few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).  \nEvery end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the user’s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partners’ public keys to send secure messages to them. So far so good, but there’s a problem with group chats.  \nAssume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isn’t a too good solution, since it will increase your mobile data traffic amount. [Threema does it that way anyway](https://threema.ch/press-files/cryptography_whitepaper.pdf). WhatApp takes another approach that I will explained a little simplified.\n\nAccording to their [Whitepaper of crypthography](https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf) it works roughly as follows:  \n1\\. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.  \n2\\. You encrypt it individually with every other group member’s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but it’s acceptable since it only happens once when joining a new group, not every time sending a message.  \n3\\. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.  \n4\\. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partner’s public key while now you encrypt them using your private key) and send it to the server (who can’t read it) to fan it out to the group.  \n5\\. Every group members uses your myGroupPubkey to decrypt is.\n\nIt is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.\n\nTo be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.\n\nDisclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesn’t mean it is actually true. Do not rely on this. If you’re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.","source":"_posts/how-do-whatsapps-end-to-end-encrypted-group-chats-work.md","raw":"---\ntitle: How do WhatsApp’s end-to-end encrypted group chats work?\ndate: 2016-04-07 22:56:43\ntags:\n---\n\n![WhatsApp_Logo](/images/whatsapp_logo.png)\n\nA few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).  \nEvery end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the user’s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partners’ public keys to send secure messages to them. So far so good, but there’s a problem with group chats.  \nAssume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isn’t a too good solution, since it will increase your mobile data traffic amount. [Threema does it that way anyway](https://threema.ch/press-files/cryptography_whitepaper.pdf). WhatApp takes another approach that I will explained a little simplified.\n\nAccording to their [Whitepaper of crypthography](https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf) it works roughly as follows:  \n1\\. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.  \n2\\. You encrypt it individually with every other group member’s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but it’s acceptable since it only happens once when joining a new group, not every time sending a message.  \n3\\. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.  \n4\\. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partner’s public key while now you encrypt them using your private key) and send it to the server (who can’t read it) to fan it out to the group.  \n5\\. Every group members uses your myGroupPubkey to decrypt is.\n\nIt is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.\n\nTo be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.\n\nDisclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesn’t mean it is actually true. Do not rely on this. If you’re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.","slug":"how-do-whatsapps-end-to-end-encrypted-group-chats-work","published":1,"updated":"2017-05-03T20:58:44.447Z","_id":"cj29gqxup000fqkqgb6rbz2co","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/whatsapp_logo.png\" alt=\"WhatsApp_Logo\"></p>\n<p>A few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).<br>Every end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the user’s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partners’ public keys to send secure messages to them. So far so good, but there’s a problem with group chats.<br>Assume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isn’t a too good solution, since it will increase your mobile data traffic amount. <a href=\"https://threema.ch/press-files/cryptography_whitepaper.pdf\" target=\"_blank\" rel=\"external\">Threema does it that way anyway</a>. WhatApp takes another approach that I will explained a little simplified.</p>\n<p>According to their <a href=\"https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf\" target=\"_blank\" rel=\"external\">Whitepaper of crypthography</a> it works roughly as follows:<br>1. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.<br>2. You encrypt it individually with every other group member’s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but it’s acceptable since it only happens once when joining a new group, not every time sending a message.<br>3. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.<br>4. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partner’s public key while now you encrypt them using your private key) and send it to the server (who can’t read it) to fan it out to the group.<br>5. Every group members uses your myGroupPubkey to decrypt is.</p>\n<p>It is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.</p>\n<p>To be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.</p>\n<p>Disclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesn’t mean it is actually true. Do not rely on this. If you’re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.</p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"/images/whatsapp_logo.png\" alt=\"WhatsApp_Logo\"></p>\n<p>A few days ago WhatsApp has announced end-to-end encryption for all chats, which basically means, that messages are encrypted in a way that nobody except for the recipient can read a message. Previously only the communication channels between you and the server and between the server and your chat partner were encrypted, but the messages lay in clear text form on the server (though in case of WhatsApp not persistently stored).<br>Every end-to-end encryption is based on asymmetric cryptography methods, where a private and a public key exist. Messages encrypted with the public key can only be decrypted using the respective private key and the other way round. The private key is always kept private (as the name implies) and should never ever leave the user’s device, while the public key is sent to every chat partner, who will use it for messages addressed to you. No one without your private key will every be able to read them. In turn you are in posession of your chat partners’ public keys to send secure messages to them. So far so good, but there’s a problem with group chats.<br>Assume a group with three members, you (A), B and C. B (C) can only read messages signed with pubkey_B (pubkey_C). This would mean you had to encrypt the message twice, once with each public key. As a consequence you would also have to send it twice, which make your traffic for group messaging increase linearly with the amount of group members. Traditionally you only had to send the exact same message to the server once, who then did a fanout to all group members. Now you would have to send x (number of group members) different (since differently encrypted) messages, which isn’t a too good solution, since it will increase your mobile data traffic amount. <a href=\"https://threema.ch/press-files/cryptography_whitepaper.pdf\" target=\"_blank\" rel=\"external\">Threema does it that way anyway</a>. WhatApp takes another approach that I will explained a little simplified.</p>\n<p>According to their <a href=\"https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf\" target=\"_blank\" rel=\"external\">Whitepaper of crypthography</a> it works roughly as follows:<br>1. When joining a group you generate a group-specific key-pair, which we call myGroupPubkey and myGroupPrivkey from now on.<br>2. You encrypt it individually with every other group member’s public key (similar as you would do with a normal message) and send it to them. This is a client-side fanout where you actually send as many messages as there are members in the group, but it’s acceptable since it only happens once when joining a new group, not every time sending a message.<br>3. The partners encrypt this key-message using their respective private keys and get your myGroupPubkey out.<br>4. You encrypt every subsequent message using myGroupPrivkey (note that traditionally you encrypt messages using the partner’s public key while now you encrypt them using your private key) and send it to the server (who can’t read it) to fan it out to the group.<br>5. Every group members uses your myGroupPubkey to decrypt is.</p>\n<p>It is important to note that you encrypt with your private key, which it is usually not intended for (biut technically perfectly capable of), since it is unsecure in the way that everyone with your public key could read the message payload. The sticking point is that since this public key is transferred in asymmetrically encrypted form it is safe that only group members are in possession of it. If a group changes, those keys are re-generated.</p>\n<p>To be precise, this is only a simplified description but it explains the fundamental concept. For instance, besides other technical details the messages are actually first encrypted symmetrically and then signed asymmetrically.</p>\n<p>Disclaimer: There is no guarantee for correctness of this explanation at all. This is how I have understood the process, but that doesn’t mean it is actually true. Do not rely on this. If you’re from a cryptographical background, have read the official Whitepaper and are of the opinion that I understood anything from please let me know.</p>\n"},{"title":"Unhosted.org applications with remoteStorage.io and WebFinger.net","date":"2016-04-12T20:57:43.000Z","_content":"\nLately you as an interested web developer might have heard or read about a thing called **unhosted applications**, mostly with a reference to [unhosted.org](http://unhosted.org/). This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps you’re using on the web store data to a backend service at the provider’s host server, regardless of them being Google Docs, Evernote, Wunderlist or also [Anchr.io](https://anchr.io). Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players – deciding whether that is better or worse it’s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then there’s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably you’ll need a webserver, but it only needs to server static files (like an Apache2, nginx or [http-server](https://www.npmjs.com/package/http-server)), nothing else – no PHP, node Node.js… Those apps (e.g. a simple todo-list) store all their data to your browser’s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now – but without giving your data away to a untrusted provider.\n\n![](/images/unhosted.jpg)\n\nThis is where quite a new thing called [RemoteStorage](https://remotestorage.io) comes in. It’s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the “official” PHP library to host one on your own server. There are also a few providers (like [5apps](http://5apps.com)) out there, yet, which you can use, but don’t have to, if you don’t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. _https://rs.yourserver.com/user1/appXyz_, and sync its data there. RemoteStorage works together with [WebFinger](https://webfinger.net). What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URL’s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type “remotestorage”. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In [this example](https://client.webfinger.net/lookup?resource=tony%405apps.com) the identifier *tony@5apps.com* maps to a *remotestorage* located at _https://storage.5apps.com/tony_. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldn’t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization – like which app may access which subkeys on the remoteStorage – is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.\n\nTwo apps you can try are [litewrite.net](https://litewrite.net/) and [Grouptabs](http://grouptabs.5apps.com). If you just want to play around with remoteStorage it might be the easiest way to use [5apps](http://5apps.com)‘ remoteStorage for this.","source":"_posts/unhostedorg-applications-with-remotestorageio-and-webfingernet.md","raw":"---\ntitle: Unhosted.org applications with remoteStorage.io and WebFinger.net\ndate: 2016-04-12 22:57:43\ntags:\n---\n\nLately you as an interested web developer might have heard or read about a thing called **unhosted applications**, mostly with a reference to [unhosted.org](http://unhosted.org/). This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps you’re using on the web store data to a backend service at the provider’s host server, regardless of them being Google Docs, Evernote, Wunderlist or also [Anchr.io](https://anchr.io). Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players – deciding whether that is better or worse it’s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then there’s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably you’ll need a webserver, but it only needs to server static files (like an Apache2, nginx or [http-server](https://www.npmjs.com/package/http-server)), nothing else – no PHP, node Node.js… Those apps (e.g. a simple todo-list) store all their data to your browser’s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now – but without giving your data away to a untrusted provider.\n\n![](/images/unhosted.jpg)\n\nThis is where quite a new thing called [RemoteStorage](https://remotestorage.io) comes in. It’s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the “official” PHP library to host one on your own server. There are also a few providers (like [5apps](http://5apps.com)) out there, yet, which you can use, but don’t have to, if you don’t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. _https://rs.yourserver.com/user1/appXyz_, and sync its data there. RemoteStorage works together with [WebFinger](https://webfinger.net). What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URL’s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type “remotestorage”. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In [this example](https://client.webfinger.net/lookup?resource=tony%405apps.com) the identifier *tony@5apps.com* maps to a *remotestorage* located at _https://storage.5apps.com/tony_. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldn’t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization – like which app may access which subkeys on the remoteStorage – is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.\n\nTwo apps you can try are [litewrite.net](https://litewrite.net/) and [Grouptabs](http://grouptabs.5apps.com). If you just want to play around with remoteStorage it might be the easiest way to use [5apps](http://5apps.com)‘ remoteStorage for this.","slug":"unhostedorg-applications-with-remotestorageio-and-webfingernet","published":1,"updated":"2017-05-03T20:58:34.646Z","_id":"cj29gsqnj000hqkqgxt2vsbco","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Lately you as an interested web developer might have heard or read about a thing called <strong>unhosted applications</strong>, mostly with a reference to <a href=\"http://unhosted.org/\" target=\"_blank\" rel=\"external\">unhosted.org</a>. This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps you’re using on the web store data to a backend service at the provider’s host server, regardless of them being Google Docs, Evernote, Wunderlist or also <a href=\"https://anchr.io\" target=\"_blank\" rel=\"external\">Anchr.io</a>. Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players – deciding whether that is better or worse it’s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then there’s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably you’ll need a webserver, but it only needs to server static files (like an Apache2, nginx or <a href=\"https://www.npmjs.com/package/http-server\" target=\"_blank\" rel=\"external\">http-server</a>), nothing else – no PHP, node Node.js… Those apps (e.g. a simple todo-list) store all their data to your browser’s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now – but without giving your data away to a untrusted provider.</p>\n<p><img src=\"/images/unhosted.jpg\" alt=\"\"></p>\n<p>This is where quite a new thing called <a href=\"https://remotestorage.io\" target=\"_blank\" rel=\"external\">RemoteStorage</a> comes in. It’s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the “official” PHP library to host one on your own server. There are also a few providers (like <a href=\"http://5apps.com\" target=\"_blank\" rel=\"external\">5apps</a>) out there, yet, which you can use, but don’t have to, if you don’t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. <em><a href=\"https://rs.yourserver.com/user1/appXyz\" target=\"_blank\" rel=\"external\">https://rs.yourserver.com/user1/appXyz</a></em>, and sync its data there. RemoteStorage works together with <a href=\"https://webfinger.net\" target=\"_blank\" rel=\"external\">WebFinger</a>. What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URL’s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type “remotestorage”. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In <a href=\"https://client.webfinger.net/lookup?resource=tony%405apps.com\" target=\"_blank\" rel=\"external\">this example</a> the identifier <em>tony@5apps.com</em> maps to a <em>remotestorage</em> located at <em><a href=\"https://storage.5apps.com/tony\" target=\"_blank\" rel=\"external\">https://storage.5apps.com/tony</a></em>. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldn’t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization – like which app may access which subkeys on the remoteStorage – is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.</p>\n<p>Two apps you can try are <a href=\"https://litewrite.net/\" target=\"_blank\" rel=\"external\">litewrite.net</a> and <a href=\"http://grouptabs.5apps.com\" target=\"_blank\" rel=\"external\">Grouptabs</a>. If you just want to play around with remoteStorage it might be the easiest way to use <a href=\"http://5apps.com\" target=\"_blank\" rel=\"external\">5apps</a>‘ remoteStorage for this.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Lately you as an interested web developer might have heard or read about a thing called <strong>unhosted applications</strong>, mostly with a reference to <a href=\"http://unhosted.org/\" target=\"_blank\" rel=\"external\">unhosted.org</a>. This basically means web-apps running in your browser which do not rely on any kind of backend. Most apps you’re using on the web store data to a backend service at the provider’s host server, regardless of them being Google Docs, Evernote, Wunderlist or also <a href=\"https://anchr.io\" target=\"_blank\" rel=\"external\">Anchr.io</a>. Obviously this makes you dependent on the provider in terms of availability and security. Also these apps are usually online-only apps, meaning that you can only use them with an internet connection. Another type of apps are those without a specific backend but still with a central, cloud-based data store, e.g. Firebase. In this case your data is still anywhere out there in the cloud at a provider you potentially could not trust (even though not on any kind of dubious private-hosted server but on a certified platform of one of the big players – deciding whether that is better or worse it’s up to you, actually). These apps are usually offline-capable, so you can use them without internet connection and if the connection comes back again, the data is synced to the data platform. And then there’s this third kind of apps, which they call unhosted ones. These are intended to be completely static, without needing any kind of backend. Theoretically you could download a zip of their HTML, JavaScript and CSS files to your computer and perfectly run the app without a webserver and a database. Well, ok, probably you’ll need a webserver, but it only needs to server static files (like an Apache2, nginx or <a href=\"https://www.npmjs.com/package/http-server\" target=\"_blank\" rel=\"external\">http-server</a>), nothing else – no PHP, node Node.js… Those apps (e.g. a simple todo-list) store all their data to your browser’s localStorage or IndexedDB. As a result it obviously is only available on your local computer and only until you clear you browser data. After all you might still want to sync your data to other devices now – but without giving your data away to a untrusted provider.</p>\n<p><img src=\"/images/unhosted.jpg\" alt=\"\"></p>\n<p>This is where quite a new thing called <a href=\"https://remotestorage.io\" target=\"_blank\" rel=\"external\">RemoteStorage</a> comes in. It’s a protocol for storing per-user data on the web in an unhosted fasion. Anything implementing the remoteStorage protocol can be your data-repository, which basically works as a simple key-value store. As a result you can implement your own remoteStorage or e.g. take the “official” PHP library to host one on your own server. There are also a few providers (like <a href=\"http://5apps.com\" target=\"_blank\" rel=\"external\">5apps</a>) out there, yet, which you can use, but don’t have to, if you don’t trust them. An unhosted-app that is remoteStorage-capable can now connect to your remoteStorage, e.g. <em><a href=\"https://rs.yourserver.com/user1/appXyz\" target=\"_blank\" rel=\"external\">https://rs.yourserver.com/user1/appXyz</a></em>, and sync its data there. RemoteStorage works together with <a href=\"https://webfinger.net\" target=\"_blank\" rel=\"external\">WebFinger</a>. What is WebFinger now? WebFinger is kind of a registry on the web, where unique keys (usually in email-address style, like user1@yourserver.com), are mapped to URL’s for a certain type of relation. In this case you would tell your unhosted app such an email-address-like identifier, which maps to your remoteStorage-endpoint for the relation-type “remotestorage”. The app queries WebFinger for that key and follows the returned registered URL to the datastore. In <a href=\"https://client.webfinger.net/lookup?resource=tony%405apps.com\" target=\"_blank\" rel=\"external\">this example</a> the identifier <em>tony@5apps.com</em> maps to a <em>remotestorage</em> located at <em><a href=\"https://storage.5apps.com/tony\" target=\"_blank\" rel=\"external\">https://storage.5apps.com/tony</a></em>. This makes the entire thing as decentralized as possible. Note that you could change your remoteStorage anytime by simply registering a new URL at WebFinger (you usually wouldn’t have to do this registration on your own, but the remoteStorage server implementation handles that for you). The authorization – like which app may access which subkeys on the remoteStorage – is handled by OAuth at your remoteStorage server implementation, where you can grant or revoke access for certain apps to certain store keys.</p>\n<p>Two apps you can try are <a href=\"https://litewrite.net/\" target=\"_blank\" rel=\"external\">litewrite.net</a> and <a href=\"http://grouptabs.5apps.com\" target=\"_blank\" rel=\"external\">Grouptabs</a>. If you just want to play around with remoteStorage it might be the easiest way to use <a href=\"http://5apps.com\" target=\"_blank\" rel=\"external\">5apps</a>‘ remoteStorage for this.</p>\n"},{"title":"Telegram: ExpenseBot & DoodlerBot","date":"2016-05-08T20:59:33.000Z","_content":"\n\nIn 2015, the [Telegram](https://telegram.org) messenger announced their [Bots](https://core.telegram.org/bots). Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias – all within an ordinary Telegram chat. You send them message, they give answers – some more and some less intelligent. Recently, also other companies – like [Facebook](http://techcrunch.com/2016/04/07/facebook-chatbots/) or [Microsoft](https://dev.botframework.com/) – announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.\n\nFrom a developer’s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.\n\nI’ve recently created two bots for Telegram that should each help with a daily task.\n\n### ExpenseBot – Keep track of your finances\n\n![1461614801_Money-Increase](/images/expensebot_icon.png)\n\nThis bot’s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to *[@ExpenseBot](https://telegram.me/ExpenseBot)* in Telegram.\n\n### DoodlerBot – Coordinate group appointments\n\n![1462726473_calendar](/images/doodlerbot_icon.png)\n\nMy second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from [doodle.com](http://doodle.com) (even though it doesn’t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to *[@DoodlerBot](https://telegram.me/DoodlerBot)* in Telegram.\n\nBoth projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with */help* to it.\n\nIn case you like my bots, I’d be really happy if you rated them at [https://storebot.me/bot/expensebot](https://storebot.me/bot/expensebot) and [https://storebot.me/bot/doodlerbot](https://storebot.me/bot/doodlerbot). Have fun!","source":"_posts/telegram-expensebot-doodlerbot.md","raw":"---\ntitle: 'Telegram: ExpenseBot & DoodlerBot'\ndate: 2016-05-08 22:59:33\ntags:\n---\n\n\nIn 2015, the [Telegram](https://telegram.org) messenger announced their [Bots](https://core.telegram.org/bots). Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias – all within an ordinary Telegram chat. You send them message, they give answers – some more and some less intelligent. Recently, also other companies – like [Facebook](http://techcrunch.com/2016/04/07/facebook-chatbots/) or [Microsoft](https://dev.botframework.com/) – announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.\n\nFrom a developer’s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.\n\nI’ve recently created two bots for Telegram that should each help with a daily task.\n\n### ExpenseBot – Keep track of your finances\n\n![1461614801_Money-Increase](/images/expensebot_icon.png)\n\nThis bot’s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to *[@ExpenseBot](https://telegram.me/ExpenseBot)* in Telegram.\n\n### DoodlerBot – Coordinate group appointments\n\n![1462726473_calendar](/images/doodlerbot_icon.png)\n\nMy second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from [doodle.com](http://doodle.com) (even though it doesn’t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to *[@DoodlerBot](https://telegram.me/DoodlerBot)* in Telegram.\n\nBoth projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with */help* to it.\n\nIn case you like my bots, I’d be really happy if you rated them at [https://storebot.me/bot/expensebot](https://storebot.me/bot/expensebot) and [https://storebot.me/bot/doodlerbot](https://storebot.me/bot/doodlerbot). Have fun!","slug":"telegram-expensebot-doodlerbot","published":1,"updated":"2017-05-03T21:00:10.276Z","_id":"cj29gugr0000iqkqgu2w4psfh","comments":1,"layout":"post","photos":[],"link":"","content":"<p>In 2015, the <a href=\"https://telegram.org\" target=\"_blank\" rel=\"external\">Telegram</a> messenger announced their <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"external\">Bots</a>. Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias – all within an ordinary Telegram chat. You send them message, they give answers – some more and some less intelligent. Recently, also other companies – like <a href=\"http://techcrunch.com/2016/04/07/facebook-chatbots/\" target=\"_blank\" rel=\"external\">Facebook</a> or <a href=\"https://dev.botframework.com/\" target=\"_blank\" rel=\"external\">Microsoft</a> – announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.</p>\n<p>From a developer’s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.</p>\n<p>I’ve recently created two bots for Telegram that should each help with a daily task.</p>\n<h3 id=\"ExpenseBot-–-Keep-track-of-your-finances\"><a href=\"#ExpenseBot-–-Keep-track-of-your-finances\" class=\"headerlink\" title=\"ExpenseBot – Keep track of your finances\"></a>ExpenseBot – Keep track of your finances</h3><p><img src=\"/images/expensebot_icon.png\" alt=\"1461614801_Money-Increase\"></p>\n<p>This bot’s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/ExpenseBot\" target=\"_blank\" rel=\"external\">@ExpenseBot</a></em> in Telegram.</p>\n<h3 id=\"DoodlerBot-–-Coordinate-group-appointments\"><a href=\"#DoodlerBot-–-Coordinate-group-appointments\" class=\"headerlink\" title=\"DoodlerBot – Coordinate group appointments\"></a>DoodlerBot – Coordinate group appointments</h3><p><img src=\"/images/doodlerbot_icon.png\" alt=\"1462726473_calendar\"></p>\n<p>My second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from <a href=\"http://doodle.com\" target=\"_blank\" rel=\"external\">doodle.com</a> (even though it doesn’t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/DoodlerBot\" target=\"_blank\" rel=\"external\">@DoodlerBot</a></em> in Telegram.</p>\n<p>Both projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with <em>/help</em> to it.</p>\n<p>In case you like my bots, I’d be really happy if you rated them at <a href=\"https://storebot.me/bot/expensebot\" target=\"_blank\" rel=\"external\">https://storebot.me/bot/expensebot</a> and <a href=\"https://storebot.me/bot/doodlerbot\" target=\"_blank\" rel=\"external\">https://storebot.me/bot/doodlerbot</a>. Have fun!</p>\n","site":{"data":{}},"excerpt":"","more":"<p>In 2015, the <a href=\"https://telegram.org\" target=\"_blank\" rel=\"external\">Telegram</a> messenger announced their <a href=\"https://core.telegram.org/bots\" target=\"_blank\" rel=\"external\">Bots</a>. Basically they are pieces of software that act like a normal chat user in many ways. They could have any functionality, from being helpful at daily tasks to even simple games or trivias – all within an ordinary Telegram chat. You send them message, they give answers – some more and some less intelligent. Recently, also other companies – like <a href=\"http://techcrunch.com/2016/04/07/facebook-chatbots/\" target=\"_blank\" rel=\"external\">Facebook</a> or <a href=\"https://dev.botframework.com/\" target=\"_blank\" rel=\"external\">Microsoft</a> – announced such bots for their messaging apps. Sometimes bots are even considered kind of the next step after native (web-) applications in the future.</p>\n<p>From a developer’s perspective, making a bot is fun, because there are almost no restrictions on how to develop your bot. All communication with Telegram works by requesting a single REST API provided by them. Choices like which programming language and -framework to use and how to structure the code are completely up to the developer. A Telegram bot can theoretically be built in any programming language. The only requirements are to be able to make HTTP request from the application and to have a server to host the bot on.</p>\n<p>I’ve recently created two bots for Telegram that should each help with a daily task.</p>\n<h3 id=\"ExpenseBot-–-Keep-track-of-your-finances\"><a href=\"#ExpenseBot-–-Keep-track-of-your-finances\" class=\"headerlink\" title=\"ExpenseBot – Keep track of your finances\"></a>ExpenseBot – Keep track of your finances</h3><p><img src=\"/images/expensebot_icon.png\" alt=\"1461614801_Money-Increase\"></p>\n<p>This bot’s purpose is to help people manage their daily expenses and keep track of their financial situation. Users can add expenses from wherever they are using a few simple commands from within the chat and have an eye on how much they have spent in a month or a day. This obviates the need for confusing Excel spreadsheets or paper notes. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/ExpenseBot\" target=\"_blank\" rel=\"external\">@ExpenseBot</a></em> in Telegram.</p>\n<h3 id=\"DoodlerBot-–-Coordinate-group-appointments\"><a href=\"#DoodlerBot-–-Coordinate-group-appointments\" class=\"headerlink\" title=\"DoodlerBot – Coordinate group appointments\"></a>DoodlerBot – Coordinate group appointments</h3><p><img src=\"/images/doodlerbot_icon.png\" alt=\"1462726473_calendar\"></p>\n<p>My second bot helps users coordinate a group of people and find the right date for a common appointment, just like you might know from <a href=\"http://doodle.com\" target=\"_blank\" rel=\"external\">doodle.com</a> (even though it doesn’t have anything to do with that commercial service, except for fulfilling the same need). Open a new doodle and let your mates in the group chat vote for their preferred date to finally make the best decision for everyone. You can reach the bot by sending a Message to <em><a href=\"https://telegram.me/DoodlerBot\" target=\"_blank\" rel=\"external\">@DoodlerBot</a></em> in Telegram.</p>\n<p>Both projects are completely independent, non-commercial and privately operated. If you have any questions our found a bug (both bots are still in beta phase and therefore might show some unexpected behavior), please contact me at @n1try or via e-mail. In both cases, you should first read a basic introduction on how to use the respective bot, by sending a message with <em>/help</em> to it.</p>\n<p>In case you like my bots, I’d be really happy if you rated them at <a href=\"https://storebot.me/bot/expensebot\" target=\"_blank\" rel=\"external\">https://storebot.me/bot/expensebot</a> and <a href=\"https://storebot.me/bot/doodlerbot\" target=\"_blank\" rel=\"external\">https://storebot.me/bot/doodlerbot</a>. Have fun!</p>\n"},{"title":"Innovation in Germany - not","date":"2016-05-19T21:00:53.000Z","_content":"\nOver last last while I got confronted with this topic quite frequently. Eventually [this german article](http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/) – or more precisely the comments below it – caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider “Unitymedia” came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called “WifiSpots”. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customer’s own network – in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most people’s routers are nowhere near working at capacity anyway. And if it’s guaranteed that the public internet traffic doesn’t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:\n\n*\"That’s exactly the reason why innovation isn’t possible in Germany. As soon as a company tries to solve people’s problems, everybody goes to the barricades. One gets punished for experiments – not surprisingly nobody wants to found a company.\"*\n\nEven though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually don’t think they are – at least not as much as they once were. I went to a conference on [Industry 4.0](https://en.wikipedia.org/wiki/Industry_4.0) last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds – and I claim that if not applied totally wrong, new technology is likely to – they are given a competitive advantage, while the current big players’ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But you’re also so much more likely to win big. As a professor at university had repeatedly said: “think big!”.\n\n***\"If your dreams do not scare you, they are not big enough! – Ellen Johnson Sirleaf\"***\n\nThat’s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, …) the contrast would be even more dramatic. Take Elon Musk – the founder of Tesla Motors and SpaceX – (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I don’t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX – they just do it.\n\n[![](/images/statista.png)](http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/)\nSource: Statista.com\n\nAnother example for Germany’s innovation power is the following. I’ve worked for two different companies as a working student – both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employee’s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I don’t want to blame that company – they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily it’s the people’s mindset that differentiates those two companies completely. I can’t really imagine that this first company is a workplace where you really feel comfortable and where you’re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The app’s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And there’s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies – of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).\n\nAnother alarming fact I want to mention in this context is that the [average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam](https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings).\n\n***\"Once a new technology rolls over you, if you’re not part of the steamroller, you’re part of the road. — Stewart Brand\"***\n\nWhat this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution – or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.","source":"_posts/innovation-in-germany-not.md","raw":"---\ntitle: Innovation in Germany - not\ndate: 2016-05-19 23:00:53\ntags:\n---\n\nOver last last while I got confronted with this topic quite frequently. Eventually [this german article](http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/) – or more precisely the comments below it – caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider “Unitymedia” came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called “WifiSpots”. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customer’s own network – in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most people’s routers are nowhere near working at capacity anyway. And if it’s guaranteed that the public internet traffic doesn’t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:\n\n*\"That’s exactly the reason why innovation isn’t possible in Germany. As soon as a company tries to solve people’s problems, everybody goes to the barricades. One gets punished for experiments – not surprisingly nobody wants to found a company.\"*\n\nEven though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually don’t think they are – at least not as much as they once were. I went to a conference on [Industry 4.0](https://en.wikipedia.org/wiki/Industry_4.0) last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds – and I claim that if not applied totally wrong, new technology is likely to – they are given a competitive advantage, while the current big players’ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But you’re also so much more likely to win big. As a professor at university had repeatedly said: “think big!”.\n\n***\"If your dreams do not scare you, they are not big enough! – Ellen Johnson Sirleaf\"***\n\nThat’s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, …) the contrast would be even more dramatic. Take Elon Musk – the founder of Tesla Motors and SpaceX – (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I don’t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX – they just do it.\n\n[![](/images/statista.png)](http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/)\nSource: Statista.com\n\nAnother example for Germany’s innovation power is the following. I’ve worked for two different companies as a working student – both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employee’s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I don’t want to blame that company – they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily it’s the people’s mindset that differentiates those two companies completely. I can’t really imagine that this first company is a workplace where you really feel comfortable and where you’re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The app’s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And there’s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies – of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).\n\nAnother alarming fact I want to mention in this context is that the [average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam](https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings).\n\n***\"Once a new technology rolls over you, if you’re not part of the steamroller, you’re part of the road. — Stewart Brand\"***\n\nWhat this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution – or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.","slug":"innovation-in-germany-not","published":1,"updated":"2017-05-03T21:01:16.762Z","_id":"cj29gw6w1000jqkqghb1fg84o","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Over last last while I got confronted with this topic quite frequently. Eventually <a href=\"http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/\" target=\"_blank\" rel=\"external\">this german article</a> – or more precisely the comments below it – caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider “Unitymedia” came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called “WifiSpots”. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customer’s own network – in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most people’s routers are nowhere near working at capacity anyway. And if it’s guaranteed that the public internet traffic doesn’t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:</p>\n<p><em>“That’s exactly the reason why innovation isn’t possible in Germany. As soon as a company tries to solve people’s problems, everybody goes to the barricades. One gets punished for experiments – not surprisingly nobody wants to found a company.”</em></p>\n<p>Even though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually don’t think they are – at least not as much as they once were. I went to a conference on <a href=\"https://en.wikipedia.org/wiki/Industry_4.0\" target=\"_blank\" rel=\"external\">Industry 4.0</a> last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds – and I claim that if not applied totally wrong, new technology is likely to – they are given a competitive advantage, while the current big players’ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But you’re also so much more likely to win big. As a professor at university had repeatedly said: “think big!”.</p>\n<p><strong><em>“If your dreams do not scare you, they are not big enough! – Ellen Johnson Sirleaf”</em></strong></p>\n<p>That’s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, …) the contrast would be even more dramatic. Take Elon Musk – the founder of Tesla Motors and SpaceX – (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I don’t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX – they just do it.</p>\n<p><a href=\"http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/\" target=\"_blank\" rel=\"external\"><img src=\"/images/statista.png\" alt=\"\"></a><br>Source: Statista.com</p>\n<p>Another example for Germany’s innovation power is the following. I’ve worked for two different companies as a working student – both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employee’s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I don’t want to blame that company – they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily it’s the people’s mindset that differentiates those two companies completely. I can’t really imagine that this first company is a workplace where you really feel comfortable and where you’re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The app’s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And there’s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies – of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).</p>\n<p>Another alarming fact I want to mention in this context is that the <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings\" target=\"_blank\" rel=\"external\">average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam</a>.</p>\n<p><strong><em>“Once a new technology rolls over you, if you’re not part of the steamroller, you’re part of the road. — Stewart Brand”</em></strong></p>\n<p>What this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution – or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Over last last while I got confronted with this topic quite frequently. Eventually <a href=\"http://t3n.de/news/hotspots-unitymedia-abgemahnt-707512/\" target=\"_blank\" rel=\"external\">this german article</a> – or more precisely the comments below it – caused me to write my own little post on my personal perception of how innovation takes place in Germany. For the non-german readers among us I want to give a brief summary of that article. Recently the german internet provider “Unitymedia” came up with the idea to provide free WiFi-Hotspots for everyone, since internet connection in public places is pretty much a negative report in Germany. The key point with that is their intention of how to implement those so called “WifiSpots”. Every Unitymedia customer who has a Wifi-capable router in her home should become such a hotspot, while they promise that the hotspot network is completely isolated from the customer’s own network – in terms of both security and bandwidth. Personally I like the idea, because I consider it quite efficient. Why put effort in distributing routers in public places if there already is full Wifi coverage? Most people’s routers are nowhere near working at capacity anyway. And if it’s guaranteed that the public internet traffic doesn’t influence you at all, why not? The article tells that the consumer protection center of North Rhine-Westphalia had admonished Unitymedia for their plans recently. One of the top comments below the article says about the following:</p>\n<p><em>“That’s exactly the reason why innovation isn’t possible in Germany. As soon as a company tries to solve people’s problems, everybody goes to the barricades. One gets punished for experiments – not surprisingly nobody wants to found a company.”</em></p>\n<p>Even though the comment received a lot of bad write-up, that boils it down for me quite well. In my opinion Germany is ways too sluggish and conservative when it comes to adapting something new. Even though most representatives of the german manufacture consider themselves progressive, I actually don’t think they are – at least not as much as they once were. I went to a conference on <a href=\"https://en.wikipedia.org/wiki/Industry_4.0\" target=\"_blank\" rel=\"external\">Industry 4.0</a> last week where one speaker claimed that Germany was at least one to two years ahead of other countries at Industry 4.0 topics, but what I picked out between the lines is that quite the opposite is true. While the Germany are continuously trying to define standards, develop well-defined business-processes, clarify legal aspects and the like other countries are just doing it. They simply try it out, taking not too much risk, and if it fails, it fails. But if it succeeds – and I claim that if not applied totally wrong, new technology is likely to – they are given a competitive advantage, while the current big players’ lead is melting. Of course, with this attitude you are more likely to fail as if you examine every little aspect fussily. But you’re also so much more likely to win big. As a professor at university had repeatedly said: “think big!”.</p>\n<p><strong><em>“If your dreams do not scare you, they are not big enough! – Ellen Johnson Sirleaf”</em></strong></p>\n<p>That’s what often is referred to as the Silicon valley mindset. In fact, as the diagram below shows, most startups are founded in the U.S.A. and I guess if there was a ranking of really big and successful startups (like Uber, WhatsApp, Tesla, …) the contrast would be even more dramatic. Take Elon Musk – the founder of Tesla Motors and SpaceX – (I really recommend his biography) as an instance. He thought big and he obviously won (admittedly he took a really high risk). I don’t think they evaluate and plan new technology (like VR and stuff) that much at SpaceX – they just do it.</p>\n<p><a href=\"http://www.statista.com/statistics/268786/start-ups-in-leading-economic-nations/\" target=\"_blank\" rel=\"external\"><img src=\"/images/statista.png\" alt=\"\"></a><br>Source: Statista.com</p>\n<p>Another example for Germany’s innovation power is the following. I’ve worked for two different companies as a working student – both were software manufacturers. One was a typical german medium-sized company and the other was an american corporation. In one of them, the second-latest version of Internet Explorer was the only browser installed on every employee’s computer and if you desired another, you had to open a ticket to make the software distribution department install an outdated version of Firefox a few hours later. I don’t want to blame that company – they did a great job at what they did. But the overall way of thinking there was old-fashioned, strict and not open-minded at all. Primarily it’s the people’s mindset that differentiates those two companies completely. I can’t really imagine that this first company is a workplace where you really feel comfortable and where you’re looking forward to a workday. At the time I worked there, they were about to release a little mobile app, whose development effort I estimate to only few weeks of intensive work of a small group of developers. The app’s purpose was great, but unfortunately, it was modern and innovative. Therefore there were only too few people to insistently support it. And there’s also the fact that processes were ways too sluggish to do a rapid development. As a result the app is still not released, but instead, two american countries each released an app with pretty much the exact same purpose. So much for that mindset in german companies – of course and as always, there definitely are exceptions (a really big global player originated in Germany at which one department prints out document to hand it over to the other department, at which a trainee typewrites it to make it digital again, not being one of them).</p>\n<p>Another alarming fact I want to mention in this context is that the <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_Internet_connection_speeds#Akamai_Q3_2015_rankings\" target=\"_blank\" rel=\"external\">average internet speed in Germany is even far behind countries like Sri-Lanka and Vietnam</a>.</p>\n<p><strong><em>“Once a new technology rolls over you, if you’re not part of the steamroller, you’re part of the road. — Stewart Brand”</em></strong></p>\n<p>What this all amounts to is that Germany should really watch out to not get passed by countries where the people are more ambitious and motivated and less conservative and formal. We should never rest on our laurels but try to permanently improve in a continuous evolution – or to quote many speakers at the conference mentioned above: to not fall into the process of disruptive self-destruction.</p>\n"},{"title":"Migrate Maildir to new server using imapsync","date":"2016-07-23T21:01:44.000Z","_content":"\n\nThis is a little tutorial for mailserver administrators, who want to *migrate* to a new server while *keeping all e-mails*. This works for mailservers whose MDA uses the [Maildir](https://en.wikipedia.org/wiki/Maildir) format – like Dovecot by default – and have *IMAP* enabled.  \nThis tutorial does *not* cover how to set up and configure a new mailserver on a new machine, based on the old one’s configuration, but only how to migrate the e-mails. Simply *tar*ing the Maildir folder and un_tar_ing it on the new machine again usually won’t work. But don’t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocol’s methods. Therefore, we use a tool *imapsync*, which is written Perl. It acts as an ordinary IMAP client – just as Outlook or Thunderbird – that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one “manual” way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&Drop them over to the new one. imapsync does just that – yet automatically and without Outlook or Thunderbird.\n\nFirst we need to *install imapsync*. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2\\. And since your local internet connection is probably ways slower then the servers’, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserver’s host machine. Let’s do it.\n\n1.  Clone the imapsync repository to any folder on your machine, e.g. `/opt/imapsync`: `git clone https://github.com/imapsync/imapsync`\n\n2.  Read the installation notes for your specific operation system at [https://github.com/imapsync/imapsync/tree/master/INSTALL.d](https://github.com/imapsync/imapsync/tree/master/INSTALL.d) and do exactly what’s described there. Usually, you will need to install some dependencies and the like.\n\n3.  Now you should be able to execute `./imapsync` from within the directory where you have cloned it to, e.g. `/opt/imapsync`. You should see a description on how to use the program.\n\nLet’s now assume that you want to migrate mails from your old server with ip *12.34.45.78* for user “*foo@example.org”* with password “*suchsecret”* to your new server with ip *98.76.54.32*. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, let’s assume that on the new machine the user, as it makes sense, is called “*foo@example.org”* again, but his password is “*ssshhhhh”* now and that both MDAs require a *TLS*-secured connection, use standard *PLAIN* login method and are listening on *port 143*.\n\nTo perform the migration now, run the following command:\n\n```bash\n./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2\n```\n\nNow all mails should be transferred from `host1` through the imapsync client to `host2`, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the `--dry` option to the above command.\n\nTo migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: [https://wiki.ubuntuusers.de/imapsync/#Massenmigration](https://wiki.ubuntuusers.de/imapsync/#Massenmigration) (although that article is in German, the code should be clear).","source":"_posts/migrate-maildir-to-new-server-using-imapsync.md","raw":"---\ntitle: Migrate Maildir to new server using imapsync\ndate: 2016-07-23 23:01:44\ntags:\n---\n\n\nThis is a little tutorial for mailserver administrators, who want to *migrate* to a new server while *keeping all e-mails*. This works for mailservers whose MDA uses the [Maildir](https://en.wikipedia.org/wiki/Maildir) format – like Dovecot by default – and have *IMAP* enabled.  \nThis tutorial does *not* cover how to set up and configure a new mailserver on a new machine, based on the old one’s configuration, but only how to migrate the e-mails. Simply *tar*ing the Maildir folder and un_tar_ing it on the new machine again usually won’t work. But don’t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocol’s methods. Therefore, we use a tool *imapsync*, which is written Perl. It acts as an ordinary IMAP client – just as Outlook or Thunderbird – that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one “manual” way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&Drop them over to the new one. imapsync does just that – yet automatically and without Outlook or Thunderbird.\n\nFirst we need to *install imapsync*. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2\\. And since your local internet connection is probably ways slower then the servers’, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserver’s host machine. Let’s do it.\n\n1.  Clone the imapsync repository to any folder on your machine, e.g. `/opt/imapsync`: `git clone https://github.com/imapsync/imapsync`\n\n2.  Read the installation notes for your specific operation system at [https://github.com/imapsync/imapsync/tree/master/INSTALL.d](https://github.com/imapsync/imapsync/tree/master/INSTALL.d) and do exactly what’s described there. Usually, you will need to install some dependencies and the like.\n\n3.  Now you should be able to execute `./imapsync` from within the directory where you have cloned it to, e.g. `/opt/imapsync`. You should see a description on how to use the program.\n\nLet’s now assume that you want to migrate mails from your old server with ip *12.34.45.78* for user “*foo@example.org”* with password “*suchsecret”* to your new server with ip *98.76.54.32*. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, let’s assume that on the new machine the user, as it makes sense, is called “*foo@example.org”* again, but his password is “*ssshhhhh”* now and that both MDAs require a *TLS*-secured connection, use standard *PLAIN* login method and are listening on *port 143*.\n\nTo perform the migration now, run the following command:\n\n```bash\n./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2\n```\n\nNow all mails should be transferred from `host1` through the imapsync client to `host2`, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the `--dry` option to the above command.\n\nTo migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: [https://wiki.ubuntuusers.de/imapsync/#Massenmigration](https://wiki.ubuntuusers.de/imapsync/#Massenmigration) (although that article is in German, the code should be clear).","slug":"migrate-maildir-to-new-server-using-imapsync","published":1,"updated":"2017-05-03T21:01:58.241Z","_id":"cj29gxaa1000kqkqg3j9iyq03","comments":1,"layout":"post","photos":[],"link":"","content":"<p>This is a little tutorial for mailserver administrators, who want to <em>migrate</em> to a new server while <em>keeping all e-mails</em>. This works for mailservers whose MDA uses the <a href=\"https://en.wikipedia.org/wiki/Maildir\" target=\"_blank\" rel=\"external\">Maildir</a> format – like Dovecot by default – and have <em>IMAP</em> enabled.<br>This tutorial does <em>not</em> cover how to set up and configure a new mailserver on a new machine, based on the old one’s configuration, but only how to migrate the e-mails. Simply <em>tar</em>ing the Maildir folder and un_tar_ing it on the new machine again usually won’t work. But don’t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocol’s methods. Therefore, we use a tool <em>imapsync</em>, which is written Perl. It acts as an ordinary IMAP client – just as Outlook or Thunderbird – that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one “manual” way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&amp;Drop them over to the new one. imapsync does just that – yet automatically and without Outlook or Thunderbird.</p>\n<p>First we need to <em>install imapsync</em>. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2. And since your local internet connection is probably ways slower then the servers’, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserver’s host machine. Let’s do it.</p>\n<ol>\n<li><p>Clone the imapsync repository to any folder on your machine, e.g. <code>/opt/imapsync</code>: <code>git clone https://github.com/imapsync/imapsync</code></p>\n</li>\n<li><p>Read the installation notes for your specific operation system at <a href=\"https://github.com/imapsync/imapsync/tree/master/INSTALL.d\" target=\"_blank\" rel=\"external\">https://github.com/imapsync/imapsync/tree/master/INSTALL.d</a> and do exactly what’s described there. Usually, you will need to install some dependencies and the like.</p>\n</li>\n<li><p>Now you should be able to execute <code>./imapsync</code> from within the directory where you have cloned it to, e.g. <code>/opt/imapsync</code>. You should see a description on how to use the program.</p>\n</li>\n</ol>\n<p>Let’s now assume that you want to migrate mails from your old server with ip <em>12.34.45.78</em> for user “<em>foo@example.org”</em> with password “<em>suchsecret”</em> to your new server with ip <em>98.76.54.32</em>. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, let’s assume that on the new machine the user, as it makes sense, is called “<em>foo@example.org”</em> again, but his password is “<em>ssshhhhh”</em> now and that both MDAs require a <em>TLS</em>-secured connection, use standard <em>PLAIN</em> login method and are listening on <em>port 143</em>.</p>\n<p>To perform the migration now, run the following command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2</div></pre></td></tr></table></figure>\n<p>Now all mails should be transferred from <code>host1</code> through the imapsync client to <code>host2</code>, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the <code>--dry</code> option to the above command.</p>\n<p>To migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: <a href=\"https://wiki.ubuntuusers.de/imapsync/#Massenmigration\" target=\"_blank\" rel=\"external\">https://wiki.ubuntuusers.de/imapsync/#Massenmigration</a> (although that article is in German, the code should be clear).</p>\n","site":{"data":{}},"excerpt":"","more":"<p>This is a little tutorial for mailserver administrators, who want to <em>migrate</em> to a new server while <em>keeping all e-mails</em>. This works for mailservers whose MDA uses the <a href=\"https://en.wikipedia.org/wiki/Maildir\" target=\"_blank\" rel=\"external\">Maildir</a> format – like Dovecot by default – and have <em>IMAP</em> enabled.<br>This tutorial does <em>not</em> cover how to set up and configure a new mailserver on a new machine, based on the old one’s configuration, but only how to migrate the e-mails. Simply <em>tar</em>ing the Maildir folder and un_tar_ing it on the new machine again usually won’t work. But don’t worry, there is a cleaner way that abstracts away any actual mailserver or file-level considerations by only using the IMAP protocol’s methods. Therefore, we use a tool <em>imapsync</em>, which is written Perl. It acts as an ordinary IMAP client – just as Outlook or Thunderbird – that connects to both mailservers, the old and the new one. All information needed is how to authenticate the respective user with both servers. Actually one “manual” way to migrate the mails would be to set up both mail accounts in Outlook or Thunderbird, let download the mails via IMAP from the old one and Ctrl+A and Drag&amp;Drop them over to the new one. imapsync does just that – yet automatically and without Outlook or Thunderbird.</p>\n<p>First we need to <em>install imapsync</em>. You could install imapsync on your local PC, just as you would with Outlook or Thunderbird, but then there would be a unnecessary detour from server 1 over your PC to server 2. And since your local internet connection is probably ways slower then the servers’, your PC would be a bottleneck. So I recommend to install imapsync on either the old or the new mailserver’s host machine. Let’s do it.</p>\n<ol>\n<li><p>Clone the imapsync repository to any folder on your machine, e.g. <code>/opt/imapsync</code>: <code>git clone https://github.com/imapsync/imapsync</code></p>\n</li>\n<li><p>Read the installation notes for your specific operation system at <a href=\"https://github.com/imapsync/imapsync/tree/master/INSTALL.d\" target=\"_blank\" rel=\"external\">https://github.com/imapsync/imapsync/tree/master/INSTALL.d</a> and do exactly what’s described there. Usually, you will need to install some dependencies and the like.</p>\n</li>\n<li><p>Now you should be able to execute <code>./imapsync</code> from within the directory where you have cloned it to, e.g. <code>/opt/imapsync</code>. You should see a description on how to use the program.</p>\n</li>\n</ol>\n<p>Let’s now assume that you want to migrate mails from your old server with ip <em>12.34.45.78</em> for user “<em>foo@example.org”</em> with password “<em>suchsecret”</em> to your new server with ip <em>98.76.54.32</em>. A prerequisite is that on both machines the mailserver is up and running and the respective user is configured. Further, let’s assume that on the new machine the user, as it makes sense, is called “<em>foo@example.org”</em> again, but his password is “<em>ssshhhhh”</em> now and that both MDAs require a <em>TLS</em>-secured connection, use standard <em>PLAIN</em> login method and are listening on <em>port 143</em>.</p>\n<p>To perform the migration now, run the following command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./imapsync --host1 12.34.45.78 --user1 foo@example.org --password1 suchsecret --authmech1 PLAIN --tls1 --host2 98.76.54.32 --user2 foo@example.org --password2 ssshhhhh --authmech2 PLAIN --tls2</div></pre></td></tr></table></figure>\n<p>Now all mails should be transferred from <code>host1</code> through the imapsync client to <code>host2</code>, using nothing but the IMAP protocol. If you want to test if everything is working fine first, before actually transferring data, you could add the <code>--dry</code> option to the above command.</p>\n<p>To migrate multiple accounts at once, you could write a small scripts that takes username-password combinations from a text file, as described here: <a href=\"https://wiki.ubuntuusers.de/imapsync/#Massenmigration\" target=\"_blank\" rel=\"external\">https://wiki.ubuntuusers.de/imapsync/#Massenmigration</a> (although that article is in German, the code should be clear).</p>\n"},{"title":"Webdevlist.net - The Developer's Resource Collection","date":"2016-09-21T21:02:25.000Z","_content":"\n![](/images/webdevlist.jpg)\n\nI just put up a new project of mine, which is called Webdevlist.\n\n### So what is Webdevlist?\n\nI’m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like _“Wow that’s cool! Could be helpful some time. I need to remember it.”_ Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlist’s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime you’re looking for a tool to help you with your development problems come visit the list. Easy enough.\n\n### Tech facts\n\nWebdevlist’s frontend is built with [Angular2](https://angular.io/ \"Angular2\"), which just has had its first final release. The backend makes use of [LoopbackJS](http://loopback.io/ \"LoopbackJS\"), which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.\n\n### Is it finished, yet?\n\nNo, it isn’t. Actually, it probably never will be. I’m continuously going to add new technology to Webdevlist’s stack and change and refactor things. Currently I’m considering to switch to [GraphQL](http://graphql.org/learn/ \"GraphQL\"). Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.\n\nI’d really appreciate to get feedback on this project!\n\n[>> Webdevlist.net](https://webdevlist.net)  \n[>> Webdevlist on GitHub](https://github.com/n1try/webdevlist.net) ","source":"_posts/webdevlistnet-the-developers-resource-collection.md","raw":"---\ntitle: Webdevlist.net - The Developer's Resource Collection\ndate: 2016-09-21 23:02:25\ntags:\n---\n\n![](/images/webdevlist.jpg)\n\nI just put up a new project of mine, which is called Webdevlist.\n\n### So what is Webdevlist?\n\nI’m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like _“Wow that’s cool! Could be helpful some time. I need to remember it.”_ Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlist’s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime you’re looking for a tool to help you with your development problems come visit the list. Easy enough.\n\n### Tech facts\n\nWebdevlist’s frontend is built with [Angular2](https://angular.io/ \"Angular2\"), which just has had its first final release. The backend makes use of [LoopbackJS](http://loopback.io/ \"LoopbackJS\"), which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.\n\n### Is it finished, yet?\n\nNo, it isn’t. Actually, it probably never will be. I’m continuously going to add new technology to Webdevlist’s stack and change and refactor things. Currently I’m considering to switch to [GraphQL](http://graphql.org/learn/ \"GraphQL\"). Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.\n\nI’d really appreciate to get feedback on this project!\n\n[>> Webdevlist.net](https://webdevlist.net)  \n[>> Webdevlist on GitHub](https://github.com/n1try/webdevlist.net) ","slug":"webdevlistnet-the-developers-resource-collection","published":1,"updated":"2017-05-03T21:02:52.850Z","_id":"cj29gye68000mqkqg3yl6ux20","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/webdevlist.jpg\" alt=\"\"></p>\n<p>I just put up a new project of mine, which is called Webdevlist.</p>\n<h3 id=\"So-what-is-Webdevlist\"><a href=\"#So-what-is-Webdevlist\" class=\"headerlink\" title=\"So what is Webdevlist?\"></a>So what is Webdevlist?</h3><p>I’m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like <em>“Wow that’s cool! Could be helpful some time. I need to remember it.”</em> Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlist’s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime you’re looking for a tool to help you with your development problems come visit the list. Easy enough.</p>\n<h3 id=\"Tech-facts\"><a href=\"#Tech-facts\" class=\"headerlink\" title=\"Tech facts\"></a>Tech facts</h3><p>Webdevlist’s frontend is built with <a href=\"https://angular.io/\" title=\"Angular2\" target=\"_blank\" rel=\"external\">Angular2</a>, which just has had its first final release. The backend makes use of <a href=\"http://loopback.io/\" title=\"LoopbackJS\" target=\"_blank\" rel=\"external\">LoopbackJS</a>, which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.</p>\n<h3 id=\"Is-it-finished-yet\"><a href=\"#Is-it-finished-yet\" class=\"headerlink\" title=\"Is it finished, yet?\"></a>Is it finished, yet?</h3><p>No, it isn’t. Actually, it probably never will be. I’m continuously going to add new technology to Webdevlist’s stack and change and refactor things. Currently I’m considering to switch to <a href=\"http://graphql.org/learn/\" title=\"GraphQL\" target=\"_blank\" rel=\"external\">GraphQL</a>. Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.</p>\n<p>I’d really appreciate to get feedback on this project!</p>\n<p><a href=\"https://webdevlist.net\" target=\"_blank\" rel=\"external\">&gt;&gt; Webdevlist.net</a><br><a href=\"https://github.com/n1try/webdevlist.net\" target=\"_blank\" rel=\"external\">&gt;&gt; Webdevlist on GitHub</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"/images/webdevlist.jpg\" alt=\"\"></p>\n<p>I just put up a new project of mine, which is called Webdevlist.</p>\n<h3 id=\"So-what-is-Webdevlist\"><a href=\"#So-what-is-Webdevlist\" class=\"headerlink\" title=\"So what is Webdevlist?\"></a>So what is Webdevlist?</h3><p>I’m pretty sure most developers know it all too well: you browse Twitter, Reddit or Stackoverflow on a late Sunday evening and come across some cool programming framework or webservice. You think like <em>“Wow that’s cool! Could be helpful some time. I need to remember it.”</em> Then you put the link anywhere in a messy text file or the like and never visit it again. Webdevlist’s aim is to become a comprehensive, community-maintained collection of useful resources concerning software development. Such could include frameworks and libraries for any language, devtools, software applications, apps, webservices like PaaS, SaaS or IaaS and also learning resources like guides and tutorials. Everytime you find a cool tool on the web, just post it to the list. Everytime you’re looking for a tool to help you with your development problems come visit the list. Easy enough.</p>\n<h3 id=\"Tech-facts\"><a href=\"#Tech-facts\" class=\"headerlink\" title=\"Tech facts\"></a>Tech facts</h3><p>Webdevlist’s frontend is built with <a href=\"https://angular.io/\" title=\"Angular2\" target=\"_blank\" rel=\"external\">Angular2</a>, which just has had its first final release. The backend makes use of <a href=\"http://loopback.io/\" title=\"LoopbackJS\" target=\"_blank\" rel=\"external\">LoopbackJS</a>, which is a mighty framework to build REST APIs with a minimum of boilerplate code. Additionally the site is powered by HTTP/2.0 to get some more speed.</p>\n<h3 id=\"Is-it-finished-yet\"><a href=\"#Is-it-finished-yet\" class=\"headerlink\" title=\"Is it finished, yet?\"></a>Is it finished, yet?</h3><p>No, it isn’t. Actually, it probably never will be. I’m continuously going to add new technology to Webdevlist’s stack and change and refactor things. Currently I’m considering to switch to <a href=\"http://graphql.org/learn/\" title=\"GraphQL\" target=\"_blank\" rel=\"external\">GraphQL</a>. Right now, Webdevlist is in some kind of beta state, meaning that it still might have bugs.</p>\n<p>I’d really appreciate to get feedback on this project!</p>\n<p><a href=\"https://webdevlist.net\" target=\"_blank\" rel=\"external\">&gt;&gt; Webdevlist.net</a><br><a href=\"https://github.com/n1try/webdevlist.net\" target=\"_blank\" rel=\"external\">&gt;&gt; Webdevlist on GitHub</a> </p>\n"},{"title":"Design of a Linked Data-enabled Microservice Platform for the Industrial Internet of Things","date":"2016-10-19T21:03:07.000Z","_content":"\nAs the topic of my bachelor's thesis at the [TECO](http://teco.edu) and part of the [ScaleIT](https://scale-it.org) research project I've designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.\nHere's my thesis' abstract to get an idea of the topic.\n\n![](/images/thesis_mockup.png)\n\n### Abstract\n\nWhile recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par \nAddressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. \n\n### Tech stack\n\nWe've used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. \n\n![](/images/thesis_stack.png)\n\nMy work is published at the [KITopen repository](https://publikationen.bibliothek.kit.edu/1000061764).\nIf you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!\n","source":"_posts/design-of-a-linked-data-enabled-microservice-platform-for-the-industrial-internet-of-things.md","raw":"---\ntitle: >-\n  Design of a Linked Data-enabled Microservice Platform for the Industrial\n  Internet of Things\ndate: 2016-10-19 23:03:07\ntags:\n---\n\nAs the topic of my bachelor's thesis at the [TECO](http://teco.edu) and part of the [ScaleIT](https://scale-it.org) research project I've designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.\nHere's my thesis' abstract to get an idea of the topic.\n\n![](/images/thesis_mockup.png)\n\n### Abstract\n\nWhile recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par \nAddressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. \n\n### Tech stack\n\nWe've used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. \n\n![](/images/thesis_stack.png)\n\nMy work is published at the [KITopen repository](https://publikationen.bibliothek.kit.edu/1000061764).\nIf you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!\n","slug":"design-of-a-linked-data-enabled-microservice-platform-for-the-industrial-internet-of-things","published":1,"updated":"2017-05-03T21:03:46.096Z","_id":"cj29gz265000nqkqgdtcvi2oo","comments":1,"layout":"post","photos":[],"link":"","content":"<p>As the topic of my bachelor’s thesis at the <a href=\"http://teco.edu\" target=\"_blank\" rel=\"external\">TECO</a> and part of the <a href=\"https://scale-it.org\" target=\"_blank\" rel=\"external\">ScaleIT</a> research project I’ve designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.<br>Here’s my thesis’ abstract to get an idea of the topic.</p>\n<p><img src=\"/images/thesis_mockup.png\" alt=\"\"></p>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>While recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par<br>Addressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. </p>\n<h3 id=\"Tech-stack\"><a href=\"#Tech-stack\" class=\"headerlink\" title=\"Tech stack\"></a>Tech stack</h3><p>We’ve used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. </p>\n<p><img src=\"/images/thesis_stack.png\" alt=\"\"></p>\n<p>My work is published at the <a href=\"https://publikationen.bibliothek.kit.edu/1000061764\" target=\"_blank\" rel=\"external\">KITopen repository</a>.<br>If you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!</p>\n","site":{"data":{}},"excerpt":"","more":"<p>As the topic of my bachelor’s thesis at the <a href=\"http://teco.edu\" target=\"_blank\" rel=\"external\">TECO</a> and part of the <a href=\"https://scale-it.org\" target=\"_blank\" rel=\"external\">ScaleIT</a> research project I’ve designed and developed an IoT software platform with focus on uniformity, openess and ease of adoption to tackle to problem of bringing flexible IT infrastructures to the industrial shopfloor.<br>Here’s my thesis’ abstract to get an idea of the topic.</p>\n<p><img src=\"/images/thesis_mockup.png\" alt=\"\"></p>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>While recent trends towards highly digitized, smart factories entail substantial chances for manufacturing companies to boost their performance, flexibility and productivity, the industry commonly struggles to adopt suitable technology. One major problem is a lack of uniform, standardized solutions, which could be integrated to the shopfloor without the necessity of highly specialized technical expert knowledge and a large amount of planning and restructuring.\\par<br>Addressing that problem, this work proposes an architecture design as well as a concrete implementation of a Internet Of Things software platform, which mainly focuses on technological uniformity and ease of adoption and usage. As a guideline, a real-world use case elaborated in cooperation with industry partners is presented. Further on, it is shown, how general purpose web technology can be combined advantageously with recent architectural-, operational- and cultural trends in software design, powerful machine-to-machine interaction techniques and common user experience concepts. In-depth thoughts on software structure, real-time communication, machine-to-machine interaction, uniform data integration and user experience are conducted to finally obtain a working proof-of-concept software alongside recommendations and best practices for adopting smart technology on the shopfloor. An eventual evaluation investigates the designed platform regarding both performance and suitability for particular real-world scenarios and recommends further endeavor to be conducted towards achieving an actual product. </p>\n<h3 id=\"Tech-stack\"><a href=\"#Tech-stack\" class=\"headerlink\" title=\"Tech stack\"></a>Tech stack</h3><p>We’ve used general-purpose web technology, Linked Data techniques, semantic hypermedia APIs with Hydra and state-of-the-art software development practices and cloud technology to fulfil our goal. We also picked up on the commonly understood UX concept of apps to abstract underlying technical details away from the end-user and created kind of an app store for on-shoploor purposes. </p>\n<p><img src=\"/images/thesis_stack.png\" alt=\"\"></p>\n<p>My work is published at the <a href=\"https://publikationen.bibliothek.kit.edu/1000061764\" target=\"_blank\" rel=\"external\">KITopen repository</a>.<br>If you got curious and are interested in more details or in case you have questions or criticism, please feel free to contact me!</p>\n"},{"title":"How to load Yago into Apache Jena / Fuseki","date":"2016-11-11T22:04:09.000Z","_content":"\nThis article describes how to load the [Yago](http://yago-knowledge.org) Linked Data knowledge collection into an [Apache Jena](https://jena.apache.org/) triple store database on Windows 10 as well as on Linux.\n\n1. At very first, please make sure you have Java 8 Runtime Environment installed on your system.\n\n2. Download all Yago graphs you need from the [downloads section](http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) as .ttl files. In my case I took all graphs from _TAXONOMY_, _CORE_ and additonally the _yagoDBpediaInstances_ and _yagoDBpediaClasses_ collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let's say `/home/ferdinand/yago/` on Linux or `C:\\Users\\Ferdinand\\yago` on Windows and extract them using 7zip.\n\n3. Delete all `.7z` files.\n\n4. Download `apache-jena-3.1.1.zip` (or newer version) and `apache-jena-fuseki-2.4.1.zip` from [here](https://jena.apache.org/download/index.cgi) and extract them to, let's say `/home/ferdinand/jena/` and `/home/ferdinand/fuseki/` (or the analogue directories on Windows).\n\n5. Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run `sed -i 's/|/-/g' ./* && sed -i 's/\\\\\\\\/-/g' ./* && sed -i 's/–/-/g' ./*` from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. `/mnt/c/Users/Ferdinand/yago`) and do the same command. It will take several minutes. I mean, really several...\n\n6. Create a folder to be used for the database later, e.g. `/home/ferdinand/yago/data`.\n\n7. Add the Fuseki root directory (e.g. `/home/ferdinand/fuseki`) and the Jena _bin_ (or _bat_ on Win) (e.g. `/home/ferdinand/jena/bin`) to your `PATH` environment variable. On Linux you would do this by editing your `~/.bash_profile`, on Windows you can search for _\"envionment variables\"_ and then use the Windows system settings dialog.\n\n7. Load the graphs using _tdbloader_: `tdbloader.bat --loc data ./*` from the directory where your .ttl files are located. This may take several hours. Not joking...\n\n8. Start Fuseki typing `java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph` to run fuseki with your entire Yago graph available under the _myGraph_ alias.\n\n9. Open [http://localhost:3030](http://localhost:3030) in your browser and start making queries.\n\nIf you're about to run really expensive queries, consider the following.\n\n1. Set the `JVM_ARGS` environment variable to `-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC`. This will basically prevent you from getting _OutOfMemory_ errors.\n\n2. Use _tdbquery_ since it might be a little more performant than the web SPARQL endpoint. An example _tdbquery_ command might look like this, assuming you have a file `q.txt` that contains your SPARQL query: `tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt > output.txt`","source":"_posts/how-to-load-yago-into-apache-jena-fuseki.md","raw":"---\ntitle: How to load Yago into Apache Jena / Fuseki\ndate: 2016-11-11 23:04:09\ntags:\n---\n\nThis article describes how to load the [Yago](http://yago-knowledge.org) Linked Data knowledge collection into an [Apache Jena](https://jena.apache.org/) triple store database on Windows 10 as well as on Linux.\n\n1. At very first, please make sure you have Java 8 Runtime Environment installed on your system.\n\n2. Download all Yago graphs you need from the [downloads section](http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) as .ttl files. In my case I took all graphs from _TAXONOMY_, _CORE_ and additonally the _yagoDBpediaInstances_ and _yagoDBpediaClasses_ collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let's say `/home/ferdinand/yago/` on Linux or `C:\\Users\\Ferdinand\\yago` on Windows and extract them using 7zip.\n\n3. Delete all `.7z` files.\n\n4. Download `apache-jena-3.1.1.zip` (or newer version) and `apache-jena-fuseki-2.4.1.zip` from [here](https://jena.apache.org/download/index.cgi) and extract them to, let's say `/home/ferdinand/jena/` and `/home/ferdinand/fuseki/` (or the analogue directories on Windows).\n\n5. Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run `sed -i 's/|/-/g' ./* && sed -i 's/\\\\\\\\/-/g' ./* && sed -i 's/–/-/g' ./*` from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. `/mnt/c/Users/Ferdinand/yago`) and do the same command. It will take several minutes. I mean, really several...\n\n6. Create a folder to be used for the database later, e.g. `/home/ferdinand/yago/data`.\n\n7. Add the Fuseki root directory (e.g. `/home/ferdinand/fuseki`) and the Jena _bin_ (or _bat_ on Win) (e.g. `/home/ferdinand/jena/bin`) to your `PATH` environment variable. On Linux you would do this by editing your `~/.bash_profile`, on Windows you can search for _\"envionment variables\"_ and then use the Windows system settings dialog.\n\n7. Load the graphs using _tdbloader_: `tdbloader.bat --loc data ./*` from the directory where your .ttl files are located. This may take several hours. Not joking...\n\n8. Start Fuseki typing `java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph` to run fuseki with your entire Yago graph available under the _myGraph_ alias.\n\n9. Open [http://localhost:3030](http://localhost:3030) in your browser and start making queries.\n\nIf you're about to run really expensive queries, consider the following.\n\n1. Set the `JVM_ARGS` environment variable to `-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC`. This will basically prevent you from getting _OutOfMemory_ errors.\n\n2. Use _tdbquery_ since it might be a little more performant than the web SPARQL endpoint. An example _tdbquery_ command might look like this, assuming you have a file `q.txt` that contains your SPARQL query: `tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt > output.txt`","slug":"how-to-load-yago-into-apache-jena-fuseki","published":1,"updated":"2017-05-03T21:04:31.934Z","_id":"cj29h0dno000oqkqgs8u07o0g","comments":1,"layout":"post","photos":[],"link":"","content":"<p>This article describes how to load the <a href=\"http://yago-knowledge.org\" target=\"_blank\" rel=\"external\">Yago</a> Linked Data knowledge collection into an <a href=\"https://jena.apache.org/\" target=\"_blank\" rel=\"external\">Apache Jena</a> triple store database on Windows 10 as well as on Linux.</p>\n<ol>\n<li><p>At very first, please make sure you have Java 8 Runtime Environment installed on your system.</p>\n</li>\n<li><p>Download all Yago graphs you need from the <a href=\"http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/\" target=\"_blank\" rel=\"external\">downloads section</a> as .ttl files. In my case I took all graphs from <em>TAXONOMY</em>, <em>CORE</em> and additonally the <em>yagoDBpediaInstances</em> and <em>yagoDBpediaClasses</em> collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let’s say <code>/home/ferdinand/yago/</code> on Linux or <code>C:\\Users\\Ferdinand\\yago</code> on Windows and extract them using 7zip.</p>\n</li>\n<li><p>Delete all <code>.7z</code> files.</p>\n</li>\n<li><p>Download <code>apache-jena-3.1.1.zip</code> (or newer version) and <code>apache-jena-fuseki-2.4.1.zip</code> from <a href=\"https://jena.apache.org/download/index.cgi\" target=\"_blank\" rel=\"external\">here</a> and extract them to, let’s say <code>/home/ferdinand/jena/</code> and <code>/home/ferdinand/fuseki/</code> (or the analogue directories on Windows).</p>\n</li>\n<li><p>Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run <code>sed -i &#39;s/|/-/g&#39; ./* &amp;&amp; sed -i &#39;s/\\\\\\\\/-/g&#39; ./* &amp;&amp; sed -i &#39;s/–/-/g&#39; ./*</code> from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. <code>/mnt/c/Users/Ferdinand/yago</code>) and do the same command. It will take several minutes. I mean, really several…</p>\n</li>\n<li><p>Create a folder to be used for the database later, e.g. <code>/home/ferdinand/yago/data</code>.</p>\n</li>\n<li><p>Add the Fuseki root directory (e.g. <code>/home/ferdinand/fuseki</code>) and the Jena <em>bin</em> (or <em>bat</em> on Win) (e.g. <code>/home/ferdinand/jena/bin</code>) to your <code>PATH</code> environment variable. On Linux you would do this by editing your <code>~/.bash_profile</code>, on Windows you can search for <em>“envionment variables”</em> and then use the Windows system settings dialog.</p>\n</li>\n<li><p>Load the graphs using <em>tdbloader</em>: <code>tdbloader.bat --loc data ./*</code> from the directory where your .ttl files are located. This may take several hours. Not joking…</p>\n</li>\n<li><p>Start Fuseki typing <code>java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph</code> to run fuseki with your entire Yago graph available under the <em>myGraph</em> alias.</p>\n</li>\n<li><p>Open <a href=\"http://localhost:3030\" target=\"_blank\" rel=\"external\">http://localhost:3030</a> in your browser and start making queries.</p>\n</li>\n</ol>\n<p>If you’re about to run really expensive queries, consider the following.</p>\n<ol>\n<li><p>Set the <code>JVM_ARGS</code> environment variable to <code>-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC</code>. This will basically prevent you from getting <em>OutOfMemory</em> errors.</p>\n</li>\n<li><p>Use <em>tdbquery</em> since it might be a little more performant than the web SPARQL endpoint. An example <em>tdbquery</em> command might look like this, assuming you have a file <code>q.txt</code> that contains your SPARQL query: <code>tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt &gt; output.txt</code></p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>This article describes how to load the <a href=\"http://yago-knowledge.org\" target=\"_blank\" rel=\"external\">Yago</a> Linked Data knowledge collection into an <a href=\"https://jena.apache.org/\" target=\"_blank\" rel=\"external\">Apache Jena</a> triple store database on Windows 10 as well as on Linux.</p>\n<ol>\n<li><p>At very first, please make sure you have Java 8 Runtime Environment installed on your system.</p>\n</li>\n<li><p>Download all Yago graphs you need from the <a href=\"http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/\" target=\"_blank\" rel=\"external\">downloads section</a> as .ttl files. In my case I took all graphs from <em>TAXONOMY</em>, <em>CORE</em> and additonally the <em>yagoDBpediaInstances</em> and <em>yagoDBpediaClasses</em> collections to have relations from Yago entities to DBpedia ones. Download the files to a folder on your system, let’s say <code>/home/ferdinand/yago/</code> on Linux or <code>C:\\Users\\Ferdinand\\yago</code> on Windows and extract them using 7zip.</p>\n</li>\n<li><p>Delete all <code>.7z</code> files.</p>\n</li>\n<li><p>Download <code>apache-jena-3.1.1.zip</code> (or newer version) and <code>apache-jena-fuseki-2.4.1.zip</code> from <a href=\"https://jena.apache.org/download/index.cgi\" target=\"_blank\" rel=\"external\">here</a> and extract them to, let’s say <code>/home/ferdinand/jena/</code> and <code>/home/ferdinand/fuseki/</code> (or the analogue directories on Windows).</p>\n</li>\n<li><p>Now the .ttl files needs to get some kind of preprocessed, where non-unicode characters are replaced in order for Jena to accept the data. On Linux run <code>sed -i &#39;s/|/-/g&#39; ./* &amp;&amp; sed -i &#39;s/\\\\\\\\/-/g&#39; ./* &amp;&amp; sed -i &#39;s/–/-/g&#39; ./*</code> from within the directory where your .ttl files are. On Windows, start the Ubuntu Bash, navigate to the respective directory (e.g. <code>/mnt/c/Users/Ferdinand/yago</code>) and do the same command. It will take several minutes. I mean, really several…</p>\n</li>\n<li><p>Create a folder to be used for the database later, e.g. <code>/home/ferdinand/yago/data</code>.</p>\n</li>\n<li><p>Add the Fuseki root directory (e.g. <code>/home/ferdinand/fuseki</code>) and the Jena <em>bin</em> (or <em>bat</em> on Win) (e.g. <code>/home/ferdinand/jena/bin</code>) to your <code>PATH</code> environment variable. On Linux you would do this by editing your <code>~/.bash_profile</code>, on Windows you can search for <em>“envionment variables”</em> and then use the Windows system settings dialog.</p>\n</li>\n<li><p>Load the graphs using <em>tdbloader</em>: <code>tdbloader.bat --loc data ./*</code> from the directory where your .ttl files are located. This may take several hours. Not joking…</p>\n</li>\n<li><p>Start Fuseki typing <code>java -jar fuseki-server.jar --update --loc /home/ferdinand/yago/data /myGraph</code> to run fuseki with your entire Yago graph available under the <em>myGraph</em> alias.</p>\n</li>\n<li><p>Open <a href=\"http://localhost:3030\" target=\"_blank\" rel=\"external\">http://localhost:3030</a> in your browser and start making queries.</p>\n</li>\n</ol>\n<p>If you’re about to run really expensive queries, consider the following.</p>\n<ol>\n<li><p>Set the <code>JVM_ARGS</code> environment variable to <code>-Xms512m -Xmx2048M -XX:-UseGCOverheadLimit -XX:+UseParallelGC</code>. This will basically prevent you from getting <em>OutOfMemory</em> errors.</p>\n</li>\n<li><p>Use <em>tdbquery</em> since it might be a little more performant than the web SPARQL endpoint. An example <em>tdbquery</em> command might look like this, assuming you have a file <code>q.txt</code> that contains your SPARQL query: <code>tdbquery --loc=/home/ferdinand/yago/data --time --results=CSV --query=q.txt &gt; output.txt</code></p>\n</li>\n</ol>\n"},{"title":"My teck stack if I had to build an app today","date":"2016-11-11T22:04:56.000Z","_content":"\nWhat technology stack would I choose, if I had to develop a web application completely from scratch? That's the question this article will cover.\n\nFirst of all: by saying web application I'm referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I'm thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.\n\nBack to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article [How it feels to learn JavaScript in 2016](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f) complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here's what I would pick if I had to realize such a project right today and if there weren't any restrictions. \n\nOf course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new [technology radar for 2016](https://www.thoughtworks.com/de/radar), where they separate into categories _adopt_, _trial_, _assess_ and _hold_. Of course, _hold_-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the _hold_ category. _Adopt_ basically are things that are modern, but also well-established enough to avoid too much risk. _Trial_-techs are more experimental and _assess_ are the latest fancy s***, so to say. Since I'm extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn't decide on one stack, but set up two: _the fancy one_ and _the super fancy one_. Additionally, I define their intersection as _the base stack_, which consists of fundamental tools etc. that both have in common.\n\n### The base stack\nFirst of all, I'd use __Git__ for version control, __Visual Studio Code__ as code editor and __GitLab__ for repository hosting and as build server. If I didn't had to implement user management myself, I'd pick __Auth0__ for that. For deployment, I'd use containers with __Docker__ on __DigitalOcean__ machines and if I needed multiple instances, __Rancher__ would help me to manage them. As reverse proxy in front of the backend I'd choose __nginx__ since it's extremely efficient, performant and has __HTTP/2.0__ support. For bundling, __Webpack__ would be my choice and task automation would be done using plain __npm scripts__. For styling the UI, I'd simply use __Bootstrap 4__ and __SCSS__.  \n\n### The super fancy stack\nThe key point here is that I'd want to abandon a traditional REST API in my project and use __GraphQL__ instead. The backend would be written in __NodeJS__ with [__Graffiti__](https://github.com/RisingStack/graffiti) as GraphQL implementation. I don't know much about the latter one, yet, except for that it's the de-facto GraphQL solution for Node. Why Node? Because it's simply the best choice for the web (my view...). It's performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn't get boring. Since GraphQL is told to work best with other Facebook technology, I'd not be that experimental here and build the frontend on __React__ plus __Relay__ (which is still completely new for me). Database would probably be a __MongoDB__ (JSON everywhere!) with [__Waterline__](https://github.com/balderdashy/waterline) ORM. To put a cherry on the cake, I'd also introduce __Redux__ in addition. I haven't worked with it much, yet, and I heard that it's kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn't supported by the React compiler afaik (please correct me, if I'm wrong), so I'd use __Babel__ to have latest JavaScript features. If having to go mobile, __React Native__ would be the rational choice.\n\n### The fancy stack\nThis stack differs from the _super fancy stack_ in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in __Go__, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I'd use the [__Iris__](http://iris-go.com/) framework. I've read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). _(__EDIT:__ It's not what it seems! Please see my comment below!)._ For the frontend I'm balancing between __Angular 2__ and [__Aurelia__](http://aurelia.io/). Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I'd give it a try. But if having to go mobile, I'd still favor Angular 2, since it perfectly aligns with __Ionic 2__.\n\nTwo other options, which look really interesting to me are __Meteor__ and __HorizonJS__. However, I'm not sure, if it's a good idea to commit to only one comprehensive framework through the full stack.\n\nSo these are my two alternative ways through the webdev jungle - btw, [this good article](https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv) describes another one, especially for newcomer web developers. Sorry, that I haven't justified all choices. Actually, as you probably know, if you're a developer, subjective views like these often aren't even based on pure rational considerations, but are rather emotional and spontaneous.\n\nPlease feel free to give me feedback on my tech stack of choice! \n\n__EDIT:__ Another framework I’d really like to try out is [InfernoJS](https://infernojs.org/), because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.\n\n__EDIT 2:__ After having read [this article](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html) and having done some further research on the Iris framework I really have to retract my above statement that I’d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that it’d be morally tenable to support the authors of that project. So please forget about Iris and take a look at [Beego](https://beego.me/) instead.","source":"_posts/my-teck-stack-if-i-had-to-build-an-app-today.md","raw":"---\ntitle: My teck stack if I had to build an app today\ndate: 2016-11-11 23:04:56\ntags:\n---\n\nWhat technology stack would I choose, if I had to develop a web application completely from scratch? That's the question this article will cover.\n\nFirst of all: by saying web application I'm referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I'm thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.\n\nBack to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article [How it feels to learn JavaScript in 2016](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f) complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here's what I would pick if I had to realize such a project right today and if there weren't any restrictions. \n\nOf course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new [technology radar for 2016](https://www.thoughtworks.com/de/radar), where they separate into categories _adopt_, _trial_, _assess_ and _hold_. Of course, _hold_-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the _hold_ category. _Adopt_ basically are things that are modern, but also well-established enough to avoid too much risk. _Trial_-techs are more experimental and _assess_ are the latest fancy s***, so to say. Since I'm extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn't decide on one stack, but set up two: _the fancy one_ and _the super fancy one_. Additionally, I define their intersection as _the base stack_, which consists of fundamental tools etc. that both have in common.\n\n### The base stack\nFirst of all, I'd use __Git__ for version control, __Visual Studio Code__ as code editor and __GitLab__ for repository hosting and as build server. If I didn't had to implement user management myself, I'd pick __Auth0__ for that. For deployment, I'd use containers with __Docker__ on __DigitalOcean__ machines and if I needed multiple instances, __Rancher__ would help me to manage them. As reverse proxy in front of the backend I'd choose __nginx__ since it's extremely efficient, performant and has __HTTP/2.0__ support. For bundling, __Webpack__ would be my choice and task automation would be done using plain __npm scripts__. For styling the UI, I'd simply use __Bootstrap 4__ and __SCSS__.  \n\n### The super fancy stack\nThe key point here is that I'd want to abandon a traditional REST API in my project and use __GraphQL__ instead. The backend would be written in __NodeJS__ with [__Graffiti__](https://github.com/RisingStack/graffiti) as GraphQL implementation. I don't know much about the latter one, yet, except for that it's the de-facto GraphQL solution for Node. Why Node? Because it's simply the best choice for the web (my view...). It's performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn't get boring. Since GraphQL is told to work best with other Facebook technology, I'd not be that experimental here and build the frontend on __React__ plus __Relay__ (which is still completely new for me). Database would probably be a __MongoDB__ (JSON everywhere!) with [__Waterline__](https://github.com/balderdashy/waterline) ORM. To put a cherry on the cake, I'd also introduce __Redux__ in addition. I haven't worked with it much, yet, and I heard that it's kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn't supported by the React compiler afaik (please correct me, if I'm wrong), so I'd use __Babel__ to have latest JavaScript features. If having to go mobile, __React Native__ would be the rational choice.\n\n### The fancy stack\nThis stack differs from the _super fancy stack_ in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in __Go__, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I'd use the [__Iris__](http://iris-go.com/) framework. I've read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). _(__EDIT:__ It's not what it seems! Please see my comment below!)._ For the frontend I'm balancing between __Angular 2__ and [__Aurelia__](http://aurelia.io/). Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I'd give it a try. But if having to go mobile, I'd still favor Angular 2, since it perfectly aligns with __Ionic 2__.\n\nTwo other options, which look really interesting to me are __Meteor__ and __HorizonJS__. However, I'm not sure, if it's a good idea to commit to only one comprehensive framework through the full stack.\n\nSo these are my two alternative ways through the webdev jungle - btw, [this good article](https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv) describes another one, especially for newcomer web developers. Sorry, that I haven't justified all choices. Actually, as you probably know, if you're a developer, subjective views like these often aren't even based on pure rational considerations, but are rather emotional and spontaneous.\n\nPlease feel free to give me feedback on my tech stack of choice! \n\n__EDIT:__ Another framework I’d really like to try out is [InfernoJS](https://infernojs.org/), because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.\n\n__EDIT 2:__ After having read [this article](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html) and having done some further research on the Iris framework I really have to retract my above statement that I’d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that it’d be morally tenable to support the authors of that project. So please forget about Iris and take a look at [Beego](https://beego.me/) instead.","slug":"my-teck-stack-if-i-had-to-build-an-app-today","published":1,"updated":"2017-05-03T21:05:15.804Z","_id":"cj29h1e4e000pqkqgyrzpovoe","comments":1,"layout":"post","photos":[],"link":"","content":"<p>What technology stack would I choose, if I had to develop a web application completely from scratch? That’s the question this article will cover.</p>\n<p>First of all: by saying web application I’m referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I’m thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.</p>\n<p>Back to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article <a href=\"https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f\" target=\"_blank\" rel=\"external\">How it feels to learn JavaScript in 2016</a> complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here’s what I would pick if I had to realize such a project right today and if there weren’t any restrictions. </p>\n<p>Of course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new <a href=\"https://www.thoughtworks.com/de/radar\" target=\"_blank\" rel=\"external\">technology radar for 2016</a>, where they separate into categories <em>adopt</em>, <em>trial</em>, <em>assess</em> and <em>hold</em>. Of course, <em>hold</em>-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the <em>hold</em> category. <em>Adopt</em> basically are things that are modern, but also well-established enough to avoid too much risk. <em>Trial</em>-techs are more experimental and <em>assess</em> are the latest fancy s<em>*</em>, so to say. Since I’m extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn’t decide on one stack, but set up two: <em>the fancy one</em> and <em>the super fancy one</em>. Additionally, I define their intersection as <em>the base stack</em>, which consists of fundamental tools etc. that both have in common.</p>\n<h3 id=\"The-base-stack\"><a href=\"#The-base-stack\" class=\"headerlink\" title=\"The base stack\"></a>The base stack</h3><p>First of all, I’d use <strong>Git</strong> for version control, <strong>Visual Studio Code</strong> as code editor and <strong>GitLab</strong> for repository hosting and as build server. If I didn’t had to implement user management myself, I’d pick <strong>Auth0</strong> for that. For deployment, I’d use containers with <strong>Docker</strong> on <strong>DigitalOcean</strong> machines and if I needed multiple instances, <strong>Rancher</strong> would help me to manage them. As reverse proxy in front of the backend I’d choose <strong>nginx</strong> since it’s extremely efficient, performant and has <strong>HTTP/2.0</strong> support. For bundling, <strong>Webpack</strong> would be my choice and task automation would be done using plain <strong>npm scripts</strong>. For styling the UI, I’d simply use <strong>Bootstrap 4</strong> and <strong>SCSS</strong>.  </p>\n<h3 id=\"The-super-fancy-stack\"><a href=\"#The-super-fancy-stack\" class=\"headerlink\" title=\"The super fancy stack\"></a>The super fancy stack</h3><p>The key point here is that I’d want to abandon a traditional REST API in my project and use <strong>GraphQL</strong> instead. The backend would be written in <strong>NodeJS</strong> with <a href=\"https://github.com/RisingStack/graffiti\" target=\"_blank\" rel=\"external\"><strong>Graffiti</strong></a> as GraphQL implementation. I don’t know much about the latter one, yet, except for that it’s the de-facto GraphQL solution for Node. Why Node? Because it’s simply the best choice for the web (my view…). It’s performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn’t get boring. Since GraphQL is told to work best with other Facebook technology, I’d not be that experimental here and build the frontend on <strong>React</strong> plus <strong>Relay</strong> (which is still completely new for me). Database would probably be a <strong>MongoDB</strong> (JSON everywhere!) with <a href=\"https://github.com/balderdashy/waterline\" target=\"_blank\" rel=\"external\"><strong>Waterline</strong></a> ORM. To put a cherry on the cake, I’d also introduce <strong>Redux</strong> in addition. I haven’t worked with it much, yet, and I heard that it’s kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn’t supported by the React compiler afaik (please correct me, if I’m wrong), so I’d use <strong>Babel</strong> to have latest JavaScript features. If having to go mobile, <strong>React Native</strong> would be the rational choice.</p>\n<h3 id=\"The-fancy-stack\"><a href=\"#The-fancy-stack\" class=\"headerlink\" title=\"The fancy stack\"></a>The fancy stack</h3><p>This stack differs from the <em>super fancy stack</em> in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in <strong>Go</strong>, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I’d use the <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"external\"><strong>Iris</strong></a> framework. I’ve read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). <em>(<strong>EDIT:</strong> It’s not what it seems! Please see my comment below!).</em> For the frontend I’m balancing between <strong>Angular 2</strong> and <a href=\"http://aurelia.io/\" target=\"_blank\" rel=\"external\"><strong>Aurelia</strong></a>. Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I’d give it a try. But if having to go mobile, I’d still favor Angular 2, since it perfectly aligns with <strong>Ionic 2</strong>.</p>\n<p>Two other options, which look really interesting to me are <strong>Meteor</strong> and <strong>HorizonJS</strong>. However, I’m not sure, if it’s a good idea to commit to only one comprehensive framework through the full stack.</p>\n<p>So these are my two alternative ways through the webdev jungle - btw, <a href=\"https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv\" target=\"_blank\" rel=\"external\">this good article</a> describes another one, especially for newcomer web developers. Sorry, that I haven’t justified all choices. Actually, as you probably know, if you’re a developer, subjective views like these often aren’t even based on pure rational considerations, but are rather emotional and spontaneous.</p>\n<p>Please feel free to give me feedback on my tech stack of choice! </p>\n<p><strong>EDIT:</strong> Another framework I’d really like to try out is <a href=\"https://infernojs.org/\" target=\"_blank\" rel=\"external\">InfernoJS</a>, because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.</p>\n<p><strong>EDIT 2:</strong> After having read <a href=\"http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html\" target=\"_blank\" rel=\"external\">this article</a> and having done some further research on the Iris framework I really have to retract my above statement that I’d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that it’d be morally tenable to support the authors of that project. So please forget about Iris and take a look at <a href=\"https://beego.me/\" target=\"_blank\" rel=\"external\">Beego</a> instead.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>What technology stack would I choose, if I had to develop a web application completely from scratch? That’s the question this article will cover.</p>\n<p>First of all: by saying web application I’m referring to something between a plain static HTML page and an entire Facebook. Basically, an application that fulfills a certain domain of tasks for the user and that requires the usual features like user management, a backend database, multiple UI views and controls, etc. The size of application I’m thinking of could be a browser-based chat app, password-manager or something similar. Neither too simple, nor too complex.</p>\n<p>Back to the topic. Choosing the right technology for a web app feels much like customizing a new PC or even a new car. There are nearly endless options to be weighed to finally pick a bunch of them for a new web application. This super famous article <a href=\"https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.m1nodqu6f\" target=\"_blank\" rel=\"external\">How it feels to learn JavaScript in 2016</a> complains about the confusing and ever-growing, chaotic jungle of new JavaScript frameworks in an ironical way. Indeed, I hear similar arguments from many developers these days. Many of them claim that code quality was getting worse in the web and that every newbie JavaScript programmer threw out his own new framework on yet another .io domain. Although that might be true to a certain extent, I personally still like the great technological variety and innovation. I love to browse GitHub, Reddit, Hackernews and Co. to discover new cool libraries to try out in a project some day. And here’s what I would pick if I had to realize such a project right today and if there weren’t any restrictions. </p>\n<p>Of course, the technology choice depends on the concrete project requirements to a certain extent, but not completely. Consequently, a new project is always a chance to try something new. ThoughtWorks just published their new <a href=\"https://www.thoughtworks.com/de/radar\" target=\"_blank\" rel=\"external\">technology radar for 2016</a>, where they separate into categories <em>adopt</em>, <em>trial</em>, <em>assess</em> and <em>hold</em>. Of course, <em>hold</em>-techs are not an option for new projects and I actually pretty much agree with their views on what has to be in the <em>hold</em> category. <em>Adopt</em> basically are things that are modern, but also well-established enough to avoid too much risk. <em>Trial</em>-techs are more experimental and <em>assess</em> are the latest fancy s<em>*</em>, so to say. Since I’m extremely eager to try out new things, my stack would probably mostly consist of technologies from the last category. So what would my stack now look like? Actually, I couldn’t decide on one stack, but set up two: <em>the fancy one</em> and <em>the super fancy one</em>. Additionally, I define their intersection as <em>the base stack</em>, which consists of fundamental tools etc. that both have in common.</p>\n<h3 id=\"The-base-stack\"><a href=\"#The-base-stack\" class=\"headerlink\" title=\"The base stack\"></a>The base stack</h3><p>First of all, I’d use <strong>Git</strong> for version control, <strong>Visual Studio Code</strong> as code editor and <strong>GitLab</strong> for repository hosting and as build server. If I didn’t had to implement user management myself, I’d pick <strong>Auth0</strong> for that. For deployment, I’d use containers with <strong>Docker</strong> on <strong>DigitalOcean</strong> machines and if I needed multiple instances, <strong>Rancher</strong> would help me to manage them. As reverse proxy in front of the backend I’d choose <strong>nginx</strong> since it’s extremely efficient, performant and has <strong>HTTP/2.0</strong> support. For bundling, <strong>Webpack</strong> would be my choice and task automation would be done using plain <strong>npm scripts</strong>. For styling the UI, I’d simply use <strong>Bootstrap 4</strong> and <strong>SCSS</strong>.  </p>\n<h3 id=\"The-super-fancy-stack\"><a href=\"#The-super-fancy-stack\" class=\"headerlink\" title=\"The super fancy stack\"></a>The super fancy stack</h3><p>The key point here is that I’d want to abandon a traditional REST API in my project and use <strong>GraphQL</strong> instead. The backend would be written in <strong>NodeJS</strong> with <a href=\"https://github.com/RisingStack/graffiti\" target=\"_blank\" rel=\"external\"><strong>Graffiti</strong></a> as GraphQL implementation. I don’t know much about the latter one, yet, except for that it’s the de-facto GraphQL solution for Node. Why Node? Because it’s simply the best choice for the web (my view…). It’s performant, comfortable to develop and especially brings consistency by having JS in front- and backend. By always being quite up-to-date with the latest ES* features, Node doesn’t get boring. Since GraphQL is told to work best with other Facebook technology, I’d not be that experimental here and build the frontend on <strong>React</strong> plus <strong>Relay</strong> (which is still completely new for me). Database would probably be a <strong>MongoDB</strong> (JSON everywhere!) with <a href=\"https://github.com/balderdashy/waterline\" target=\"_blank\" rel=\"external\"><strong>Waterline</strong></a> ORM. To put a cherry on the cake, I’d also introduce <strong>Redux</strong> in addition. I haven’t worked with it much, yet, and I heard that it’s kind of mind-blowing in the beginning. However, I consider its concept to cover a large potential to manage consistency in my app. The last thing here is that I desperately want is ES6 syntax. It isn’t supported by the React compiler afaik (please correct me, if I’m wrong), so I’d use <strong>Babel</strong> to have latest JavaScript features. If having to go mobile, <strong>React Native</strong> would be the rational choice.</p>\n<h3 id=\"The-fancy-stack\"><a href=\"#The-fancy-stack\" class=\"headerlink\" title=\"The fancy stack\"></a>The fancy stack</h3><p>This stack differs from the <em>super fancy stack</em> in a few points. A key point is that it would not use GraphQL, but a good old REST API. This API would be written in <strong>Go</strong>, since I like the language - especially its efficiency and its good suitability for web development. More precisely, I’d use the <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"external\"><strong>Iris</strong></a> framework. I’ve read the documentation and it looked incredibly powerful to me (in terms of both functionality and perfomance). <em>(<strong>EDIT:</strong> It’s not what it seems! Please see my comment below!).</em> For the frontend I’m balancing between <strong>Angular 2</strong> and <a href=\"http://aurelia.io/\" target=\"_blank\" rel=\"external\"><strong>Aurelia</strong></a>. Angular 2 is guaranteed to work for any potential case, is extremely powerful and has great community- and library support. However, Aurelia look promising, too, and probably is even more clear and less boilerplate code. Consequently, I’d give it a try. But if having to go mobile, I’d still favor Angular 2, since it perfectly aligns with <strong>Ionic 2</strong>.</p>\n<p>Two other options, which look really interesting to me are <strong>Meteor</strong> and <strong>HorizonJS</strong>. However, I’m not sure, if it’s a good idea to commit to only one comprehensive framework through the full stack.</p>\n<p>So these are my two alternative ways through the webdev jungle - btw, <a href=\"https://medium.freecodecamp.com/a-study-plan-to-cure-javascript-fatigue-8ad3a54f2eb1#.3ri3a1fdv\" target=\"_blank\" rel=\"external\">this good article</a> describes another one, especially for newcomer web developers. Sorry, that I haven’t justified all choices. Actually, as you probably know, if you’re a developer, subjective views like these often aren’t even based on pure rational considerations, but are rather emotional and spontaneous.</p>\n<p>Please feel free to give me feedback on my tech stack of choice! </p>\n<p><strong>EDIT:</strong> Another framework I’d really like to try out is <a href=\"https://infernojs.org/\" target=\"_blank\" rel=\"external\">InfernoJS</a>, because it claims to be extremely lightweight and performant. However, before using Inferno, one should probably be familiar with React, since it uses very similar concepts and syntaxes.</p>\n<p><strong>EDIT 2:</strong> After having read <a href=\"http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html\" target=\"_blank\" rel=\"external\">this article</a> and having done some further research on the Iris framework I really have to retract my above statement that I’d use it as a web backend. While it looks nice on paper, after diving a little deeper I really have to admit that it’d be morally tenable to support the authors of that project. So please forget about Iris and take a look at <a href=\"https://beego.me/\" target=\"_blank\" rel=\"external\">Beego</a> instead.</p>\n"},{"title":"HTTP/2.0 server push proxy","date":"2016-11-14T22:05:45.000Z","_content":"\nI just released a new, little Node project on GitHub and NPM, which is called [http2-serverpush-proxy](https://www.npmjs.com/package/http2-serverpush-proxy) and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as _connect_ middleware for ExpressJS.\n\n### How it works\nUsually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user's browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can't be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, _http2-serverpush-proxy_ sits as a proxy between your actual webserver and the user. In contrast to some other approaches like [http2-push-manifest](https://github.com/GoogleChrome/http2-push-manifest), where the assets to be pushed are declared statically, this library __dynamically parses the HTML__ files and extracts contained assets that should be pushed.\n\n\n![](/images/push_screenshot1.png)\nWithout server push\n![](/images/push_screenshot2.png)\nWith server push\n\nDetails on how to use this library are to be found on the [project site](https://github.com/n1try/http2-serverpush-proxy). Please feel free to give me feedback!\n","source":"_posts/http20-server-push-proxy.md","raw":"---\ntitle: HTTP/2.0 server push proxy\ndate: 2016-11-14 23:05:45\ntags:\n---\n\nI just released a new, little Node project on GitHub and NPM, which is called [http2-serverpush-proxy](https://www.npmjs.com/package/http2-serverpush-proxy) and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as _connect_ middleware for ExpressJS.\n\n### How it works\nUsually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user's browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can't be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, _http2-serverpush-proxy_ sits as a proxy between your actual webserver and the user. In contrast to some other approaches like [http2-push-manifest](https://github.com/GoogleChrome/http2-push-manifest), where the assets to be pushed are declared statically, this library __dynamically parses the HTML__ files and extracts contained assets that should be pushed.\n\n\n![](/images/push_screenshot1.png)\nWithout server push\n![](/images/push_screenshot2.png)\nWith server push\n\nDetails on how to use this library are to be found on the [project site](https://github.com/n1try/http2-serverpush-proxy). Please feel free to give me feedback!\n","slug":"http20-server-push-proxy","published":1,"updated":"2017-05-03T21:14:54.439Z","_id":"cj29h2tau000sqkqgg272sndi","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I just released a new, little Node project on GitHub and NPM, which is called <a href=\"https://www.npmjs.com/package/http2-serverpush-proxy\" target=\"_blank\" rel=\"external\">http2-serverpush-proxy</a> and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as <em>connect</em> middleware for ExpressJS.</p>\n<h3 id=\"How-it-works\"><a href=\"#How-it-works\" class=\"headerlink\" title=\"How it works\"></a>How it works</h3><p>Usually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user’s browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can’t be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, <em>http2-serverpush-proxy</em> sits as a proxy between your actual webserver and the user. In contrast to some other approaches like <a href=\"https://github.com/GoogleChrome/http2-push-manifest\" target=\"_blank\" rel=\"external\">http2-push-manifest</a>, where the assets to be pushed are declared statically, this library <strong>dynamically parses the HTML</strong> files and extracts contained assets that should be pushed.</p>\n<p><img src=\"/images/push_screenshot1.png\" alt=\"\"><br>Without server push<br><img src=\"/images/push_screenshot2.png\" alt=\"\"><br>With server push</p>\n<p>Details on how to use this library are to be found on the <a href=\"https://github.com/n1try/http2-serverpush-proxy\" target=\"_blank\" rel=\"external\">project site</a>. Please feel free to give me feedback!</p>\n","site":{"data":{}},"excerpt":"","more":"<p>I just released a new, little Node project on GitHub and NPM, which is called <a href=\"https://www.npmjs.com/package/http2-serverpush-proxy\" target=\"_blank\" rel=\"external\">http2-serverpush-proxy</a> and does exactly what the name suggests. It spawns a reverse proxy between a web application and its clients, that serves via HTTP/2 and automatically server-pushes assets contained in the HTML. It can be used as either standalone server or as <em>connect</em> middleware for ExpressJS.</p>\n<h3 id=\"How-it-works\"><a href=\"#How-it-works\" class=\"headerlink\" title=\"How it works\"></a>How it works</h3><p>Usually, websites consist of multiple assets, like CSS and JS files as well as images like PNGs, JPGs and SVGs. Traditionally, a user’s browser fetches the HTML first, parses it and then downloads all linked assets. However, this is slow, since the assets can’t be loaded before the HTML is completely fetched and parsed. With server push, your webserver can actively send those assets to the client browser even before it requested them. To prevent you from having to implement this functionality, <em>http2-serverpush-proxy</em> sits as a proxy between your actual webserver and the user. In contrast to some other approaches like <a href=\"https://github.com/GoogleChrome/http2-push-manifest\" target=\"_blank\" rel=\"external\">http2-push-manifest</a>, where the assets to be pushed are declared statically, this library <strong>dynamically parses the HTML</strong> files and extracts contained assets that should be pushed.</p>\n<p><img src=\"/images/push_screenshot1.png\" alt=\"\"><br>Without server push<br><img src=\"/images/push_screenshot2.png\" alt=\"\"><br>With server push</p>\n<p>Details on how to use this library are to be found on the <a href=\"https://github.com/n1try/http2-serverpush-proxy\" target=\"_blank\" rel=\"external\">project site</a>. Please feel free to give me feedback!</p>\n"},{"title":"Http performance Java (Jersey) vs. Go vs. NodeJS","date":"2016-11-19T22:06:49.000Z","_content":"\nI developed a very basic benchmark suite to compare different HTTP server's performance. It is inspired by [arcadius/java-rest-api-web-container-benchmark](https://github.com/arcadius/java-rest-api-web-container-benchmark), but uses [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) instead of [ab](http://httpd.apache.org/docs/2.4/programs/ab.html).\n\nI implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.\n\n## Server Implementations\n* __Java:__ [Jersey](http://jersey.java.net/) with embedded [Grizzly](https://grizzly.java.net/)\n* __Go:__ Using plain `net/http` package\n* __NodeJS:__ Using plain `http` package\n* __NodeJS:__ Using de-facto standard [Express 4](http://expressjs.com/) framework\n\n## Setup\nMy machine, where the benchmark suite was executed on, has the following specifications.\n\n```\n===CPU:\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\n \n===RAM: \n             total       used       free     shared    buffers     cached\nMem:          7.7G       6.3G       1.4G       412M       527M       2.4G\n-/+ buffers/cache:       3.3G       4.3G\nSwap:         5.6G         0B       5.6G\n\n===Java version: \njava version \"1.8.0_101\"\nJava(TM) SE Runtime Environment (build 1.8.0_101-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n \n===OS: \nLinux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux\n\n===Node: \nv6.5.0\n\n=== Go:\ngo version go1.7.3 linux/amd64\n```\n\n## Test parameters\nBasically there are three parameters to be varied for the benchmark.\n* The __number of total reqests__ to be performed against the API. I chose to set this to __100,000__\n* The __number of concurrent__ client to make those requests. I chose to have __32__ concurrent clients, each of them making 3,125 requests.\n* The __number of threads__ to be used by _h2load_. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.\n\n## Results\nRunning my [benchmark script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh) delivered the following results.\n\n![](images/benchmarks.svg)\n\n## Discussion\nFirst of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language's HTTP servers.\nAs we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like [Iris](http://iris-go.com/) on top, which add additional overhead.\n\nSecond place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in [this benchmark](http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/).\n\nBoth of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. \n\nConclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though [Express still has a very great performance](https://raygun.com/blog/2016/06/node-performance/).\n\nThe full benchmark results as well as the suite's source code can be found at my [GitHub project](https://github.com/n1try/http-server-benchmarks).\n\n## EDIT\nAt January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go's net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn't. Using Node's `cluster` module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the `IOStrategy` from the default `WorkerThreadIOStrategy` to `SameThreadIOStrategy`, which brought around 10 % in this specific case, where we don't have any blocking computations but only spit out static JSON. If you're interested in leaarning more about different io strategies, refer to [this official documentation page](https://grizzly.java.net/iostrategies.html). Here is my updated benchmark chart.\n\n![](images/benchmarks2.svg)","source":"_posts/http-performance-java-jersey-vs-go-vs-nodejs.md","raw":"---\ntitle: Http performance Java (Jersey) vs. Go vs. NodeJS\ndate: 2016-11-19 23:06:49\ntags:\n---\n\nI developed a very basic benchmark suite to compare different HTTP server's performance. It is inspired by [arcadius/java-rest-api-web-container-benchmark](https://github.com/arcadius/java-rest-api-web-container-benchmark), but uses [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) instead of [ab](http://httpd.apache.org/docs/2.4/programs/ab.html).\n\nI implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.\n\n## Server Implementations\n* __Java:__ [Jersey](http://jersey.java.net/) with embedded [Grizzly](https://grizzly.java.net/)\n* __Go:__ Using plain `net/http` package\n* __NodeJS:__ Using plain `http` package\n* __NodeJS:__ Using de-facto standard [Express 4](http://expressjs.com/) framework\n\n## Setup\nMy machine, where the benchmark suite was executed on, has the following specifications.\n\n```\n===CPU:\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\nmodel name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores\t: 2\n \n===RAM: \n             total       used       free     shared    buffers     cached\nMem:          7.7G       6.3G       1.4G       412M       527M       2.4G\n-/+ buffers/cache:       3.3G       4.3G\nSwap:         5.6G         0B       5.6G\n\n===Java version: \njava version \"1.8.0_101\"\nJava(TM) SE Runtime Environment (build 1.8.0_101-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n \n===OS: \nLinux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux\n\n===Node: \nv6.5.0\n\n=== Go:\ngo version go1.7.3 linux/amd64\n```\n\n## Test parameters\nBasically there are three parameters to be varied for the benchmark.\n* The __number of total reqests__ to be performed against the API. I chose to set this to __100,000__\n* The __number of concurrent__ client to make those requests. I chose to have __32__ concurrent clients, each of them making 3,125 requests.\n* The __number of threads__ to be used by _h2load_. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.\n\n## Results\nRunning my [benchmark script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh) delivered the following results.\n\n![](images/benchmarks.svg)\n\n## Discussion\nFirst of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language's HTTP servers.\nAs we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like [Iris](http://iris-go.com/) on top, which add additional overhead.\n\nSecond place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in [this benchmark](http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/).\n\nBoth of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. \n\nConclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though [Express still has a very great performance](https://raygun.com/blog/2016/06/node-performance/).\n\nThe full benchmark results as well as the suite's source code can be found at my [GitHub project](https://github.com/n1try/http-server-benchmarks).\n\n## EDIT\nAt January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go's net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn't. Using Node's `cluster` module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the `IOStrategy` from the default `WorkerThreadIOStrategy` to `SameThreadIOStrategy`, which brought around 10 % in this specific case, where we don't have any blocking computations but only spit out static JSON. If you're interested in leaarning more about different io strategies, refer to [this official documentation page](https://grizzly.java.net/iostrategies.html). Here is my updated benchmark chart.\n\n![](images/benchmarks2.svg)","slug":"http-performance-java-jersey-vs-go-vs-nodejs","published":1,"updated":"2017-05-03T21:11:08.986Z","_id":"cj29h3t17000tqkqg4025s0u6","comments":1,"layout":"post","photos":[],"link":"","content":"<p>I developed a very basic benchmark suite to compare different HTTP server’s performance. It is inspired by <a href=\"https://github.com/arcadius/java-rest-api-web-container-benchmark\" target=\"_blank\" rel=\"external\">arcadius/java-rest-api-web-container-benchmark</a>, but uses <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"external\">h2load</a> instead of <a href=\"http://httpd.apache.org/docs/2.4/programs/ab.html\" target=\"_blank\" rel=\"external\">ab</a>.</p>\n<p>I implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.</p>\n<h2 id=\"Server-Implementations\"><a href=\"#Server-Implementations\" class=\"headerlink\" title=\"Server Implementations\"></a>Server Implementations</h2><ul>\n<li><strong>Java:</strong> <a href=\"http://jersey.java.net/\" target=\"_blank\" rel=\"external\">Jersey</a> with embedded <a href=\"https://grizzly.java.net/\" target=\"_blank\" rel=\"external\">Grizzly</a></li>\n<li><strong>Go:</strong> Using plain <code>net/http</code> package</li>\n<li><strong>NodeJS:</strong> Using plain <code>http</code> package</li>\n<li><strong>NodeJS:</strong> Using de-facto standard <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"external\">Express 4</a> framework</li>\n</ul>\n<h2 id=\"Setup\"><a href=\"#Setup\" class=\"headerlink\" title=\"Setup\"></a>Setup</h2><p>My machine, where the benchmark suite was executed on, has the following specifications.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\">===CPU:</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\"> </div><div class=\"line\">===RAM: </div><div class=\"line\">             total       used       free     shared    buffers     cached</div><div class=\"line\">Mem:          7.7G       6.3G       1.4G       412M       527M       2.4G</div><div class=\"line\">-/+ buffers/cache:       3.3G       4.3G</div><div class=\"line\">Swap:         5.6G         0B       5.6G</div><div class=\"line\"></div><div class=\"line\">===Java version: </div><div class=\"line\">java version &quot;1.8.0_101&quot;</div><div class=\"line\">Java(TM) SE Runtime Environment (build 1.8.0_101-b13)</div><div class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)</div><div class=\"line\"> </div><div class=\"line\">===OS: </div><div class=\"line\">Linux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux</div><div class=\"line\"></div><div class=\"line\">===Node: </div><div class=\"line\">v6.5.0</div><div class=\"line\"></div><div class=\"line\">=== Go:</div><div class=\"line\">go version go1.7.3 linux/amd64</div></pre></td></tr></table></figure>\n<h2 id=\"Test-parameters\"><a href=\"#Test-parameters\" class=\"headerlink\" title=\"Test parameters\"></a>Test parameters</h2><p>Basically there are three parameters to be varied for the benchmark.</p>\n<ul>\n<li>The <strong>number of total reqests</strong> to be performed against the API. I chose to set this to <strong>100,000</strong></li>\n<li>The <strong>number of concurrent</strong> client to make those requests. I chose to have <strong>32</strong> concurrent clients, each of them making 3,125 requests.</li>\n<li>The <strong>number of threads</strong> to be used by <em>h2load</em>. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Running my <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"external\">benchmark script</a> delivered the following results.</p>\n<p><img src=\"images/benchmarks.svg\" alt=\"\"></p>\n<h2 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h2><p>First of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language’s HTTP servers.<br>As we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"external\">Iris</a> on top, which add additional overhead.</p>\n<p>Second place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in <a href=\"http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/\" target=\"_blank\" rel=\"external\">this benchmark</a>.</p>\n<p>Both of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. </p>\n<p>Conclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though <a href=\"https://raygun.com/blog/2016/06/node-performance/\" target=\"_blank\" rel=\"external\">Express still has a very great performance</a>.</p>\n<p>The full benchmark results as well as the suite’s source code can be found at my <a href=\"https://github.com/n1try/http-server-benchmarks\" target=\"_blank\" rel=\"external\">GitHub project</a>.</p>\n<h2 id=\"EDIT\"><a href=\"#EDIT\" class=\"headerlink\" title=\"EDIT\"></a>EDIT</h2><p>At January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go’s net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn’t. Using Node’s <code>cluster</code> module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the <code>IOStrategy</code> from the default <code>WorkerThreadIOStrategy</code> to <code>SameThreadIOStrategy</code>, which brought around 10 % in this specific case, where we don’t have any blocking computations but only spit out static JSON. If you’re interested in leaarning more about different io strategies, refer to <a href=\"https://grizzly.java.net/iostrategies.html\" target=\"_blank\" rel=\"external\">this official documentation page</a>. Here is my updated benchmark chart.</p>\n<p><img src=\"images/benchmarks2.svg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>I developed a very basic benchmark suite to compare different HTTP server’s performance. It is inspired by <a href=\"https://github.com/arcadius/java-rest-api-web-container-benchmark\" target=\"_blank\" rel=\"external\">arcadius/java-rest-api-web-container-benchmark</a>, but uses <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"external\">h2load</a> instead of <a href=\"http://httpd.apache.org/docs/2.4/programs/ab.html\" target=\"_blank\" rel=\"external\">ab</a>.</p>\n<p>I implemented four very basic REST APIs with exactly one route each, which exposes a small, static todo list as JSON.</p>\n<h2 id=\"Server-Implementations\"><a href=\"#Server-Implementations\" class=\"headerlink\" title=\"Server Implementations\"></a>Server Implementations</h2><ul>\n<li><strong>Java:</strong> <a href=\"http://jersey.java.net/\" target=\"_blank\" rel=\"external\">Jersey</a> with embedded <a href=\"https://grizzly.java.net/\" target=\"_blank\" rel=\"external\">Grizzly</a></li>\n<li><strong>Go:</strong> Using plain <code>net/http</code> package</li>\n<li><strong>NodeJS:</strong> Using plain <code>http</code> package</li>\n<li><strong>NodeJS:</strong> Using de-facto standard <a href=\"http://expressjs.com/\" target=\"_blank\" rel=\"external\">Express 4</a> framework</li>\n</ul>\n<h2 id=\"Setup\"><a href=\"#Setup\" class=\"headerlink\" title=\"Setup\"></a>Setup</h2><p>My machine, where the benchmark suite was executed on, has the following specifications.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\">===CPU:</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\">model name\t: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores\t: 2</div><div class=\"line\"> </div><div class=\"line\">===RAM: </div><div class=\"line\">             total       used       free     shared    buffers     cached</div><div class=\"line\">Mem:          7.7G       6.3G       1.4G       412M       527M       2.4G</div><div class=\"line\">-/+ buffers/cache:       3.3G       4.3G</div><div class=\"line\">Swap:         5.6G         0B       5.6G</div><div class=\"line\"></div><div class=\"line\">===Java version: </div><div class=\"line\">java version &quot;1.8.0_101&quot;</div><div class=\"line\">Java(TM) SE Runtime Environment (build 1.8.0_101-b13)</div><div class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)</div><div class=\"line\"> </div><div class=\"line\">===OS: </div><div class=\"line\">Linux ferdinand-notebook 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u2 (2016-10-19) x86_64 GNU/Linux</div><div class=\"line\"></div><div class=\"line\">===Node: </div><div class=\"line\">v6.5.0</div><div class=\"line\"></div><div class=\"line\">=== Go:</div><div class=\"line\">go version go1.7.3 linux/amd64</div></pre></td></tr></table></figure>\n<h2 id=\"Test-parameters\"><a href=\"#Test-parameters\" class=\"headerlink\" title=\"Test parameters\"></a>Test parameters</h2><p>Basically there are three parameters to be varied for the benchmark.</p>\n<ul>\n<li>The <strong>number of total reqests</strong> to be performed against the API. I chose to set this to <strong>100,000</strong></li>\n<li>The <strong>number of concurrent</strong> client to make those requests. I chose to have <strong>32</strong> concurrent clients, each of them making 3,125 requests.</li>\n<li>The <strong>number of threads</strong> to be used by <em>h2load</em>. I set this parameter to four, corresponding to the number of logical CPU cores of my machine.</li>\n</ul>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Running my <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"external\">benchmark script</a> delivered the following results.</p>\n<p><img src=\"images/benchmarks.svg\" alt=\"\"></p>\n<h2 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h2><p>First of all, please notice that this is definitely not a 100 % correct, scientifical evaluation. Rather it should give basic insights on the order of magnitute of the performance differences between different language’s HTTP servers.<br>As we can clearly see, Go is the fastest candidate among my test subjects. However, my implementation only utilized the plain, built-in http package without any custom ServeMux or any router or middleware on top of it. In a real-world application, one would most likely not operate on such a low level, but use frameworks like <a href=\"http://iris-go.com/\" target=\"_blank\" rel=\"external\">Iris</a> on top, which add additional overhead.</p>\n<p>Second place is Java using Grizzly as an embedded server inside a Jersey application. The reason for me picking Grizzly was that it pointed out to be the fastest among the common servers in <a href=\"http://menelic.com/2016/01/06/java-rest-api-benchmark-tomcat-vs-jetty-vs-grizzly-vs-undertow/\" target=\"_blank\" rel=\"external\">this benchmark</a>.</p>\n<p>Both of my Node implementations perform worst in this benchmark, whereas Express is even only as half as good as the plain http package. Evidently, it introduces quite an amount of overhead. However, one would most likely not implement an actual REST API without a higher-level framework like Express. Consequently, the Express benchmark is probably more representative. </p>\n<p>Conclusing I can say that I was pretty surprised about how large the differences between various servers are. Go is almost six times as fast as Node with Express, even though <a href=\"https://raygun.com/blog/2016/06/node-performance/\" target=\"_blank\" rel=\"external\">Express still has a very great performance</a>.</p>\n<p>The full benchmark results as well as the suite’s source code can be found at my <a href=\"https://github.com/n1try/http-server-benchmarks\" target=\"_blank\" rel=\"external\">GitHub project</a>.</p>\n<h2 id=\"EDIT\"><a href=\"#EDIT\" class=\"headerlink\" title=\"EDIT\"></a>EDIT</h2><p>At January 1st 2017 I did some minor adjustments to my benchmark suite. A thoughtful reader has drawn my attention to the fact that my comparison was a little unfair in the way that Go’s net/http as well as Grizzly use as many threads as the host system provides CPU core by default, while Node doesn’t. Using Node’s <code>cluster</code> module I made both Node-based webservers use four listener threads, too and actually the results have improved by around 45 %. Furthermore I did an adjustment to the Jersey + Grizzly server by changing the <code>IOStrategy</code> from the default <code>WorkerThreadIOStrategy</code> to <code>SameThreadIOStrategy</code>, which brought around 10 % in this specific case, where we don’t have any blocking computations but only spit out static JSON. If you’re interested in leaarning more about different io strategies, refer to <a href=\"https://grizzly.java.net/iostrategies.html\" target=\"_blank\" rel=\"external\">this official documentation page</a>. Here is my updated benchmark chart.</p>\n<p><img src=\"images/benchmarks2.svg\" alt=\"\"></p>\n"},{"title":"Caddy - a modern web server (vs. nginx)","date":"2017-01-09T22:07:55.000Z","_content":"\n__Update:__ I'm glad to tell that this article made it to the front page of [Hacker News](https://news.ycombinator.com/news) only a few hours after publication 🤓.\n\nAt the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, ...) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a [reverse-proxy](https://en.wikipedia.org/wiki/Reverse_proxy) to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to [this statistic](https://w3techs.com/technologies/overview/web_server/all)) and are named [Apache 2](https://httpd.apache.org/) (or _httpd_) (written in C), [nginx](https://www.nginx.com/solutions/web-server/) (say _\"engine ex\"_) (also written in C) and [Microsoft IIS](https://www.iis.net/) (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won't cover IIS further in the following. \n\n![Most popular web servers on the internet](images/webservers.png)\n\n_Most popular web servers on the internet ([Source](https://w3techs.com/technologies/overview/web_server/all))_\n\nnginx' first release was in 2004 and Apache2's roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today's requirements anymore. \n\nPersonally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by [Apache2's extremely high memory overhead](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison). The second reason was that Apache2 still didn't have HTTP/2.0 support in 2016.\n\n![Apache2 vs. nginx memory usage](https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg)\n\n_Apache2 vs. nginx memory usage ([Source](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison))_\n\nI was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I'm a developer and not a sysadmin there's one thing I didn't like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It's also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found [Caddy](https://caddyserver.com). As it turned out, it can even do a lot more cool things, while still being easy to use.\n\nCaddy is written is Go, open-source and pretty actively (according to commit history) developed on [GitHub](https://github.com/mholt/caddy). The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today's web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) [Let's Encrypt](https://letsencrypt.org/) certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it's done completely automatically now. You don't need to run any script. You don't even need to create a Let's Encrypt account or install the _certbot_. At the center of Caddy are is the _middleware_ (or _directives_), which are added to the config as a one-liner. The [list of such](https://caddyserver.com/docs/) is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or [JWT](https://jwt.io)-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using _php-fpm_, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don't need to install any further libraries to be linked (-> no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it's not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). \n\nI migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I'm happy with the setup. But what about performance?\n\nTo measure a very basic performance benchmark, I took [this script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh), which I used in [an earlier benchmark scenario](https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html). This script uses the [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) load test tool and I adjusted the parameters in a way that it performs a total of __100,000 requests__ against a specific route at my webserver with a number of __32 concurrent clients__ (each performing 3,125 requests) on __4 CPU threads__. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.\n\n```\n===CPU:\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\n \n===RAM: \n              total        used        free      shared  buff/cache   available\nMem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G\nSwap:           29G          0B         29G\n \n===OS: \nLinux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nThe results look like this.\n![](images/webserver_performance.png)\n\n_Caddy vs. nginx performance comparison_\n\nAs you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I'm not getting paid for this 😉). Concerning memory usage: I didn't observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).\n\nPlease note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.\n\nBy the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a `mod_http2` for Apache2, but it's not included in the majority of the builds, yet, and to be honest, I didn't want to make an own one. If you're interested in that, you can get a rough idea of Apache2 vs. nginx performance in [this article](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison) (spoiler: it's pretty poor).\n\nSo to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more _serious_ projects you should probably wait until it's even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I'd stick with nginx. Besides that I can't figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.\n\nPlease let me know if you liked my article and also if you don't agree with some of my arguments and insights.","source":"_posts/caddy-a-modern-web-server-vs-nginx.md","raw":"---\ntitle: Caddy - a modern web server (vs. nginx)\ndate: 2017-01-09 23:07:55\ntags:\n---\n\n__Update:__ I'm glad to tell that this article made it to the front page of [Hacker News](https://news.ycombinator.com/news) only a few hours after publication 🤓.\n\nAt the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, ...) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a [reverse-proxy](https://en.wikipedia.org/wiki/Reverse_proxy) to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to [this statistic](https://w3techs.com/technologies/overview/web_server/all)) and are named [Apache 2](https://httpd.apache.org/) (or _httpd_) (written in C), [nginx](https://www.nginx.com/solutions/web-server/) (say _\"engine ex\"_) (also written in C) and [Microsoft IIS](https://www.iis.net/) (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won't cover IIS further in the following. \n\n![Most popular web servers on the internet](images/webservers.png)\n\n_Most popular web servers on the internet ([Source](https://w3techs.com/technologies/overview/web_server/all))_\n\nnginx' first release was in 2004 and Apache2's roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today's requirements anymore. \n\nPersonally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by [Apache2's extremely high memory overhead](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison). The second reason was that Apache2 still didn't have HTTP/2.0 support in 2016.\n\n![Apache2 vs. nginx memory usage](https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg)\n\n_Apache2 vs. nginx memory usage ([Source](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison))_\n\nI was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I'm a developer and not a sysadmin there's one thing I didn't like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It's also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found [Caddy](https://caddyserver.com). As it turned out, it can even do a lot more cool things, while still being easy to use.\n\nCaddy is written is Go, open-source and pretty actively (according to commit history) developed on [GitHub](https://github.com/mholt/caddy). The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today's web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) [Let's Encrypt](https://letsencrypt.org/) certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it's done completely automatically now. You don't need to run any script. You don't even need to create a Let's Encrypt account or install the _certbot_. At the center of Caddy are is the _middleware_ (or _directives_), which are added to the config as a one-liner. The [list of such](https://caddyserver.com/docs/) is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or [JWT](https://jwt.io)-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using _php-fpm_, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don't need to install any further libraries to be linked (-> no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it's not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). \n\nI migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I'm happy with the setup. But what about performance?\n\nTo measure a very basic performance benchmark, I took [this script](https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh), which I used in [an earlier benchmark scenario](https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html). This script uses the [h2load](https://github.com/nghttp2/nghttp2#benchmarking-tool) load test tool and I adjusted the parameters in a way that it performs a total of __100,000 requests__ against a specific route at my webserver with a number of __32 concurrent clients__ (each performing 3,125 requests) on __4 CPU threads__. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.\n\n```\n===CPU:\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\nmodel name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz\ncpu cores : 2\n \n===RAM: \n              total        used        free      shared  buff/cache   available\nMem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G\nSwap:           29G          0B         29G\n \n===OS: \nLinux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nThe results look like this.\n![](images/webserver_performance.png)\n\n_Caddy vs. nginx performance comparison_\n\nAs you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I'm not getting paid for this 😉). Concerning memory usage: I didn't observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).\n\nPlease note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.\n\nBy the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a `mod_http2` for Apache2, but it's not included in the majority of the builds, yet, and to be honest, I didn't want to make an own one. If you're interested in that, you can get a rough idea of Apache2 vs. nginx performance in [this article](https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison) (spoiler: it's pretty poor).\n\nSo to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more _serious_ projects you should probably wait until it's even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I'd stick with nginx. Besides that I can't figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.\n\nPlease let me know if you liked my article and also if you don't agree with some of my arguments and insights.","slug":"caddy-a-modern-web-server-vs-nginx","published":1,"updated":"2017-05-03T21:08:46.343Z","_id":"cj29h58jr000uqkqgj88yibfe","comments":1,"layout":"post","photos":[],"link":"","content":"<p><strong>Update:</strong> I’m glad to tell that this article made it to the front page of <a href=\"https://news.ycombinator.com/news\" target=\"_blank\" rel=\"external\">Hacker News</a> only a few hours after publication 🤓.</p>\n<p>At the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, …) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\" target=\"_blank\" rel=\"external\">reverse-proxy</a> to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to <a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"external\">this statistic</a>) and are named <a href=\"https://httpd.apache.org/\" target=\"_blank\" rel=\"external\">Apache 2</a> (or <em>httpd</em>) (written in C), <a href=\"https://www.nginx.com/solutions/web-server/\" target=\"_blank\" rel=\"external\">nginx</a> (say <em>“engine ex”</em>) (also written in C) and <a href=\"https://www.iis.net/\" target=\"_blank\" rel=\"external\">Microsoft IIS</a> (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won’t cover IIS further in the following. </p>\n<p><img src=\"images/webservers.png\" alt=\"Most popular web servers on the internet\"></p>\n<p>_Most popular web servers on the internet (<a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"external\">Source</a>)_</p>\n<p>nginx’ first release was in 2004 and Apache2’s roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today’s requirements anymore. </p>\n<p>Personally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">Apache2’s extremely high memory overhead</a>. The second reason was that Apache2 still didn’t have HTTP/2.0 support in 2016.</p>\n<p><img src=\"https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg\" alt=\"Apache2 vs. nginx memory usage\"></p>\n<p><em>Apache2 vs. nginx memory usage (<a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">Source</a>)</em></p>\n<p>I was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I’m a developer and not a sysadmin there’s one thing I didn’t like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It’s also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found <a href=\"https://caddyserver.com\" target=\"_blank\" rel=\"external\">Caddy</a>. As it turned out, it can even do a lot more cool things, while still being easy to use.</p>\n<p>Caddy is written is Go, open-source and pretty actively (according to commit history) developed on <a href=\"https://github.com/mholt/caddy\" target=\"_blank\" rel=\"external\">GitHub</a>. The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today’s web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) <a href=\"https://letsencrypt.org/\" target=\"_blank\" rel=\"external\">Let’s Encrypt</a> certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it’s done completely automatically now. You don’t need to run any script. You don’t even need to create a Let’s Encrypt account or install the <em>certbot</em>. At the center of Caddy are is the <em>middleware</em> (or <em>directives</em>), which are added to the config as a one-liner. The <a href=\"https://caddyserver.com/docs/\" target=\"_blank\" rel=\"external\">list of such</a> is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or <a href=\"https://jwt.io\" target=\"_blank\" rel=\"external\">JWT</a>-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using <em>php-fpm</em>, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don’t need to install any further libraries to be linked (-&gt; no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it’s not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). </p>\n<p>I migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I’m happy with the setup. But what about performance?</p>\n<p>To measure a very basic performance benchmark, I took <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"external\">this script</a>, which I used in <a href=\"https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html\">an earlier benchmark scenario</a>. This script uses the <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"external\">h2load</a> load test tool and I adjusted the parameters in a way that it performs a total of <strong>100,000 requests</strong> against a specific route at my webserver with a number of <strong>32 concurrent clients</strong> (each performing 3,125 requests) on <strong>4 CPU threads</strong>. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">===CPU:</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\"> </div><div class=\"line\">===RAM: </div><div class=\"line\">              total        used        free      shared  buff/cache   available</div><div class=\"line\">Mem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G</div><div class=\"line\">Swap:           29G          0B         29G</div><div class=\"line\"> </div><div class=\"line\">===OS: </div><div class=\"line\">Linux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</div></pre></td></tr></table></figure>\n<p>The results look like this.<br><img src=\"images/webserver_performance.png\" alt=\"\"></p>\n<p><em>Caddy vs. nginx performance comparison</em></p>\n<p>As you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I’m not getting paid for this 😉). Concerning memory usage: I didn’t observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).</p>\n<p>Please note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.</p>\n<p>By the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a <code>mod_http2</code> for Apache2, but it’s not included in the majority of the builds, yet, and to be honest, I didn’t want to make an own one. If you’re interested in that, you can get a rough idea of Apache2 vs. nginx performance in <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">this article</a> (spoiler: it’s pretty poor).</p>\n<p>So to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more <em>serious</em> projects you should probably wait until it’s even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I’d stick with nginx. Besides that I can’t figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.</p>\n<p>Please let me know if you liked my article and also if you don’t agree with some of my arguments and insights.</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>Update:</strong> I’m glad to tell that this article made it to the front page of <a href=\"https://news.ycombinator.com/news\" target=\"_blank\" rel=\"external\">Hacker News</a> only a few hours after publication 🤓.</p>\n<p>At the time of writing this article the web is effectively powered by three different major web server software packages. A web server, as covered in this article, basically has two purposes. One is to serve static (no dynamic functionality, no backend, no databse, …) web sites, usually consisting of HTML, JavaScript and CSS plus images etc. The other is to act as a <a href=\"https://en.wikipedia.org/wiki/Reverse_proxy\" target=\"_blank\" rel=\"external\">reverse-proxy</a> to web application backends. The three servers I just mentioned have a combined market share of 94.7 % (according to <a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"external\">this statistic</a>) and are named <a href=\"https://httpd.apache.org/\" target=\"_blank\" rel=\"external\">Apache 2</a> (or <em>httpd</em>) (written in C), <a href=\"https://www.nginx.com/solutions/web-server/\" target=\"_blank\" rel=\"external\">nginx</a> (say <em>“engine ex”</em>) (also written in C) and <a href=\"https://www.iis.net/\" target=\"_blank\" rel=\"external\">Microsoft IIS</a> (written in C++). While the first two are platform independent and open-source, the latter is a proprietary, commercial, Windows-only Microsoft product and therefore more interesting at enterprise level rather than for smaller indie projects. Consequently I won’t cover IIS further in the following. </p>\n<p><img src=\"images/webservers.png\" alt=\"Most popular web servers on the internet\"></p>\n<p>_Most popular web servers on the internet (<a href=\"https://w3techs.com/technologies/overview/web_server/all\" target=\"_blank\" rel=\"external\">Source</a>)_</p>\n<p>nginx’ first release was in 2004 and Apache2’s roots even date back to 1995. Of course both projects are getting updates regularly, but their base concepts still remain the same. And at some point they might not perfectly fit today’s requirements anymore. </p>\n<p>Personally I switched from Apache2 to nginx a few months ago mainly because of two reasons. The first one was that I had really been annoyed by <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">Apache2’s extremely high memory overhead</a>. The second reason was that Apache2 still didn’t have HTTP/2.0 support in 2016.</p>\n<p><img src=\"https://objects-us-west-1.dream.io/kbimages/images/Webserver_memory_graph.jpg\" alt=\"Apache2 vs. nginx memory usage\"></p>\n<p><em>Apache2 vs. nginx memory usage (<a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">Source</a>)</em></p>\n<p>I was pretty happy with nginx and especially its performance as well as the large amount of documentation and forum posts on the web about every conceivable problem were great. But since I’m a developer and not a sysadmin there’s one thing I didn’t like. The configuration is not that intuitive and you really need to get into the syntax and concepts to get an understanding of knobs to turn in order to achieve a certain goal. It’s also much more fine-grained than necessary for the average user. Personally I just want a simple config file with an intuitive syntax where I can tell my web server which static content to display or which backend to reverse-proxy for which route / domain. This, plus some additional features like handling compression, TLS encryption, authentication and maybe some basic rewrites, is fine. Looking for a more modern web server that fulfills these requirements I found <a href=\"https://caddyserver.com\" target=\"_blank\" rel=\"external\">Caddy</a>. As it turned out, it can even do a lot more cool things, while still being easy to use.</p>\n<p>Caddy is written is Go, open-source and pretty actively (according to commit history) developed on <a href=\"https://github.com/mholt/caddy\" target=\"_blank\" rel=\"external\">GitHub</a>. The goal when developing Caddy was exactly what I was looking for: easy configuration and fitness for today’s web applications. It comes with HTTP/2.0 (and even QUIC) support out of the box and serves via HTTPS by default (HTTP to HTTPS redirection is also handled automatically, while you manually had to tell Apache2 or nginx to do so). It even obtains (and regularly renews!) <a href=\"https://letsencrypt.org/\" target=\"_blank\" rel=\"external\">Let’s Encrypt</a> certificates for every (sub)domain you specified in the config file. While enabling HTTPS for a site was really a pain some years ago, it’s done completely automatically now. You don’t need to run any script. You don’t even need to create a Let’s Encrypt account or install the <em>certbot</em>. At the center of Caddy are is the <em>middleware</em> (or <em>directives</em>), which are added to the config as a one-liner. The <a href=\"https://caddyserver.com/docs/\" target=\"_blank\" rel=\"external\">list of such</a> is long and you will find a middleware for almost everything. For instance there are middleware components for logging, gzipping, header modification, (basic or <a href=\"https://jwt.io\" target=\"_blank\" rel=\"external\">JWT</a>-based) authentication and load balancing. But also more fancy things like automatically serving Markdown as HTML, a plug-and-play file browser GUI, HTML minification, IP filtering or pattern-based text replacement in HTML files are available as middlewares. Caddy also aligns well with PHP, using <em>php-fpm</em>, just as nginx does. As usual with Go applications, the entire program is shipped as a single binary (available for Windows, Mac, Linux and BSD), which includes all of its dependencies. Consequently you don’t need to install any further libraries to be linked (-&gt; no version conflicts), what really makes the installation a no-brainer. However, this introduces one little drawback in comparison to nginx modules: every middleware you want to use needs to be included into the binary and if it’s not, you need to re-compile the program (which is done for you by the download script at Caddy website, actually). </p>\n<p>I migrated all of my websites and -apps from nginx to Caddy (which took me hardly more than an hour) and so far I’m happy with the setup. But what about performance?</p>\n<p>To measure a very basic performance benchmark, I took <a href=\"https://github.com/n1try/http-server-benchmarks/blob/master/run-load.sh\" target=\"_blank\" rel=\"external\">this script</a>, which I used in <a href=\"https://ferdinand-muetsch.de/http-performance-java-jersey-vs-go-vs-nodejs.html\">an earlier benchmark scenario</a>. This script uses the <a href=\"https://github.com/nghttp2/nghttp2#benchmarking-tool\" target=\"_blank\" rel=\"external\">h2load</a> load test tool and I adjusted the parameters in a way that it performs a total of <strong>100,000 requests</strong> against a specific route at my webserver with a number of <strong>32 concurrent clients</strong> (each performing 3,125 requests) on <strong>4 CPU threads</strong>. I ran both servers with almost their default configuration, except that I turned on HTTP/2.0 with a self-signed certificate. The file served was a static HTML file containing 6.2 kBytes of data. Both h2load and the respective web server were executed locally on the same machine with the following specs.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">===CPU:</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\">model name : Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz</div><div class=\"line\">cpu cores : 2</div><div class=\"line\"> </div><div class=\"line\">===RAM: </div><div class=\"line\">              total        used        free      shared  buff/cache   available</div><div class=\"line\">Mem:           7,7G        1,8G        4,2G        316M        1,6G        5,3G</div><div class=\"line\">Swap:           29G          0B         29G</div><div class=\"line\"> </div><div class=\"line\">===OS: </div><div class=\"line\">Linux ferdinand-ubuntu 4.8.0-32-generic #34-Ubuntu SMP Tue Dec 13 14:30:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</div></pre></td></tr></table></figure>\n<p>The results look like this.<br><img src=\"images/webserver_performance.png\" alt=\"\"></p>\n<p><em>Caddy vs. nginx performance comparison</em></p>\n<p>As you can clearly see, nginx still performs way better, at least in this very simple scenario. However, Caddy is much more easy to use, in my opinion. Seems like we are having a classical trade-off here. Anyway, you should really give Caddy a try (and I’m not getting paid for this 😉). Concerning memory usage: I didn’t observe that in detail, but suprisingly I found that neither the Caddy process nor the sum of nginx worker processes exceeded 10 MB of RAM usage (may I have done something wrong?).</p>\n<p>Please note that I only measured one specific figure (concurrent req/s) in one specific scenario. One can think of other benchmark setups where results might be the complete opposite, potentially.</p>\n<p>By the way, Apache2 was not included to this benchmark, because I wanted to use HTTP/2.0. Actually in the meantime there is a <code>mod_http2</code> for Apache2, but it’s not included in the majority of the builds, yet, and to be honest, I didn’t want to make an own one. If you’re interested in that, you can get a rough idea of Apache2 vs. nginx performance in <a href=\"https://help.dreamhost.com/hc/en-us/articles/215945987-Web-server-performance-comparison\" target=\"_blank\" rel=\"external\">this article</a> (spoiler: it’s pretty poor).</p>\n<p>So to conclude the discussion: Should you use Caddy in preference to nginx or Apache2? For private projects definitely yes, if you asked me. For more <em>serious</em> projects you should probably wait until it’s even a little more mature (e.g. when a 1.x.x version is out) and maybe also incorporating dynamic module loading. Until then I’d stick with nginx. Besides that I can’t figure out a reason for preferring Apache2 over nginx, except for being too lazy to do the migration.</p>\n<p>Please let me know if you liked my article and also if you don’t agree with some of my arguments and insights.</p>\n"},{"title":"LinkedData Trivia Game","date":"2017-02-01T22:09:18.000Z","_content":"\nOriginally I got inspired by [this recent post](https://news.ycombinator.com/item?id=13677748) on HackerNews, where [alex_g](https://news.ycombinator.com/user?id=alex_g) has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I'm using the [DBPedia](https://dbpedia.org) knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, [kit-lod16-knowledge-panel](https://github.com/n1try/kit-lod16-knowledge-panel), which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).\n\n[Code on GitHub](https://github.com/n1try/linkeddata-trivia)\n\n![](images/trivia.jpg)\n\n### Limitations\nThis project is __not a production-ready__ app at all, but rather a __proof-of-concept__ to experiment with. Currently, the __major issue is performance__. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. \n\nAnother limitation is the way \"wrong\" answer options are generated. Currently, random values within a certain interval around the \"correct\" answer are generated for dates and numbers. For properties, whose _rdfs:range_ are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, __string-valued answers, among others, are ignored__ completely, because it's hard to auto-generate an alternative value for a plain string. There's room for enhancement here.\n\nA third way for improvement would be to include not only DBPedia, but also [Yago](https://yago-knowledge.org), Wikidata and other sources. ","source":"_posts/linkeddata-trivia-game.md","raw":"---\ntitle: LinkedData Trivia Game\ndate: 2017-02-01 23:09:18\ntags:\n---\n\nOriginally I got inspired by [this recent post](https://news.ycombinator.com/item?id=13677748) on HackerNews, where [alex_g](https://news.ycombinator.com/user?id=alex_g) has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I'm using the [DBPedia](https://dbpedia.org) knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, [kit-lod16-knowledge-panel](https://github.com/n1try/kit-lod16-knowledge-panel), which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).\n\n[Code on GitHub](https://github.com/n1try/linkeddata-trivia)\n\n![](images/trivia.jpg)\n\n### Limitations\nThis project is __not a production-ready__ app at all, but rather a __proof-of-concept__ to experiment with. Currently, the __major issue is performance__. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. \n\nAnother limitation is the way \"wrong\" answer options are generated. Currently, random values within a certain interval around the \"correct\" answer are generated for dates and numbers. For properties, whose _rdfs:range_ are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, __string-valued answers, among others, are ignored__ completely, because it's hard to auto-generate an alternative value for a plain string. There's room for enhancement here.\n\nA third way for improvement would be to include not only DBPedia, but also [Yago](https://yago-knowledge.org), Wikidata and other sources. ","slug":"linkeddata-trivia-game","published":1,"updated":"2017-05-03T21:09:38.898Z","_id":"cj29h7097000vqkqgiplm947s","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Originally I got inspired by <a href=\"https://news.ycombinator.com/item?id=13677748\" target=\"_blank\" rel=\"external\">this recent post</a> on HackerNews, where <a href=\"https://news.ycombinator.com/user?id=alex_g\" target=\"_blank\" rel=\"external\">alex_g</a> has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I’m using the <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"external\">DBPedia</a> knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, <a href=\"https://github.com/n1try/kit-lod16-knowledge-panel\" target=\"_blank\" rel=\"external\">kit-lod16-knowledge-panel</a>, which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).</p>\n<p><a href=\"https://github.com/n1try/linkeddata-trivia\" target=\"_blank\" rel=\"external\">Code on GitHub</a></p>\n<p><img src=\"images/trivia.jpg\" alt=\"\"></p>\n<h3 id=\"Limitations\"><a href=\"#Limitations\" class=\"headerlink\" title=\"Limitations\"></a>Limitations</h3><p>This project is <strong>not a production-ready</strong> app at all, but rather a <strong>proof-of-concept</strong> to experiment with. Currently, the <strong>major issue is performance</strong>. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. </p>\n<p>Another limitation is the way “wrong” answer options are generated. Currently, random values within a certain interval around the “correct” answer are generated for dates and numbers. For properties, whose <em>rdfs:range</em> are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, <strong>string-valued answers, among others, are ignored</strong> completely, because it’s hard to auto-generate an alternative value for a plain string. There’s room for enhancement here.</p>\n<p>A third way for improvement would be to include not only DBPedia, but also <a href=\"https://yago-knowledge.org\" target=\"_blank\" rel=\"external\">Yago</a>, Wikidata and other sources. </p>\n","site":{"data":{}},"excerpt":"","more":"<p>Originally I got inspired by <a href=\"https://news.ycombinator.com/item?id=13677748\" target=\"_blank\" rel=\"external\">this recent post</a> on HackerNews, where <a href=\"https://news.ycombinator.com/user?id=alex_g\" target=\"_blank\" rel=\"external\">alex_g</a> has built a quiz, which automatically generates questions from Wikipedia articles using natural language processing (NLP). However, I found the results not that satisfying, yet, and decides to build my own dynamic quiz. Instead of NLP processing I decided to use Linked Data as a base for generating questions. More precisely I’m using the <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"external\">DBPedia</a> knowledge base to retreive fact information from, which mostly originates in Wikipedia articles as well. The data is structured as an RDF graph and can be queried using SPARQL. Despite from the official DBPedia SPARQL endpoint this little proof-of-concept-like app uses another webservice, <a href=\"https://github.com/n1try/kit-lod16-knowledge-panel\" target=\"_blank\" rel=\"external\">kit-lod16-knowledge-panel</a>, which I developed in the context of the Linked Open Data seminar at university. It is responsible for ranking RDF properties for specific RDF entities by relevance in order to decide, which one to display to an end-user (or include to a quiz).</p>\n<p><a href=\"https://github.com/n1try/linkeddata-trivia\" target=\"_blank\" rel=\"external\">Code on GitHub</a></p>\n<p><img src=\"images/trivia.jpg\" alt=\"\"></p>\n<h3 id=\"Limitations\"><a href=\"#Limitations\" class=\"headerlink\" title=\"Limitations\"></a>Limitations</h3><p>This project is <strong>not a production-ready</strong> app at all, but rather a <strong>proof-of-concept</strong> to experiment with. Currently, the <strong>major issue is performance</strong>. Since the app fires a bunch of rather expensive, non-optimized SPARQL queries at the public DBPedia endpoint, the whole process of generating a quiz question takes several seconds on average, sometimes even up to a minute. This could be optimized to a certain extent (e.g. currently there are at least 8 separate HTTP requests from this app plus a few more from the ranking webservice), but all in all querying RDF data is still pretty slow. </p>\n<p>Another limitation is the way “wrong” answer options are generated. Currently, random values within a certain interval around the “correct” answer are generated for dates and numbers. For properties, whose <em>rdfs:range</em> are entities of a class, a random set of other entities from the same class is fetched from DBPedia and shown as alternative answers. However, <strong>string-valued answers, among others, are ignored</strong> completely, because it’s hard to auto-generate an alternative value for a plain string. There’s room for enhancement here.</p>\n<p>A third way for improvement would be to include not only DBPedia, but also <a href=\"https://yago-knowledge.org\" target=\"_blank\" rel=\"external\">Yago</a>, Wikidata and other sources. </p>\n"},{"title":"ML: Telegram chat message classification","date":"2017-02-28T22:10:05.000Z","_content":"\n### Intro\nFirst of all, a short disclaimer: I'm not an expert in machine learning at all. In fact I'm in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I've done the [machine learning course](https://www.youtube.com/user/UWCSE/playlists?sort=dd&shelf_id=16&view=50) by [Pedro Domingos](https://homes.cs.washington.edu/~pedrod/) at University of Washington, [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) by Udacity and Google and the [Machine Learning 1 lecture at Karlsruhe Institute Of Technology](https://his.anthropomatik.kit.edu/english/28_315.php), all of which I can really recommend.\nAfter having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my [Telegram](https://telegram.com) messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook's [fastText](https://github.com/facebookresearch/fastText) text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to [DBPedia](https://dbpedia.org) classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of [SpamAssassin](http://spamassassin.apache.org/)) and it's really easy to understand, I decided to go for that one, too. Inspired by [this article](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/), where the sentiment of tweets is analyzed, I chose to also use the [natural language toolkit](http://www.nltk.org/) for Python. Another option would have been [sklearn](http://scikit-learn.org/), but NLTK also provided some useful utilities beyond the pure ML scope. \n\nAll of my __code is [available on GitHub](https://github.com/n1try/tg-chat-classification/)__.\n\n### Basic Steps\n1. The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it's not a classical REST API, but instead they're using the [MTProto](https://core.telegram.org/mtproto) protocol. I found [vysheng/tg](https://github.com/vysheng/tg) as a cool C++-written commandline client on GitHub as well as [tvdstaaij/telegram-history-dump](https://github.com/tvdstaaij/telegram-history-dump) as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn't want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let's call them _M_, _P_ and _J_). The outcome were three [JSON Lines](http://jsonlines.org/) files.\n2. To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: __C = { _M_, _P_, _J_, _F_ }__\n3. Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form _(text, label)_, where _label_ is the name of the message's sender and _text_ is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.\n4. Next step was to extract the features. In text classification, there is often one binary (_contains_ / _contains not_) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.\n5. Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is `['in', 'case', 'of', 'fire', 'coffee', 'we', 'trust']`, the resultung feature vector for a message _\"in coffee we trust\"_ would be `('in'=True, 'case'=False, 'of'=False, 'fire'=False, 'coffee'=True, 'we'=True, 'trust'=True)`.\n6. One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.\n7. Train [nltk.NaiveBayesClassifier](http://www.nltk.org/api/nltk.classify.html) classifier. This is really just one line of code.\n8. Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.\n\nUsing that basic initial setup on a set of __37257 messages__, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an __accuracy of 0.58__. There seemed to be room for optimization.\n\n### Optimizations\n* Inspired by _fastText_, I decided to include n-grams. This seemed resonable to me, because intuitively I'd say that single words a way less characteristic for a person's writing style than certain phrases. I extended the feature list from step 4 by all possible __bi- and tri-grams__, which are easy to compute with NLTK. Actually I'm not taking ALL bi- and tri-grams and I'm not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the __top 5000 single words, bigrams and trigrams__, ranked descending by their overall frequency. \n* Since NLTK already provides a corpus of __stopwords__ (like \"in\", \"and\", \"of\", etc.), which are obviously not characteristic for a person's style of chatting, I decided to remove them (the German ones) from the message set in step 2.\n\nWith these optimizations, I ended up with an __accuracy of 0.61__ after a training time of 348 seconds (I didn't log testing time at that point).\n\n### Conclusion\nCertainly 61 % accuracy isn't really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a __fastText__ classifier on my data as a comparison baseline and it even only reached __60 % accuracy__ (but with a much better __training time of only 0.66 seconds__). \nMy intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it's not only hard for a machine to predict the message's sender but also for a human. \nMoreover, given more training data (I'd need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.\nActually, the practical relevance of this project isn't quit high anyway, but it was a good practice for me to get into the basics of ML and it's really fun!\n\nPlease leave me feedback if you like to.","source":"_posts/ml-telegram-chat-message-classification.md","raw":"---\ntitle: 'ML: Telegram chat message classification'\ndate: 2017-02-28 23:10:05\ntags:\n---\n\n### Intro\nFirst of all, a short disclaimer: I'm not an expert in machine learning at all. In fact I'm in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I've done the [machine learning course](https://www.youtube.com/user/UWCSE/playlists?sort=dd&shelf_id=16&view=50) by [Pedro Domingos](https://homes.cs.washington.edu/~pedrod/) at University of Washington, [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) by Udacity and Google and the [Machine Learning 1 lecture at Karlsruhe Institute Of Technology](https://his.anthropomatik.kit.edu/english/28_315.php), all of which I can really recommend.\nAfter having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my [Telegram](https://telegram.com) messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook's [fastText](https://github.com/facebookresearch/fastText) text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to [DBPedia](https://dbpedia.org) classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of [SpamAssassin](http://spamassassin.apache.org/)) and it's really easy to understand, I decided to go for that one, too. Inspired by [this article](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/), where the sentiment of tweets is analyzed, I chose to also use the [natural language toolkit](http://www.nltk.org/) for Python. Another option would have been [sklearn](http://scikit-learn.org/), but NLTK also provided some useful utilities beyond the pure ML scope. \n\nAll of my __code is [available on GitHub](https://github.com/n1try/tg-chat-classification/)__.\n\n### Basic Steps\n1. The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it's not a classical REST API, but instead they're using the [MTProto](https://core.telegram.org/mtproto) protocol. I found [vysheng/tg](https://github.com/vysheng/tg) as a cool C++-written commandline client on GitHub as well as [tvdstaaij/telegram-history-dump](https://github.com/tvdstaaij/telegram-history-dump) as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn't want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let's call them _M_, _P_ and _J_). The outcome were three [JSON Lines](http://jsonlines.org/) files.\n2. To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: __C = { _M_, _P_, _J_, _F_ }__\n3. Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form _(text, label)_, where _label_ is the name of the message's sender and _text_ is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.\n4. Next step was to extract the features. In text classification, there is often one binary (_contains_ / _contains not_) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.\n5. Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is `['in', 'case', 'of', 'fire', 'coffee', 'we', 'trust']`, the resultung feature vector for a message _\"in coffee we trust\"_ would be `('in'=True, 'case'=False, 'of'=False, 'fire'=False, 'coffee'=True, 'we'=True, 'trust'=True)`.\n6. One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.\n7. Train [nltk.NaiveBayesClassifier](http://www.nltk.org/api/nltk.classify.html) classifier. This is really just one line of code.\n8. Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.\n\nUsing that basic initial setup on a set of __37257 messages__, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an __accuracy of 0.58__. There seemed to be room for optimization.\n\n### Optimizations\n* Inspired by _fastText_, I decided to include n-grams. This seemed resonable to me, because intuitively I'd say that single words a way less characteristic for a person's writing style than certain phrases. I extended the feature list from step 4 by all possible __bi- and tri-grams__, which are easy to compute with NLTK. Actually I'm not taking ALL bi- and tri-grams and I'm not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the __top 5000 single words, bigrams and trigrams__, ranked descending by their overall frequency. \n* Since NLTK already provides a corpus of __stopwords__ (like \"in\", \"and\", \"of\", etc.), which are obviously not characteristic for a person's style of chatting, I decided to remove them (the German ones) from the message set in step 2.\n\nWith these optimizations, I ended up with an __accuracy of 0.61__ after a training time of 348 seconds (I didn't log testing time at that point).\n\n### Conclusion\nCertainly 61 % accuracy isn't really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a __fastText__ classifier on my data as a comparison baseline and it even only reached __60 % accuracy__ (but with a much better __training time of only 0.66 seconds__). \nMy intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it's not only hard for a machine to predict the message's sender but also for a human. \nMoreover, given more training data (I'd need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.\nActually, the practical relevance of this project isn't quit high anyway, but it was a good practice for me to get into the basics of ML and it's really fun!\n\nPlease leave me feedback if you like to.","slug":"ml-telegram-chat-message-classification","published":1,"updated":"2017-05-03T21:10:26.656Z","_id":"cj29h80am000wqkqgnolw6acz","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"Intro\"><a href=\"#Intro\" class=\"headerlink\" title=\"Intro\"></a>Intro</h3><p>First of all, a short disclaimer: I’m not an expert in machine learning at all. In fact I’m in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I’ve done the <a href=\"https://www.youtube.com/user/UWCSE/playlists?sort=dd&amp;shelf_id=16&amp;view=50\" target=\"_blank\" rel=\"external\">machine learning course</a> by <a href=\"https://homes.cs.washington.edu/~pedrod/\" target=\"_blank\" rel=\"external\">Pedro Domingos</a> at University of Washington, <a href=\"https://www.udacity.com/course/intro-to-machine-learning--ud120\" target=\"_blank\" rel=\"external\">Intro to Machine Learning</a> by Udacity and Google and the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"external\">Machine Learning 1 lecture at Karlsruhe Institute Of Technology</a>, all of which I can really recommend.<br>After having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my <a href=\"https://telegram.com\" target=\"_blank\" rel=\"external\">Telegram</a> messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook’s <a href=\"https://github.com/facebookresearch/fastText\" target=\"_blank\" rel=\"external\">fastText</a> text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"external\">DBPedia</a> classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of <a href=\"http://spamassassin.apache.org/\" target=\"_blank\" rel=\"external\">SpamAssassin</a>) and it’s really easy to understand, I decided to go for that one, too. Inspired by <a href=\"http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\" target=\"_blank\" rel=\"external\">this article</a>, where the sentiment of tweets is analyzed, I chose to also use the <a href=\"http://www.nltk.org/\" target=\"_blank\" rel=\"external\">natural language toolkit</a> for Python. Another option would have been <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"external\">sklearn</a>, but NLTK also provided some useful utilities beyond the pure ML scope. </p>\n<p>All of my <strong>code is <a href=\"https://github.com/n1try/tg-chat-classification/\" target=\"_blank\" rel=\"external\">available on GitHub</a></strong>.</p>\n<h3 id=\"Basic-Steps\"><a href=\"#Basic-Steps\" class=\"headerlink\" title=\"Basic Steps\"></a>Basic Steps</h3><ol>\n<li>The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it’s not a classical REST API, but instead they’re using the <a href=\"https://core.telegram.org/mtproto\" target=\"_blank\" rel=\"external\">MTProto</a> protocol. I found <a href=\"https://github.com/vysheng/tg\" target=\"_blank\" rel=\"external\">vysheng/tg</a> as a cool C++-written commandline client on GitHub as well as <a href=\"https://github.com/tvdstaaij/telegram-history-dump\" target=\"_blank\" rel=\"external\">tvdstaaij/telegram-history-dump</a> as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn’t want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let’s call them <em>M</em>, <em>P</em> and <em>J</em>). The outcome were three <a href=\"http://jsonlines.org/\" target=\"_blank\" rel=\"external\">JSON Lines</a> files.</li>\n<li>To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: <strong>C = { <em>M</em>, <em>P</em>, <em>J</em>, <em>F</em> }</strong></li>\n<li>Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form <em>(text, label)</em>, where <em>label</em> is the name of the message’s sender and <em>text</em> is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.</li>\n<li>Next step was to extract the features. In text classification, there is often one binary (<em>contains</em> / <em>contains not</em>) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.</li>\n<li>Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is <code>[&#39;in&#39;, &#39;case&#39;, &#39;of&#39;, &#39;fire&#39;, &#39;coffee&#39;, &#39;we&#39;, &#39;trust&#39;]</code>, the resultung feature vector for a message <em>“in coffee we trust”</em> would be <code>(&#39;in&#39;=True, &#39;case&#39;=False, &#39;of&#39;=False, &#39;fire&#39;=False, &#39;coffee&#39;=True, &#39;we&#39;=True, &#39;trust&#39;=True)</code>.</li>\n<li>One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.</li>\n<li>Train <a href=\"http://www.nltk.org/api/nltk.classify.html\" target=\"_blank\" rel=\"external\">nltk.NaiveBayesClassifier</a> classifier. This is really just one line of code.</li>\n<li>Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.</li>\n</ol>\n<p>Using that basic initial setup on a set of <strong>37257 messages</strong>, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an <strong>accuracy of 0.58</strong>. There seemed to be room for optimization.</p>\n<h3 id=\"Optimizations\"><a href=\"#Optimizations\" class=\"headerlink\" title=\"Optimizations\"></a>Optimizations</h3><ul>\n<li>Inspired by <em>fastText</em>, I decided to include n-grams. This seemed resonable to me, because intuitively I’d say that single words a way less characteristic for a person’s writing style than certain phrases. I extended the feature list from step 4 by all possible <strong>bi- and tri-grams</strong>, which are easy to compute with NLTK. Actually I’m not taking ALL bi- and tri-grams and I’m not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the <strong>top 5000 single words, bigrams and trigrams</strong>, ranked descending by their overall frequency. </li>\n<li>Since NLTK already provides a corpus of <strong>stopwords</strong> (like “in”, “and”, “of”, etc.), which are obviously not characteristic for a person’s style of chatting, I decided to remove them (the German ones) from the message set in step 2.</li>\n</ul>\n<p>With these optimizations, I ended up with an <strong>accuracy of 0.61</strong> after a training time of 348 seconds (I didn’t log testing time at that point).</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>Certainly 61 % accuracy isn’t really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a <strong>fastText</strong> classifier on my data as a comparison baseline and it even only reached <strong>60 % accuracy</strong> (but with a much better <strong>training time of only 0.66 seconds</strong>).<br>My intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it’s not only hard for a machine to predict the message’s sender but also for a human.<br>Moreover, given more training data (I’d need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.<br>Actually, the practical relevance of this project isn’t quit high anyway, but it was a good practice for me to get into the basics of ML and it’s really fun!</p>\n<p>Please leave me feedback if you like to.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Intro\"><a href=\"#Intro\" class=\"headerlink\" title=\"Intro\"></a>Intro</h3><p>First of all, a short disclaimer: I’m not an expert in machine learning at all. In fact I’m in a rather early stage of the learning process, have basic knowledge and this project is kind of my first practical hands-on ML. I’ve done the <a href=\"https://www.youtube.com/user/UWCSE/playlists?sort=dd&amp;shelf_id=16&amp;view=50\" target=\"_blank\" rel=\"external\">machine learning course</a> by <a href=\"https://homes.cs.washington.edu/~pedrod/\" target=\"_blank\" rel=\"external\">Pedro Domingos</a> at University of Washington, <a href=\"https://www.udacity.com/course/intro-to-machine-learning--ud120\" target=\"_blank\" rel=\"external\">Intro to Machine Learning</a> by Udacity and Google and the <a href=\"https://his.anthropomatik.kit.edu/english/28_315.php\" target=\"_blank\" rel=\"external\">Machine Learning 1 lecture at Karlsruhe Institute Of Technology</a>, all of which I can really recommend.<br>After having gathered all that theoretical knowledge, I wanted to try something practical on my own. I decided to learn a simple classifier for chat messages from my <a href=\"https://telegram.com\" target=\"_blank\" rel=\"external\">Telegram</a> messenger history. I wanted to learn a program that can, given a chat message, tell who the sender of that message is. I further got inspired after having read the papers related to Facebook’s <a href=\"https://github.com/facebookresearch/fastText\" target=\"_blank\" rel=\"external\">fastText</a> text classification algorithm. In their examples they classify Wikipedia abstracts / descriptions to <a href=\"https://dbpedia.org\" target=\"_blank\" rel=\"external\">DBPedia</a> classes or news article headlines to their respective news categories, only based on plain, natural words. Basically these problems are very similar to mine, so I decided to give it a try. Since I found that many text classifiers are learned using the Naive Bayes algorithm (especially popular in spam detection and part of <a href=\"http://spamassassin.apache.org/\" target=\"_blank\" rel=\"external\">SpamAssassin</a>) and it’s really easy to understand, I decided to go for that one, too. Inspired by <a href=\"http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\" target=\"_blank\" rel=\"external\">this article</a>, where the sentiment of tweets is analyzed, I chose to also use the <a href=\"http://www.nltk.org/\" target=\"_blank\" rel=\"external\">natural language toolkit</a> for Python. Another option would have been <a href=\"http://scikit-learn.org/\" target=\"_blank\" rel=\"external\">sklearn</a>, but NLTK also provided some useful utilities beyond the pure ML scope. </p>\n<p>All of my <strong>code is <a href=\"https://github.com/n1try/tg-chat-classification/\" target=\"_blank\" rel=\"external\">available on GitHub</a></strong>.</p>\n<h3 id=\"Basic-Steps\"><a href=\"#Basic-Steps\" class=\"headerlink\" title=\"Basic Steps\"></a>Basic Steps</h3><ol>\n<li>The very first step was to download the data, namely the chat messages. Luckily, Telegram has an open API. However it’s not a classical REST API, but instead they’re using the <a href=\"https://core.telegram.org/mtproto\" target=\"_blank\" rel=\"external\">MTProto</a> protocol. I found <a href=\"https://github.com/vysheng/tg\" target=\"_blank\" rel=\"external\">vysheng/tg</a> as a cool C++-written commandline client on GitHub as well as <a href=\"https://github.com/tvdstaaij/telegram-history-dump\" target=\"_blank\" rel=\"external\">tvdstaaij/telegram-history-dump</a> as a Ruby script to automate the history download for a set of users / chat partners. I told the script (ran in a Docker container, since I didn’t want to install Ruby) to fetch at max 40,000 messages for my top three chat partners (let’s call them <em>M</em>, <em>P</em> and <em>J</em>). The outcome were three <a href=\"http://jsonlines.org/\" target=\"_blank\" rel=\"external\">JSON Lines</a> files.</li>\n<li>To pre-process these files as needed for my learning algorithm, I wrote a Python script that extracted only message text and sender from all incoming messages and dumped these data to a JSON file. Additionally I also extracted the same information for all outgoing messages, i.e. all messages where the sender was me. Consequently, there are four classes: <strong>C = { <em>M</em>, <em>P</em>, <em>J</em>, <em>F</em> }</strong></li>\n<li>Another data-preprocessing step was to convert the JSON objects with class names as keys for message-arrays to one large list of tuples of the form <em>(text, label)</em>, where <em>label</em> is the name of the message’s sender and <em>text</em> is the respective message text. In this step I also discarded words with a length of less than 2 characters and converted everything to lower case.</li>\n<li>Next step was to extract the features. In text classification, there is often one binary (<em>contains</em> / <em>contains not</em>) feature for every possible word. So if all messages in total comprise X different words, there will be a X-dimensional feature vector.</li>\n<li>Last step before actually training the classifier is to compute the feature vector for every messages. For examples if the total feature set is <code>[&#39;in&#39;, &#39;case&#39;, &#39;of&#39;, &#39;fire&#39;, &#39;coffee&#39;, &#39;we&#39;, &#39;trust&#39;]</code>, the resultung feature vector for a message <em>“in coffee we trust”</em> would be <code>(&#39;in&#39;=True, &#39;case&#39;=False, &#39;of&#39;=False, &#39;fire&#39;=False, &#39;coffee&#39;=True, &#39;we&#39;=True, &#39;trust&#39;=True)</code>.</li>\n<li>One more minor thing: shuffle the feature set so that the order of messages and message senders is random. Also divide the feature set into training- and test data, where test data contains about 10 % of the number of messages in the train data.</li>\n<li>Train <a href=\"http://www.nltk.org/api/nltk.classify.html\" target=\"_blank\" rel=\"external\">nltk.NaiveBayesClassifier</a> classifier. This is really just one line of code.</li>\n<li>Use the returned classifier to predict classes for the test messages, validate them and compute the accuracy.</li>\n</ol>\n<p>Using that basic initial setup on a set of <strong>37257 messages</strong>, (7931 from M, 9795 from P, 9314 from F and 10217 from J), I ended up with an <strong>accuracy of 0.58</strong>. There seemed to be room for optimization.</p>\n<h3 id=\"Optimizations\"><a href=\"#Optimizations\" class=\"headerlink\" title=\"Optimizations\"></a>Optimizations</h3><ul>\n<li>Inspired by <em>fastText</em>, I decided to include n-grams. This seemed resonable to me, because intuitively I’d say that single words a way less characteristic for a person’s writing style than certain phrases. I extended the feature list from step 4 by all possible <strong>bi- and tri-grams</strong>, which are easy to compute with NLTK. Actually I’m not taking ALL bi- and tri-grams and I’m not even take all single words as features. Reason for that is that there were approx. 35k different words in the dataset. Plus the n-grams this would make an extremely multi-dimensional feature vector and as it turned out, it was way to complex for my 16 GB MacBook Pro to compute. Consequently, I only took the <strong>top 5000 single words, bigrams and trigrams</strong>, ranked descending by their overall frequency. </li>\n<li>Since NLTK already provides a corpus of <strong>stopwords</strong> (like “in”, “and”, “of”, etc.), which are obviously not characteristic for a person’s style of chatting, I decided to remove them (the German ones) from the message set in step 2.</li>\n</ul>\n<p>With these optimizations, I ended up with an <strong>accuracy of 0.61</strong> after a training time of 348 seconds (I didn’t log testing time at that point).</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>Certainly 61 % accuracy isn’t really a good classifier, but at least significantly better than random guessing (chance of 1/4 in this case). However, I trained a <strong>fastText</strong> classifier on my data as a comparison baseline and it even only reached <strong>60 % accuracy</strong> (but with a much better <strong>training time of only 0.66 seconds</strong>).<br>My intuitive explanation for these rather bad results is the complexity of the problem itself. Given only a set of words without any context and semantics, it’s not only hard for a machine to predict the message’s sender but also for a human.<br>Moreover, given more training data (I’d need a longer message history) and more computing power to handle larger feature sets, the accuracy might further improve slightly.<br>Actually, the practical relevance of this project isn’t quit high anyway, but it was a good practice for me to get into the basics of ML and it’s really fun!</p>\n<p>Please leave me feedback if you like to.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}